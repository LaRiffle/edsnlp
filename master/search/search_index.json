{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started okokok","text":"<p>EDS-NLP provides a set of spaCy components that are used to extract information from clinical notes written in French.</p> <p>If it's your first time with spaCy, we recommend you familiarise yourself with some of their key concepts by looking at the \"spaCy 101\" page.</p>"},{"location":"#quick-start","title":"Quick start","text":""},{"location":"#installation","title":"Installation","text":"<p>You can install EDS-NLP via <code>pip</code>:</p> <pre><code>$ pip install edsnlp\n---&gt; 100%\ncolor:green Successfully installed!\n</code></pre> <p>We recommend pinning the library version in your projects, or use a strict package manager like Poetry.</p> <pre><code>pip install edsnlp==0.8.1\n</code></pre>"},{"location":"#a-first-pipeline","title":"A first pipeline","text":"<p>Once you've installed the library, let's begin with a very simple example that extracts mentions of COVID19 in a text, and detects whether they are negated.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")  # (1)\n\nterms = dict(\n    covid=[\"covid\", \"coronavirus\"],  # (2)\n)\n\n# Sentencizer component, needed for negation detection\nnlp.add_pipe(\"eds.sentences\")  # (3)\n# Matcher component\nnlp.add_pipe(\"eds.matcher\", config=dict(terms=terms))  # (4)\n# Negation detection\nnlp.add_pipe(\"eds.negation\")\n\n# Process your text in one call !\ndoc = nlp(\"Le patient est atteint de covid\")\n\ndoc.ents  # (5)\n# Out: (covid,)\n\ndoc.ents[0]._.negation  # (6)\n# Out: False\n</code></pre> <ol> <li>We only need spaCy's French tokenizer.</li> <li>This example terminology provides a very simple, and by no means exhaustive, list of synonyms for COVID19.</li> <li>In spaCy, pipelines are added via the <code>nlp.add_pipe</code> method. EDS-NLP pipelines are automatically discovered by spaCy.</li> <li>See the matching tutorial for mode details.</li> <li>spaCy stores extracted entities in the <code>Doc.ents</code> attribute.</li> <li>The <code>eds.negation</code> pipeline has added a <code>negation</code> custom attribute.</li> </ol> <p>This example is complete, it should run as-is. Check out the spaCy 101 page if you're not familiar with spaCy.</p>"},{"location":"#available-pipeline-components","title":"Available pipeline components","text":"CoreQualifiersMiscellaneousNERTrainable <p>See the Core components overview for more information.</p> Component Description <code>eds.normalizer</code> Non-destructive input text normalisation <code>eds.sentences</code> Better sentence boundary detection <code>eds.matcher</code> A simple yet powerful entity extractor <code>eds.terminology</code> A simple yet powerful terminology matcher <code>eds.contextual_matcher</code> A conditional entity extractor <code>eds.endlines</code> An unsupervised model to classify each end line <p>See the Qualifiers overview for more information.</p> Pipeline Description <code>eds.negation</code> Rule-based negation detection <code>eds.family</code> Rule-based family context detection <code>eds.hypothesis</code> Rule-based speculation detection <code>eds.reported_speech</code> Rule-based reported speech detection <code>eds.history</code> Rule-based medical history detection <p>See the Miscellaneous components overview for more information.</p> Component Description <code>eds.dates</code> Date extraction and normalisation <code>eds.consultation_dates</code> Identify consultation dates <code>eds.measurements</code> Measure extraction and normalisation <code>eds.sections</code> Section detection <code>eds.reason</code> Rule-based hospitalisation reason detection <code>eds.tables</code> Tables detection <p>See the NER overview for more information.</p> Component Description <code>eds.covid</code> A COVID mentions detector <code>eds.charlson</code> A Charlson score extractor <code>eds.sofa</code> A SOFA score extractor <code>eds.elston_ellis</code> An Elston &amp; Ellis code extractor <code>eds.emergency_priority</code> A priority score extractor <code>eds.emergency_ccmu</code> A CCMU score extractor <code>eds.emergency_gemsa</code> A GEMSA score extractor <code>eds.tnm</code> A TNM score extractor <code>eds.adicap</code> A ADICAP codes extractor <code>eds.drugs</code> A drug mentions extractor <code>eds.cim10</code> A CIM10 terminology matcher <code>eds.umls</code> An UMLS terminology matcher <code>eds.ckd</code> CKD extractor <code>eds.copd</code> COPD extractor <code>eds.cerebrovascular_accident</code> Cerebrovascular accident extractor <code>eds.congestive_heart_failure</code> Congestive heart failure extractor <code>eds.connective_tissue_disease</code> Connective tissue disease extractor <code>eds.dementia</code> Dementia extractor <code>eds.diabetes</code> Diabetes extractor <code>eds.hemiplegia</code> Hemiplegia extractor <code>eds.leukemia</code> Leukemia extractor <code>eds.liver_disease</code> Liver disease extractor <code>eds.lymphoma</code> Lymphoma extractor <code>eds.myocardial_infarction</code> Myocardial infarction extractor <code>eds.peptic_ulcer_disease</code> Peptic ulcer disease extractor <code>eds.peripheral_vascular_disease</code> Peripheral vascular disease extractor <code>eds.solid_tumor</code> Solid tumor extractor <code>eds.alcohol</code> Alcohol consumption extractor <code>eds.tobacco</code> Tobacco consumption extractor Pipeline Description <code>eds.nested-ner</code> A trainable component for nested (and classic) NER <code>eds.span-qualifier</code> A trainable component for multi-class multi-label span qualification"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>The performances of an extraction pipeline may depend on the population and documents that are considered.</p>"},{"location":"#contributing-to-eds-nlp","title":"Contributing to EDS-NLP","text":"<p>We welcome contributions ! Fork the project and propose a pull request. Take a look at the dedicated page for detail.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use EDS-NLP, please cite us as below.</p> <pre><code>@misc{edsnlp,\nauthor = {Dura, Basile and Wajsburt, Perceval and Petit-Jean, Thomas and Cohen, Ariel and Jean, Charline and Bey, Romain},\ndoi    = {10.5281/zenodo.6424993},\ntitle  = {EDS-NLP: efficient information extraction from French clinical notes},\nurl    = {http://aphp.github.io/edsnlp}\n}\n</code></pre>"},{"location":"tokenizers/","title":"Tokenizers","text":"<p>In addition to the standard spaCy <code>FrenchLanguage</code> (<code>fr</code>), EDS-NLP offers a new language better fit for French clinical documents: <code>EDSLanguage</code> (<code>eds</code>). Additionally, the <code>EDSLanguage</code> document creation should be around 5-6 times faster than the <code>fr</code> language. The main differences lie in the tokenization process.</p> <p>A comparison of the two tokenization methods is demonstrated below:</p> Example FrenchLanguage EDSLanguage <code>ACR5</code> [<code>ACR5</code>] [<code>ACR</code>, <code>5</code>] <code>26.5/</code> [<code>26.5/</code>] [<code>26.5</code>, <code>/</code>] <code>\\n \\n CONCLUSION</code> [<code>\\n \\n</code>, <code>CONCLUSION</code>] [<code>\\n</code>, <code>\\n</code>, <code>CONCLUSION</code>] <code>l'art\u00e8re</code> [<code>l'</code>, <code>art\u00e8re</code>] [<code>l'</code>, <code>art\u00e8re</code>] (same) <code>Dr. Pichon</code> [<code>Dr</code>, <code>.</code>, <code>Pichon</code>] [<code>Dr.</code>, <code>Pichon</code>] <code>B.H.HP.A.7.A</code> [<code>B.H.HP.A.7.A</code>] [<code>B.</code>, <code>H.</code>, <code>HP.</code>, <code>A</code>, <code>7</code>, <code>A</code>, <code>0</code>] <p>To instantiate one of the two languages, you can call the <code>spacy.blank</code> method.</p> EDSLanguageFrenchLanguage <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n</code></pre> <pre><code>import spacy\n\nnlp = spacy.blank(\"fr\")\n</code></pre>"},{"location":"advanced-tutorials/","title":"Advanced use cases","text":"<p>In this section, we review a few advanced use cases:</p> <ul> <li>Adding pre-computed word vectors to spaCy</li> <li>Deploying your spaCy pipeline as an API</li> <li>Creating your own component</li> </ul>"},{"location":"advanced-tutorials/fastapi/","title":"Deploying as an API","text":"<p>In this section, we will see how you can deploy your pipeline as a REST API using the power of FastAPI.</p>"},{"location":"advanced-tutorials/fastapi/#the-nlp-pipeline","title":"The NLP pipeline","text":"<p>Let's create a simple NLP model, that can:</p> <ul> <li>match synonyms of COVID19</li> <li>check for negation, speculation and reported speech.</li> </ul> <p>You know the drill:</p> pipeline.py<pre><code>import spacy\n\nnlp = spacy.blank('fr')\n\nnlp.add_pipe(\"eds.sentences\")\n\nconfig = dict(\n    regex=dict(\n        covid=[\n            \"covid\",\n            r\"covid[-\\s]?19\",\n            r\"sars[-\\s]?cov[-\\s]?2\",\n            r\"corona[-\\s]?virus\",\n        ],\n    ),\n    attr=\"LOWER\",\n)\nnlp.add_pipe('eds.matcher', config=config)\n\nnlp.add_pipe(\"eds.negation\")\nnlp.add_pipe(\"eds.family\")\nnlp.add_pipe(\"eds.hypothesis\")\nnlp.add_pipe(\"eds.reported_speech\")\n</code></pre>"},{"location":"advanced-tutorials/fastapi/#creating-the-fastapi-app","title":"Creating the FastAPI app","text":"<p>FastAPI is a incredibly efficient framework, based on Python type hints from the ground up, with the help of Pydantic (another great library for building modern Python). We won't go into too much detail about FastAPI in this tutorial. For further information on how the framework operates, go to its excellent documentation!</p> <p>We'll need to create two things:</p> <ol> <li>A module containing the models for inputs and outputs.</li> <li>The script that defines the application itself.</li> </ol> models.py<pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\n\nclass Entity(BaseModel):  # (1)\n\n    # OMOP-style attributes\n    start: int\n    end: int\n    label: str\n    lexical_variant: str\n    normalized_variant: str\n\n    # Qualifiers\n    negated: bool\n    hypothesis: bool\n    family: bool\n    reported_speech: bool\n\n\nclass Document(BaseModel):  # (2)\n    text: str\n    ents: List[Entity]\n</code></pre> <ol> <li>The <code>Entity</code> model contains attributes that define a matched entity, as well as variables that contain the output of the qualifier components.</li> <li>The <code>Document</code> model contains the input text, and a list of detected entities</li> </ol> <p>Having defined the output models and the pipeline, we can move on to creating the application itself:</p> app.py<pre><code>from typing import List\n\nfrom fastapi import FastAPI\n\nfrom pipeline import nlp\nfrom models import Entity, Document\n\n\napp = FastAPI(title=\"EDS-NLP\", version=edsnlp.__version__)\n\n\n@app.post(\"/covid\", response_model=List[Document])  # (1)\nasync def process(\n    notes: List[str],  # (2)\n):\n\n    documents = []\n\n    for doc in nlp.pipe(notes):\n        entities = []\n\n        for ent in doc.ents:\n            entity = Entity(\n                start=ent.start_char,\n                end=ent.end_char,\n                label=ent.label_,\n                lexical_variant=ent.text,\n                normalized_variant=ent._.normalized_variant,\n                negated=ent._.negation,\n                hypothesis=ent._.hypothesis,\n                family=ent._.family,\n                reported_speech=ent._.reported_speech,\n            )\n            entities.append(entity)\n\n        documents.append(\n            Document(\n                text=doc.text,\n                ents=entities,\n            )\n        )\n\n    return documents\n</code></pre> <ol> <li>By telling FastAPI what output format is expected, you get automatic data validation.</li> <li>In FastAPI, input and output schemas are defined through Python type hinting.    Here, we tell FastAPI to expect a list of strings in the <code>POST</code> request body.    As a bonus, you get data validation for free.</li> </ol>"},{"location":"advanced-tutorials/fastapi/#running-the-api","title":"Running the API","text":"<p>Our simple API is ready to launch! We'll just need to install FastAPI along with a ASGI server to run it. This can be done in one go:</p> <pre><code>$ pip install 'fastapi[uvicorn]'\n---&gt; 100%\ncolor:green Successfully installed fastapi\n</code></pre> <p>Launching the API is trivial:</p> <pre><code>$ uvicorn app:app --reload\n</code></pre> <p>Go to <code>localhost:8000/docs</code> to admire the automatically generated documentation!</p>"},{"location":"advanced-tutorials/fastapi/#using-the-api","title":"Using the API","text":"<p>You can try the API directly from the documentation. Otherwise, you may use the <code>requests</code> package:</p> <pre><code>import requests\n\nnotes = [\n    \"Le p\u00e8re du patient n'est pas atteint de la covid.\",\n    \"Probable coronavirus.\",\n]\n\nr = requests.post(\n    \"http://localhost:8000/covid\",\n    json=notes,\n)\n\nr.json()\n</code></pre> <p>You should get something like:</p> <pre><code>[\n{\n\"text\": \"Le p\u00e8re du patient n'est pas atteint de la covid.\",\n\"ents\": [\n{\n\"start\": 43,\n\"end\": 48,\n\"label\": \"covid\",\n\"lexical_variant\": \"covid\",\n\"normalized_variant\": \"covid\",\n\"negated\": true,\n\"hypothesis\": false,\n\"family\": true,\n\"reported_speech\": false\n}\n]\n},\n{\n\"text\": \"Probable coronavirus.\",\n\"ents\": [\n{\n\"start\": 9,\n\"end\": 20,\n\"label\": \"covid\",\n\"lexical_variant\": \"coronavirus\",\n\"normalized_variant\": \"coronavirus\",\n\"negated\": false,\n\"hypothesis\": true,\n\"family\": false,\n\"reported_speech\": false\n}\n]\n}\n]\n</code></pre>"},{"location":"advanced-tutorials/word-vectors/","title":"Word embeddings","text":"<p>The only ready-to-use components in EDS-NLP are rule-based components. However, that does not prohibit you from exploiting spaCy's machine learning capabilities! You can mix and match machine learning pipelines, trainable or not, with EDS-NLP rule-based components.</p> <p>In this tutorial, we will explore how you can use static word vectors trained with Gensim within spaCy.</p> <p>Training the word embedding, however, is outside the scope of this post. You'll find very well designed resources on the subject in Gensim's documenation.</p> <p>Using Transformer models</p> <p>spaCy v3 introduced support for Transformer models through their helper library <code>spacy-transformers</code> that interfaces with HuggingFace's <code>transformers</code> library.</p> <p>Using transformer models can significantly increase your model's performance.</p>"},{"location":"advanced-tutorials/word-vectors/#adding-pre-trained-word-vectors","title":"Adding pre-trained word vectors","text":"<p>spaCy provides a <code>init vectors</code> CLI utility that takes a Gensim-trained binary and transforms it to a spaCy-readable pipeline.</p> <p>Using it is straightforward :</p> <pre><code>$ spacy init vectors fr /path/to/vectors /path/to/pipeline\n---&gt; 100%\ncolor:green Conversion successful!\n</code></pre> <p>See the documentation for implementation details.</p>"},{"location":"pipelines/","title":"Pipelines overview","text":"<p>EDS-NLP provides easy-to-use pipeline components.</p> CoreQualifiersMiscellaneousNERTrainable Pipeline Description <code>eds.normalizer</code> Non-destructive input text normalisation <code>eds.sentences</code> Better sentence boundary detection <code>eds.matcher</code> A simple yet powerful entity extractor <code>eds.terminology</code> A simple yet powerful terminology matcher <code>eds.contextual-matcher</code> A conditional entity extractor <code>eds.endlines</code> An unsupervised model to classify each end line <p>See the Qualifier overview for more information.</p> Pipeline Description <code>eds.negation</code> Rule-based negation detection <code>eds.family</code> Rule-based family context detection <code>eds.hypothesis</code> Rule-based speculation detection <code>eds.reported_speech</code> Rule-based reported speech detection <code>eds.history</code> Rule-based medical history detection Component Description <code>eds.dates</code> Date extraction and normalisation <code>eds.consultation_dates</code> Identify consultation dates <code>eds.measurements</code> Measure extraction and normalisation <code>eds.sections</code> Section detection <code>eds.reason</code> Rule-based hospitalisation reason detection <code>eds.tables</code> Tables detection <p>See the NER overview for more information.</p> Component Description <code>eds.covid</code> A COVID mentions detector <code>eds.charlson</code> A Charlson score extractor <code>eds.sofa</code> A SOFA score extractor <code>eds.elston_ellis</code> An Elston &amp; Ellis code extractor <code>eds.emergency_priority</code> A priority score extractor <code>eds.emergency_ccmu</code> A CCMU score extractor <code>eds.emergency_gemsa</code> A GEMSA score extractor <code>eds.tnm</code> A TNM score extractor <code>eds.adicap</code> A ADICAP codes extractor <code>eds.drugs</code> A drug mentions extractor <code>eds.cim10</code> A CIM10 terminology matcher <code>eds.umls</code> An UMLS terminology matcher <code>eds.ckd</code> CKD extractor <code>eds.copd</code> COPD extractor <code>eds.cerebrovascular_accident</code> Cerebrovascular accident extractor <code>eds.congestive_heart_failure</code> Congestive heart failure extractor <code>eds.connective_tissue_disease</code> Connective tissue disease extractor <code>eds.dementia</code> Dementia extractor <code>eds.diabetes</code> Diabetes extractor <code>eds.hemiplegia</code> Hemiplegia extractor <code>eds.leukemia</code> Leukemia extractor <code>eds.liver_disease</code> Liver disease extractor <code>eds.lymphoma</code> Lymphoma extractor <code>eds.myocardial_infarction</code> Myocardial infarction extractor <code>eds.peptic_ulcer_disease</code> Peptic ulcer disease extractor <code>eds.peripheral_vascular_disease</code> Peripheral vascular disease extractor <code>eds.solid_tumor</code> Solid tumor extractor <code>eds.alcohol</code> Alcohol consumption extractor <code>eds.tobacco</code> Tobacco consumption extractor Pipeline Description <code>eds.nested-ner</code> A trainable component for nested (and classic) NER <code>eds.span-qualifier</code> A trainable component for multi-class multi-label span qualification <p>You can add them to your pipeline by simply calling <code>add_pipe</code>, for instance:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.tnm\")\n</code></pre>"},{"location":"pipelines/architecture/","title":"Basic Architecture","text":"<p>Most pipelines provided by EDS-NLP aim to qualify pre-extracted entities. To wit, the basic usage of the library:</p> <ol> <li>Implement a normaliser (see <code>normalizer</code>)</li> <li>Add an entity recognition component (eg the simple but powerful <code>matcher</code> pipeline)</li> <li>Add zero or more entity qualification components, such as <code>negation</code>, <code>family</code> or <code>hypothesis</code>. These qualifiers typically help detect false-positives.</li> </ol>"},{"location":"pipelines/architecture/#scope","title":"Scope","text":"<p>Since the basic usage of EDS-NLP components is to qualify entities, most pipelines can function in two modes:</p> <ol> <li>Annotation of the extracted entities (this is the default). To increase throughput, only pre-extracted entities (found in <code>doc.ents</code>) are processed.</li> <li>Full-text, token-wise annotation. This mode is activated by setting the <code>on_ents_only</code> parameter to <code>False</code>.</li> </ol> <p>The possibility to do full-text annotation implies that one could use the pipelines the other way around, eg detecting all negations once and for all in an ETL phase, and reusing the results consequently. However, this is not the intended use of the library, which aims to help researchers downstream as a standalone application.</p>"},{"location":"pipelines/architecture/#result-persistence","title":"Result persistence","text":"<p>Depending on their purpose (entity extraction, qualification, etc), EDS-NLP pipelines write their results to <code>Doc.ents</code>, <code>Doc.spans</code> or in a custom attribute.</p>"},{"location":"pipelines/architecture/#extraction-pipelines","title":"Extraction pipelines","text":"<p>Extraction pipelines (matchers, the date detector or NER pipelines, for instance) keep their results to the <code>Doc.ents</code> attribute directly.</p> <p>Note that spaCy prohibits overlapping entities within the <code>Doc.ents</code> attribute. To circumvent this limitation, we filter spans, and keep all discarded entities within the <code>discarded</code> key of the <code>Doc.spans</code> attribute.</p> <p>Some pipelines write their output to the <code>Doc.spans</code> dictionary. We enforce the following doctrine:</p> <ul> <li>Should the pipe extract entities that are directly informative (typically the output of the <code>eds.matcher</code> component), said entities are stashed in the <code>Doc.ents</code> attribute.</li> <li>On the other hand, should the entity be useful to another pipe, but less so in itself (eg the output of the <code>eds.sections</code> or <code>eds.dates</code> component), it will be stashed in a specific key within the <code>Doc.spans</code> attribute.</li> </ul>"},{"location":"pipelines/architecture/#entity-tagging","title":"Entity tagging","text":"<p>Moreover, most pipelines declare spaCy extensions, on the <code>Doc</code>, <code>Span</code> and/or <code>Token</code> objects.</p> <p>These extensions are especially useful for qualifier pipelines, but can also be used by other pipelines to persist relevant information. For instance, the <code>eds.dates</code> pipeline:</p> <ol> <li>Populates <code>Doc.spans[\"dates\"]</code></li> <li>For each detected item, keeps the normalised date in <code>Span._.date</code></li> </ol> <ol></ol>"},{"location":"pipelines/overview/","title":"Pipes overview","text":"<p>EDS-NLP provides easy-to-use pipeline components (aka pipes).</p>"},{"location":"pipelines/overview/#available-components","title":"Available components","text":"CoreQualifiersMiscellaneousNERTrainable <p>See the Core components overview for more information.</p> Component Description <code>eds.normalizer</code> Non-destructive input text normalisation <code>eds.sentences</code> Better sentence boundary detection <code>eds.matcher</code> A simple yet powerful entity extractor <code>eds.terminology</code> A simple yet powerful terminology matcher <code>eds.contextual_matcher</code> A conditional entity extractor <code>eds.endlines</code> An unsupervised model to classify each end line <p>See the Qualifiers overview for more information.</p> Pipeline Description <code>eds.negation</code> Rule-based negation detection <code>eds.family</code> Rule-based family context detection <code>eds.hypothesis</code> Rule-based speculation detection <code>eds.reported_speech</code> Rule-based reported speech detection <code>eds.history</code> Rule-based medical history detection <p>See the Miscellaneous components overview for more information.</p> Component Description <code>eds.dates</code> Date extraction and normalisation <code>eds.consultation_dates</code> Identify consultation dates <code>eds.measurements</code> Measure extraction and normalisation <code>eds.sections</code> Section detection <code>eds.reason</code> Rule-based hospitalisation reason detection <code>eds.tables</code> Tables detection <p>See the NER overview for more information.</p> Component Description <code>eds.covid</code> A COVID mentions detector <code>eds.charlson</code> A Charlson score extractor <code>eds.sofa</code> A SOFA score extractor <code>eds.elston_ellis</code> An Elston &amp; Ellis code extractor <code>eds.emergency_priority</code> A priority score extractor <code>eds.emergency_ccmu</code> A CCMU score extractor <code>eds.emergency_gemsa</code> A GEMSA score extractor <code>eds.tnm</code> A TNM score extractor <code>eds.adicap</code> A ADICAP codes extractor <code>eds.drugs</code> A drug mentions extractor <code>eds.cim10</code> A CIM10 terminology matcher <code>eds.umls</code> An UMLS terminology matcher <code>eds.ckd</code> CKD extractor <code>eds.copd</code> COPD extractor <code>eds.cerebrovascular_accident</code> Cerebrovascular accident extractor <code>eds.congestive_heart_failure</code> Congestive heart failure extractor <code>eds.connective_tissue_disease</code> Connective tissue disease extractor <code>eds.dementia</code> Dementia extractor <code>eds.diabetes</code> Diabetes extractor <code>eds.hemiplegia</code> Hemiplegia extractor <code>eds.leukemia</code> Leukemia extractor <code>eds.liver_disease</code> Liver disease extractor <code>eds.lymphoma</code> Lymphoma extractor <code>eds.myocardial_infarction</code> Myocardial infarction extractor <code>eds.peptic_ulcer_disease</code> Peptic ulcer disease extractor <code>eds.peripheral_vascular_disease</code> Peripheral vascular disease extractor <code>eds.solid_tumor</code> Solid tumor extractor <code>eds.alcohol</code> Alcohol consumption extractor <code>eds.tobacco</code> Tobacco consumption extractor Pipeline Description <code>eds.nested-ner</code> A trainable component for nested (and classic) NER <code>eds.span-qualifier</code> A trainable component for multi-class multi-label span qualification <p>You can add them to your pipeline by simply calling <code>add_pipe</code>, for instance:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.tnm\")\n</code></pre>"},{"location":"pipelines/overview/#basic-architecture","title":"Basic architecture","text":"<p>Most components provided by EDS-NLP aim to qualify pre-extracted entities. To wit, the basic usage of the library:</p> <ol> <li>Implement a normaliser (see <code>normalizer</code>)</li> <li>Add an entity recognition component (eg the simple but powerful <code>matcher</code> component)</li> <li>Add zero or more entity qualification components, such as <code>negation</code>, <code>family</code> or <code>hypothesis</code>. These qualifiers typically help detect false-positives.</li> </ol>"},{"location":"pipelines/overview/#extraction-components","title":"Extraction components","text":"<p>Extraction components (matchers, the date detector or NER components, for instance) keep their results to the <code>doc.ents</code> and <code>doc.spans</code> attributes directly.</p> <p>By default, some components do not write their output to <code>doc.ents</code>, such as the <code>eds.sections</code> matcher. This is mainly due to the fact that, since <code>doc.ents</code> cannot contain overlapping entities, we filter spans and keep the largest one by default. Since sections usually cover large spans of text, storing them in ents would remove every other overlapping entities.</p>"},{"location":"pipelines/overview/#entity-tagging","title":"Entity tagging","text":"<p>Moreover, most components declare extensions, on the <code>Doc</code>, <code>Span</code> and/or <code>Token</code> objects.</p> <p>These extensions are especially useful for qualifier components, but can also be used by other components to persist relevant information. For instance, the <code>eds.dates</code> component declares a <code>span._.date</code> extension to store a normalised version of each detected date.</p>"},{"location":"pipelines/core/contextual-matcher/","title":"Contextual Matcher","text":"<p>During feature extraction, it may be necessary to search for additional patterns in their neighborhood, namely:</p> <ul> <li>patterns to discard irrelevant entities</li> <li>patterns to enrich these entities and store some information</li> </ul> <p>For example, to extract mentions of non-benign cancers, we need to discard all extractions that mention \"benin\" in their immediate neighborhood. Although such a filtering is feasible using a regular expression, it essentially requires modifying each of the regular expressions.</p> <p>The ContextualMatcher allows to perform this extraction in a clear and concise way.</p>"},{"location":"pipelines/core/contextual-matcher/#the-configuration-file","title":"The configuration file","text":"<p>The whole ContextualMatcher pipeline is basically defined as a list of pattern dictionaries. Let us see step by step how to build such a list using the example stated just above.</p>"},{"location":"pipelines/core/contextual-matcher/#a-finding-mentions-of-cancer","title":"a. Finding mentions of cancer","text":"<p>To do this, we can build either a set of <code>terms</code> or a set of <code>regex</code>. <code>terms</code> will be used to search for exact matches in the text. While less flexible, it is faster than using regex. In our case we could use the following lists (which are of course absolutely not exhaustives):</p> <pre><code>terms = [\n    \"cancer\",\n    \"tumeur\",\n]\n\nregex = [\n    \"adeno(carcinom|[\\s-]?k)\",\n    \"neoplas\",\n    \"melanom\",\n]\n</code></pre> <p>Maybe we want to exclude mentions of benign cancers:</p> <pre><code>benign = \"benign|benin\"\n</code></pre>"},{"location":"pipelines/core/contextual-matcher/#b-find-mention-of-a-stage-and-extract-its-value","title":"b. Find mention of a stage and extract its value","text":"<p>For this we will forge a RegEx with one capturing group (basically a pattern enclosed in parentheses):</p> <pre><code>stage = \"stade (I{1,3}V?|[1234])\"\n</code></pre> <p>This will extract stage between 1 and 4</p> <p>We can add a second regex to try to capture if the cancer is in a metastasis stage or not:</p> <pre><code>metastase = \"(metasta)\"\n</code></pre>"},{"location":"pipelines/core/contextual-matcher/#c-the-complete-configuration","title":"c. The complete configuration","text":"<p>We can now put everything together:</p> <pre><code>cancer = dict(\n    source=\"Cancer solide\",\n    regex=regex,\n    terms=terms,\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=benign,\n        window=3,\n    ),\n    assign=[\n        dict(\n            name=\"stage\",\n            regex=stage,\n            window=(-10, 10),\n            replace_entity=False,\n            reduce_mode=None,\n        ),\n        dict(\n            name=\"metastase\",\n            regex=metastase,\n            window=10,\n            replace_entity=False,\n            reduce_mode=\"keep_last\",\n        ),\n    ],\n)\n</code></pre> <p>Here the configuration consists of a single dictionary. We might want to also include lymphoma in the matcher:</p> <pre><code>lymphome = dict(\n    source=\"Lymphome\",\n    regex=[\"lymphom\", \"lymphangio\"],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=[\"hodgkin\"],  # (1)\n        window=3,\n    ),\n)\n</code></pre> <ol> <li>We are excluding \"Lymphome de Hodgkin\" here</li> </ol> <p>In this case, the configuration can be concatenated in a list:</p> <pre><code>patterns = [cancer, lymphome]\n</code></pre>"},{"location":"pipelines/core/contextual-matcher/#available-parameters-for-more-flexibility","title":"Available parameters for more flexibility","text":"<p>3 main parameters can be used to refine how entities will be formed</p>"},{"location":"pipelines/core/contextual-matcher/#the-include_assigned-parameter","title":"The <code>include_assigned</code> parameter","text":"<p>Following the previous example, you might want your extracted entities to include, if found, the cancer stage and the metastasis status. This can be achieved by setting <code>include_assigned=True</code> in the pipe configuration.</p> <p>For instance, from the sentence \"Le patient a un cancer au stade 3\", the extracted entity will be:</p> <ul> <li>\"cancer\" if <code>include_assigned=False</code></li> <li>\"cancer au stade 3\" if <code>include_assigned=True</code></li> </ul>"},{"location":"pipelines/core/contextual-matcher/#the-reduce_mode-parameter","title":"The <code>reduce_mode</code> parameter","text":"<p>It may happen that an assignment matches more than once. For instance, in the (nonsensical) sentence \"Le patient a un cancer au stade 3 et au stade 4\", both \"stade 3\" and \"stade 4\" will be matched by the <code>stage</code> assign key. Depending on your use case, you may want to keep all the extractions, or just one.</p> <ul> <li>If <code>reduce_mode=None</code> (default), all extractions are kept in a list</li> <li>If <code>reduce_mode=\"keep_first\"</code>, only the extraction closest to the main matched entity will be kept (in this case, it would be \"stade 3\" since it is the closest to \"cancer\")</li> <li>If <code>reduce_mode==\"keep_last\"</code>, only the furthest extraction is kept.</li> </ul>"},{"location":"pipelines/core/contextual-matcher/#the-replace_entity-parameter","title":"The <code>replace_entity</code> parameter","text":"<p>This parameter can be se to <code>True</code> only for a single assign key per dictionary. This limitation comes from the purpose of this parameter: If set to <code>True</code>, the corresponding <code>assign</code> key will be returned as the entity, instead of the match itself. For clarity, let's take the same sentence \"Le patient a un cancer au stade 3\" as an example:</p> <ul> <li>if <code>replace_entity=True</code> in the <code>stage</code> assign key, then the extracted entity will be \"stade 3\" instead of \"cancer\"</li> <li>if <code>replace_entity=False</code> for every assign key, the returned entity will be, as expected, \"cancer\"</li> </ul> <p>Please notice that with <code>replace_entity</code> set to True, if the correponding assign key matches nothing, the entity will be discarded.</p>"},{"location":"pipelines/core/contextual-matcher/#examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nnlp.add_pipe(\"sentences\")\nnlp.add_pipe(\"normalizer\")\n\nnlp.add_pipe(\n    \"eds.contextual-matcher\",\n    name=\"Cancer\",\n    config=dict(\n        patterns=patterns,\n        label=\"cancer\",\n    ),\n)\n</code></pre> <p>Let us see what we can get from this pipeline with a few examples</p> Simple matchExclusion ruleExtracting additional infos <pre><code>txt = \"Le patient a eu un cancer il y a 5 ans\"\ndoc = nlp(txt)\nent = doc.ents[0]\n\nent.label_\n# Out: cancer\n\nent._.source\n# Out: Cancer solide\n\nent.text, ent.start, ent.end\n# Out: ('cancer', 5, 6)\n</code></pre> <p>Let us check that when a benign mention is present, the extraction is excluded:</p> <pre><code>txt = \"Le patient a eu un cancer relativement b\u00e9nin il y a 5 ans\"\ndoc = nlp(txt)\n\ndoc.ents\n# Out: ()\n</code></pre> <p>All informations extracted from the provided <code>assign</code> configuration can be found in the <code>assigned</code> attribute under the form of a dictionary:</p> <pre><code>txt = \"Le patient a eu un cancer de stade 3.\"\ndoc = nlp(txt)\n\ndoc.ents[0]._.assigned\n# Out: {'stage': '3'}\n</code></pre> <p>However, most of the configuration is provided in the <code>patterns</code> key, as a pattern dictionary or a list of pattern dictionaries</p>"},{"location":"pipelines/core/contextual-matcher/#the-pattern-dictionary","title":"The pattern dictionary","text":""},{"location":"pipelines/core/contextual-matcher/#description","title":"Description","text":"<p>A patterr is a nested dictionary with the following keys:</p> <code>source</code><code>regex</code><code>regex_attr</code><code>terms</code><code>exclude</code><code>assign</code> <p>A label describing the pattern</p> <p>A single Regex or a list of Regexes</p> <p>An attributes to overwrite the given <code>attr</code> when matching with Regexes.</p> <p>A single term or a list of terms (for exact matches)</p> <p>A dictionary (or list of dictionaries) to define exclusion rules. Exclusion rules are given as Regexes, and if a match is found in the surrounding context of an extraction, the extraction is removed. Each dictionary should have the following keys:</p> <code>window</code><code>regex</code> <p>Size of the context to use (in number of words). You can provide the window as:</p> <ul> <li>A positive integer, in this case the used context will be taken after the extraction</li> <li>A negative integer, in this case the used context will be taken before the extraction</li> <li>A tuple of integers <code>(start, end)</code>, in this case the used context will be the snippet from <code>start</code> tokens before the extraction to <code>end</code> tokens after the extraction</li> </ul> <p>A single Regex or a list of Regexes.</p> <p>A dictionary to refine the extraction. Similarily to the <code>exclude</code> key, you can provide a dictionary to use on the context before and after the extraction.</p> <code>name</code><code>window</code><code>regex</code><code>replace_entity</code><code>reduce_mode</code> <p>A name (string)</p> <p>Size of the context to use (in number of words). You can provide the window as:</p> <ul> <li>A positive integer, in this case the used context will be taken after the extraction</li> <li>A negative integer, in this case the used context will be taken before the extraction</li> <li>A tuple of integers <code>(start, end)</code>, in this case the used context will be the snippet from <code>start</code> tokens before the extraction to <code>end</code> tokens after the extraction</li> </ul> <p>A dictionary where keys are labels and values are Regexes with a single capturing group</p> <p>If set to <code>True</code>, the match from the corresponding assign key will be used as entity, instead of the main match. See this paragraph</p> <p>Set how multiple assign matches are handled. See the documentation of the <code>reduce_mode</code> parameter</p>"},{"location":"pipelines/core/contextual-matcher/#a-full-pattern-dictionary-example","title":"A full pattern dictionary example","text":"<pre><code>dict(\n    source=\"AVC\",\n    regex=[\n        \"accidents? vasculaires? cerebr\",\n    ],\n    terms=\"avc\",\n    regex_attr=\"NORM\",\n    exclude=[\n        dict(\n            regex=[\"service\"],\n            window=3,\n        ),\n        dict(\n            regex=[\" a \"],\n            window=-2,\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"neo\",\n            regex=r\"(neonatal)\",\n            expand_entity=True,\n            window=3,\n        ),\n        dict(\n            name=\"trans\",\n            regex=\"(transitoire)\",\n            expand_entity=True,\n            window=3,\n        ),\n        dict(\n            name=\"hemo\",\n            regex=r\"(hemorragique)\",\n            expand_entity=True,\n            window=3,\n        ),\n        dict(\n            name=\"risk\",\n            regex=r\"(risque)\",\n            expand_entity=False,\n            window=-3,\n        ),\n    ],\n)\n</code></pre>"},{"location":"pipelines/core/contextual-matcher/#edsnlp.pipelines.core.contextual_matcher.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>patterns</code> <p>The configuration dictionary</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> </p> <code>assign_as_span</code> <p>Whether to store eventual extractions defined via the <code>assign</code> key as Spans or as string</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>alignment_mode</code> <p>Overwrite alignment mode.</p> <p> TYPE: <code>str</code> DEFAULT: <code>expand</code> </p> <code>regex_flags</code> <p>RegExp flags to use when matching, filtering and assigning (See here)</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>include_assigned</code> <p>Whether to include (eventual) assign matches to the final entity</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>label_name</code> <p>Deprecated, use <code>label</code> instead. The label to assign to the matched entities</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>The label to assign to the matched entities</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p>"},{"location":"pipelines/core/contextual-matcher/#authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.matcher</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/core/endlines/","title":"Endlines","text":"<p>The <code>eds.endlines</code> component classifies newline characters as actual end of lines or mere spaces. In the latter case, the token is removed from the normalised document.</p> <p>Behind the scenes, it uses a <code>endlinesmodel</code> instance, which is an unsupervised algorithm based on the work of Zweigenbaum et al., 2016.</p> <ol><li><p><p>Zweigenbaum P., Grouin C. and Lavergne T., 2016. Une cat\\'egorisation de fins de lignes non-supervis\\'ee (End-of-line classification with no supervision).</p></p></li></ol>"},{"location":"pipelines/core/endlines/#edsnlp.pipelines.core.endlines.factory.create_component--training","title":"Training","text":"<pre><code>import spacy\nfrom edsnlp.pipelines.core.endlines.model import EndLinesModel\n\nnlp = spacy.blank(\"eds\")\n\ntexts = [\n\"\"\"\nLe patient est arriv\u00e9 hier soir.\nIl est accompagn\u00e9 par son fils\n\nANTECEDENTS\nIl a fait une TS en 2010\nFumeur, il est arret\u00e9 il a 5 mois\nChirurgie de coeur en 2011\nCONCLUSION\nIl doit prendre\nle medicament indiqu\u00e9 3 fois par jour. Revoir m\u00e9decin\ndans 1 mois.\nDIAGNOSTIC :\n\nAntecedents Familiaux:\n- 1. P\u00e8re avec diabete\n\"\"\",\n\"\"\"\nJ'aime le\nfromage...\n\"\"\",\n]\n\ndocs = list(nlp.pipe(texts))\n\n# Train and predict an EndLinesModel\nendlines = EndLinesModel(nlp=nlp)\n\ndf = endlines.fit_and_predict(docs)\ndf.head()\n\nPATH = \"/tmp/path_to_save\"\nendlines.save(PATH)\n</code></pre>"},{"location":"pipelines/core/endlines/#edsnlp.pipelines.core.endlines.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\nfrom spacy.tokens import Span\nfrom spacy import displacy\n\nnlp = spacy.blank(\"eds\")\n\nPATH = \"/tmp/path_to_save\"\nnlp.add_pipe(\"eds.endlines\", config=dict(model_path=PATH))\n\ndocs = list(nlp.pipe(texts))\n\ndoc_exemple = docs[1]\n\ndoc_exemple.ents = tuple(\n    Span(doc_exemple, token.i, token.i + 1, \"excluded\")\n    for token in doc_exemple\n    if token.tag_ == \"EXCLUDED\"\n)\n\ndisplacy.render(doc_exemple, style=\"ent\", options={\"colors\": {\"space\": \"red\"}})\n</code></pre>"},{"location":"pipelines/core/endlines/#edsnlp.pipelines.core.endlines.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.endlines</code> pipeline declares one extension, on both <code>Span</code> and <code>Token</code> objects. The <code>end_line</code> attribute is a boolean, set to <code>True</code> if the pipeline predicts that the new line is an end line character. Otherwise, it is set to <code>False</code> if the new line is classified as a space.</p> <p>The pipeline also sets the <code>excluded</code> custom attribute on newlines that are classified as spaces. It lets downstream matchers skip excluded tokens (see normalisation) for more detail.</p>"},{"location":"pipelines/core/endlines/#edsnlp.pipelines.core.endlines.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> DEFAULT: <code>eds.endlines</code> </p> <code>model_path</code> <p>Path to trained model. If None, it will use a default model</p> <p> TYPE: <code>Optional[Union[str, EndLinesModel]]</code> DEFAULT: <code>None</code> </p>"},{"location":"pipelines/core/endlines/#edsnlp.pipelines.core.endlines.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.endlines</code> pipeline was developed by AP-HP's Data Science team based on the work of Zweigenbaum et al., 2016.</p>"},{"location":"pipelines/core/matcher/","title":"Matcher","text":"<p>EDS-NLP simplifies the matching process by exposing a <code>eds.matcher</code> component that can match on terms or regular expressions.</p>"},{"location":"pipelines/core/matcher/#edsnlp.pipelines.core.matcher.factory.create_component--examples","title":"Examples","text":"<p>Let us redefine the pipeline :</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],  # (1)\n    patient=\"patient\",  # (2)\n)\n\nregex = dict(\n    covid=r\"coronavirus|covid[-\\s]?19|sars[-\\s]cov[-\\s]2\",  # (3)\n)\n\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=terms,\n        regex=regex,\n        attr=\"LOWER\",\n        term_matcher=\"exact\",\n        term_matcher_config={},\n    ),\n)\n</code></pre> <ol> <li>Every key in the <code>terms</code> dictionary is mapped to a concept.</li> <li>The <code>eds.matcher</code> pipeline expects a list of expressions, or a single expression.</li> <li>We can also define regular expression patterns.</li> </ol> <p>This snippet is complete, and should run as is.</p> <p>Patterns, be they <code>terms</code> or <code>regex</code>, are defined as dictionaries where keys become  the label of the extracted entities. Dictionary values are either a single  expression or a list of expressions that match the concept.</p>"},{"location":"pipelines/core/matcher/#edsnlp.pipelines.core.matcher.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.matcher</code> </p> <code>terms</code> <p>A dictionary of terms.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A dictionary of regular expressions.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>The default attribute to use for matching. Can be overridden using the <code>terms</code> and <code>regex</code> configurations.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p>You won't be able to match on newlines if this is enabled and the \"spaces\"/\"newline\" option of <code>eds.normalizer</code> is enabled (by default).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>exact</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher class</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>span_setter</code> <p>How to set the spans in the doc.</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p>"},{"location":"pipelines/core/matcher/#edsnlp.pipelines.core.matcher.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.matcher</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/core/normalizer/","title":"Normalisation","text":"<p>The normalisation scheme used by EDS-NLP adheres to the non-destructive doctrine. In other words,</p> <pre><code>nlp(text).text == text\n</code></pre> <p>is always true.</p> <p>To achieve this, the input text is never modified. Instead, our normalisation strategy focuses on two axes:</p> <ol> <li>Only the <code>NORM</code> and <code>tag_</code> attributes are modified by the <code>normalizer</code> pipeline ;</li> <li>Pipelines (eg the <code>pollution</code> pipeline) can mark tokens as excluded by setting the extension <code>Token.tag_</code> to <code>EXCLUDED</code> or as space by setting the extension <code>Token.tag_</code> to <code>SPACE</code>.    It enables downstream matchers to skip excluded tokens.</li> </ol> <p>The normaliser can act on the input text in five dimensions :</p> <ol> <li>Move the text to lowercase.</li> <li>Remove accents. We use a deterministic approach to avoid modifying the character-length of the text, which helps for RegEx matching.</li> <li>Normalize apostrophes and quotation marks, which are often coded using special characters.</li> <li>Detect spaces and new lines and mark them as such (to be skipped later)</li> <li>Detect tokens in pollutions patterns and mark them as such (to be skipped later)</li> </ol> <p>Note</p> <p>We recommend you also add an end-of-line classifier to remove excess new line characters (introduced by the PDF layout).</p> <p>We provide a <code>endlines</code> pipeline, which requires training an unsupervised model. Refer to the dedicated page for more information.</p>"},{"location":"pipelines/core/normalizer/#usage","title":"Usage","text":"<p>The normalisation is handled by the single <code>eds.normalizer</code> pipeline. The following code snippet is complete, and should run as is.</p> <pre><code>import spacy\nfrom edsnlp.matchers.utils import get_text\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\n\n# Notice the special character used for the apostrophe and the quotes\ntext = \"Le patient est admis \u00e0 l'h\u00f4pital le 23 ao\u00fbt 2021 pour une douleur \u02baaffreuse\u201d \u00e0 l`estomac.\"\n\ndoc = nlp(text)\n\nget_text(doc, attr=\"NORM\", ignore_excluded=False)\n# Out: le patient est admis a l'hopital le 23 aout 2021 pour une douleur \"affreuse\" a l'estomac.\n</code></pre>"},{"location":"pipelines/core/normalizer/#utilities","title":"Utilities","text":"<p>To simplify the use of the normalisation output, we provide the <code>get_text</code> utility function. It computes the textual representation for a <code>Span</code> or <code>Doc</code> object.</p> <p>Moreover, every span exposes a <code>normalized_variant</code> extension getter, which computes the normalised representation of an entity on the fly.</p>"},{"location":"pipelines/core/normalizer/#configuration","title":"Configuration","text":"<p>The pipeline can be configured using the following parameters :</p>"},{"location":"pipelines/core/normalizer/#edsnlp.pipelines.core.normalizer.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>lowercase</code> <p>Whether to remove case.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>accents</code> <p><code>Accents</code> configuration object</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p> <code>quotes</code> <p><code>Quotes</code> configuration object</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p> <code>spaces</code> <p><code>Spaces</code> configuration object</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p> <code>pollution</code> <p>Optional <code>Pollution</code> configuration object.</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p>"},{"location":"pipelines/core/normalizer/#pipelines","title":"Pipelines","text":"<p>Let's review each subcomponent.</p>"},{"location":"pipelines/core/normalizer/#lowercase","title":"Lowercase","text":"<p>The <code>eds.lowercase</code> pipeline transforms every token to lowercase. It is not configurable.</p> <p>Consider the following example :</p> <pre><code>import spacy\nfrom edsnlp.matchers.utils import get_text\n\nconfig = dict(\n    lowercase=True,\n    accents=False,\n    quotes=False,\n    spaces=False,\n    pollution=False,\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\", config=config)\n\ntext = \"Pneumopathie \u00e0 NBNbWbWbNbWbNBNbNbWbW `coronavirus'\"\n\ndoc = nlp(text)\n\nget_text(doc, attr=\"NORM\", ignore_excluded=False)\n# Out: pneumopathie \u00e0 nbnbwbwbnbwbnbnbnbwbw 'coronavirus'\n</code></pre>"},{"location":"pipelines/core/normalizer/#accents","title":"Accents","text":"<p>The <code>eds.accents</code> pipeline removes accents. To avoid edge cases, the component uses a specified list of accentuated characters and their unaccented representation, making it more predictable than using a library such as <code>unidecode</code>.</p> <p>Consider the following example :</p> <pre><code>import spacy\nfrom edsnlp.matchers.utils import get_text\n\nconfig = dict(\n    lowercase=False,\n    accents=True,\n    quotes=False,\n    spaces=False,\n    pollution=False,\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\", config=config)\n\ntext = \"Pneumopathie \u00e0 NBNbWbWbNbWbNBNbNbWbW `coronavirus'\"\n\ndoc = nlp(text)\n\nget_text(doc, attr=\"NORM\", ignore_excluded=False)\n# Out: Pneumopathie a NBNbWbWbNbWbNBNbNbWbW `coronavirus'\n</code></pre>"},{"location":"pipelines/core/normalizer/#apostrophes-and-quotation-marks","title":"Apostrophes and quotation marks","text":"<p>Apostrophes and quotation marks can be encoded using unpredictable special characters. The <code>eds.quotes</code> component transforms every such special character to <code>'</code> and <code>\"</code>, respectively.</p> <p>Consider the following example :</p> <pre><code>import spacy\nfrom edsnlp.matchers.utils import get_text\n\nconfig = dict(\n    lowercase=False,\n    accents=False,\n    quotes=True,\n    spaces=False,\n    pollution=False,\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\", config=config)\n\ntext = \"Pneumopathie \u00e0 NBNbWbWbNbWbNBNbNbWbW `coronavirus'\"\n\ndoc = nlp(text)\n\nget_text(doc, attr=\"NORM\", ignore_excluded=False)\n# Out: Pneumopathie \u00e0 NBNbWbWbNbWbNBNbNbWbW 'coronavirus'\n</code></pre>"},{"location":"pipelines/core/normalizer/#spaces","title":"Spaces","text":"<p>This is not truly a normalisation component, but this allows us to detect spaces tokens ahead of the other components and encode it as using the <code>tag_</code> attribute for fast matching.</p> <p>Tip</p> <p>This component and its <code>spaces</code> option should be enabled if you ever set   <code>ignore_space_tokens</code> parameter token to True in a downstream component.</p> <pre><code>import spacy\n\nconfig = dict(\n    lowercase=False,\n    accents=False,\n    quotes=False,\n    spaces=True,\n    pollution=False,\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\", config=config)\n\ndoc = nlp(\"Phrase    avec des espaces \\n et un retour \u00e0 la ligne\")\n[t.tag_ for t in doc]\n# Out: ['', 'SPACE', '', '', '', 'SPACE', '', '', '', '', '', '']\n</code></pre>"},{"location":"pipelines/core/normalizer/#pollution","title":"Pollution","text":"<p>The pollution pipeline uses a set of regular expressions to detect pollutions (irrelevant non-medical text that hinders text processing). Corresponding tokens are marked as excluded (by setting <code>Token._.excluded</code> to <code>True</code>), enabling the use of the phrase matcher.</p> <p>Consider the following example :</p> <pre><code>import spacy\nfrom edsnlp.matchers.utils import get_text\n\nconfig = dict(\n    lowercase=False,\n    accents=True,\n    quotes=False,\n    spaces=False,\n    pollution=True,\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\", config=config)\n\ntext = \"Pneumopathie \u00e0 NBNbWbWbNbWbNBNbNbWbW `coronavirus'\"\n\ndoc = nlp(text)\n\nget_text(doc, attr=\"NORM\", ignore_excluded=False)\n# Out: Pneumopathie a NBNbWbWbNbWbNBNbNbWbW `coronavirus'\n\nget_text(doc, attr=\"TEXT\", ignore_excluded=True)\n# Out: Pneumopathie \u00e0 `coronavirus'\n</code></pre> <p>This example above shows that the normalisation scheme works on two axes: non-destructive text modification and exclusion of tokens. The two are independent: a matcher can use the <code>NORM</code> attribute but keep excluded tokens, and conversely, match on <code>TEXT</code> while ignoring excluded tokens.</p> <p></p>"},{"location":"pipelines/core/normalizer/#types-of-pollution","title":"Types of pollution","text":"<p>Pollution can come in various forms in clinical texts. We provide a small set of possible pollutions patterns that can be enabled or disabled as needed.</p> <p>For instance, if we consider biology tables as pollution, we only need to instantiate the <code>normalizer</code> pipe as follows:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        pollution=dict(\n            biology=True,\n        ),\n    ),\n)\n</code></pre> Type Description Example Included by default <code>information</code> Footnote present in a lot of notes, providing information to the patient about the use of its data \"L'AP-HP collecte vos donn\u00e9es administratives \u00e0 des fins ...\" <code>True</code> <code>bars</code> Barcodes wrongly parsed as text \"...NBNbWbWbNbWbNBNbNbWbW...\" <code>True</code> <code>biology</code> Parsed biology results table. It often contains disease names that often leads to false positives with NER pipelines. \"...\u00a6UI/L \u00a620 \u00a6 \u00a6 \u00a620-70 Polyarthrite rhumato\u00efde Facteur rhumatoide \u00a6UI/mL \u00a6 \u00a6&lt;10 \u00a6 \u00a6 \u00a6 \u00a60-14...\" <code>False</code> <code>doctors</code> List of doctor names and specialities, often found in left-side note margins. Also source of potential false positives. \"... Dr ABC - Diab\u00e8te/Endocrino ...\" <code>True</code> <code>web</code> Webpages URL and email adresses. Also source of potential false positives. \"... www.vascularites.fr ...\" <code>True</code> <code>coding</code> Subsection containing ICD-10 codes along with their description. Also source of potential false positives. \"... (2) E112 + Oeil (2) E113 + Neuro (2) E114 D\u00e9mence (2) F03 MA (2) F001+G301 DCL G22+G301 Vasc (2) ...\" <code>False</code> <code>footer</code> Footer of new page \"2/2Pat : NOM Prenom le 2020/01/01 IPP 12345678 Intitul\u00e9 RCP : Urologie HMN le \" <code>True</code>"},{"location":"pipelines/core/normalizer/#custom-pollution","title":"Custom pollution","text":"<p>If you want to exclude specific patterns, you can provide them as a RegEx (or a list of Regexes). For instance, to consider text between \"AAA\" and \"ZZZ\" as pollution you might use:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        pollution=dict(\n            custom_pollution=r\"AAA.*ZZZ\",\n        ),\n    ),\n)\n</code></pre>"},{"location":"pipelines/core/normalizer/#authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.normalizer</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/core/overview/","title":"Core Components","text":"<p>This section deals with \"core\" functionalities offered by EDS-NLP:</p> <ul> <li>Generic matchers against regular expressions and list of terms</li> <li>Text cleaning</li> <li>Sentence boundaries detection</li> </ul>"},{"location":"pipelines/core/overview/#available-components","title":"Available components","text":"Component Description <code>eds.normalizer</code> Non-destructive input text normalisation <code>eds.sentences</code> Better sentence boundary detection <code>eds.matcher</code> A simple yet powerful entity extractor <code>eds.terminology</code> A simple yet powerful terminology matcher <code>eds.contextual_matcher</code> A conditional entity extractor <code>eds.endlines</code> An unsupervised model to classify each end line"},{"location":"pipelines/core/sentences/","title":"Sentences","text":"<p>The <code>eds.sentences</code> matcher provides an alternative to spaCy's default <code>sentencizer</code>, aiming to overcome some of its limitations.</p> <p>Indeed, the <code>sentencizer</code> merely looks at period characters to detect the end of a sentence, a strategy that often fails in a clinical note settings. Our <code>eds.sentences</code> component also classifies end-of-lines as sentence boundaries if the subsequent token begins with an uppercase character, leading to slightly better performances.</p> <p>Moreover, the <code>eds.sentences</code> component use the output of the <code>eds.normalizer</code> and <code>eds.endlines</code> output by default when these components are added to the pipeline.</p>"},{"location":"pipelines/core/sentences/#edsnlp.pipelines.core.sentences.factory.create_component--examples","title":"Examples","text":"EDS-NLPspaCy sentencizer <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n\ntext = \"\"\"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\nIl lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans.\"\n\"\"\"\n\ndoc = nlp(text)\n\nfor sentence in doc.sents:\n    print(\"&lt;s&gt;\", sentence, \"&lt;/s&gt;\")\n# Out: &lt;s&gt; Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\n# Out:  &lt;\\s&gt;\n# Out: &lt;s&gt; Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans. &lt;\\s&gt;\n</code></pre> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"sentencizer\")\n\ntext = \"\"\"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\"\nIl lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans.\n\"\"\"\n\ndoc = nlp(text)\n\nfor sentence in doc.sents:\n    print(\"&lt;s&gt;\", sentence, \"&lt;/s&gt;\")\n# Out: &lt;s&gt; Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\n# Out: Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans. &lt;\\s&gt;\n</code></pre> <p>Notice how EDS-NLP's implementation is more robust to ill-defined sentence endings.</p>"},{"location":"pipelines/core/sentences/#edsnlp.pipelines.core.sentences.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.sentences'</code> </p> <code>punct_chars</code> <p>Punctuation characters.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>use_endlines</code> <p>Whether to use endlines prediction.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires the upstream <code>eds.normalizer</code> pipe).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p>"},{"location":"pipelines/core/sentences/#edsnlp.pipelines.core.sentences.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.sentences</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/core/terminology/","title":"Terminology","text":"<p>EDS-NLP simplifies the terminology matching process by exposing a <code>eds.terminology</code> pipeline that can match on terms or regular expressions.</p> <p>The terminology matcher is very similar to the generic matcher, although the use case differs slightly. The generic matcher is designed to extract any entity, while the terminology matcher is specifically tailored towards high volume terminologies.</p> <p>There are some key differences:</p> <ol> <li>It labels every matched entity to the same value, provided to the pipeline</li> <li>The keys provided in the <code>regex</code> and <code>terms</code> dictionaries are used as the    <code>kb_id_</code> of the entity, which handles fine-grained labelling</li> </ol> <p>For instance, a terminology matcher could detect every drug mention under the top-level label <code>drug</code>, and link each individual mention to a given drug through its <code>kb_id_</code> attribute.</p> <ol></ol>"},{"location":"pipelines/core/terminology/#edsnlp.pipelines.core.terminology.factory.create_component--examples","title":"Examples","text":"<p>Let us redefine the pipeline :</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],  # (1)\n    flu=[\"grippe saisonni\u00e8re\"],  # (2)\n)\n\nregex = dict(\n    covid=r\"coronavirus|covid[-\\s]?19|sars[-\\s]cov[-\\s]2\",  # (3)\n)\n\nnlp.add_pipe(\n    \"eds.terminology\",\n    config=dict(\n        label=\"disease\",\n        terms=terms,\n        regex=regex,\n        attr=\"LOWER\",\n    ),\n)\n</code></pre> <ol> <li>Every key in the <code>terms</code> dictionary is mapped to a concept.</li> <li>The <code>eds.matcher</code> pipeline expects a list of expressions, or a single expression.</li> <li>We can also define regular expression patterns.</li> </ol> <p>This snippet is complete, and should run as is.</p>"},{"location":"pipelines/core/terminology/#edsnlp.pipelines.core.terminology.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>terms</code> <p>A dictionary of terms.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A dictionary of regular expressions.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>The default attribute to use for matching. Can be overridden using the <code>terms</code> and <code>regex</code> configurations.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>exact</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher class</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p> <p>Patterns, be they <code>terms</code> or <code>regex</code>, are defined as dictionaries where keys become the <code>kb_id_</code> of the extracted entities. Dictionary values are either a single expression or a list of expressions that match the concept (see example).</p>"},{"location":"pipelines/core/terminology/#edsnlp.pipelines.core.terminology.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.terminology</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/misc/consultation-dates/","title":"Consultation dates","text":"<p>The <code>eds.consultation-dates</code> matcher consists of two main parts:</p> <ul> <li>A matcher which finds mentions of consultation events (more details below)</li> <li>A date parser (see the corresponding pipe) that links a date to those events</li> </ul>"},{"location":"pipelines/misc/consultation-dates/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--examples","title":"Examples","text":"<p>Note</p> <p>The matcher has been built to run on consultation notes (<code>CR-CONS</code> at APHP), so please filter accordingly before proceeding.</p> <pre><code>import spacy\n\n# HIHIHI\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        lowercase=True,\n        accents=True,\n        quotes=True,\n        pollution=False,\n    ),\n)\nnlp.add_pipe(\"eds.consultation_dates\")\n\ntext = \"\"\"\nXXX\nObjet : Compte-Rendu de Consultation du 03/10/2018.\nXXX\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans[\"consultation_dates\"]\n# Out: [Consultation du 03/10/2018]\n\ndoc.spans[\"consultation_dates\"][0]._.consultation_date.to_datetime()\n# Out: DateTime(2018, 10, 3, 0, 0, 0, tzinfo=Timezone('Europe/Paris'))\n</code></pre>"},{"location":"pipelines/misc/consultation-dates/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.consultation_dates</code> pipeline declares one extension on the <code>Span</code> object: the <code>consultation_date</code> attribute, which is a Python <code>datetime</code> object.</p>"},{"location":"pipelines/misc/consultation-dates/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>Language pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>consultation_mention</code> <p>List of RegEx for consultation mentions.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains terms directly referring to consultations, such as \"Consultation du...\" or \"Compte rendu du...\". This list is the only one enabled by default since it is fairly precise and not error-prone.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>True</code> </p> <code>town_mention</code> <p>List of RegEx for all AP-HP hospitals' towns mentions.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains the towns of each AP-HP's hospital. Its goal is to fetch dates mentioned as \"Paris, le 13 d\u00e9cembre 2015\". It has a high recall but poor precision, since those dates can often be dates of letter redaction instead of consultation dates.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>False</code> </p> <code>document_date_mention</code> <p>List of RegEx for document date.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains expressions mentioning the date of creation/edition of a document, such as \"Date du rapport: 13/12/2015\" or \"Sign\u00e9 le 13/12/2015\". Like <code>town_mention</code> patterns, it has a high recall but is prone to errors since document date and consultation date aren't necessary similar.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/misc/consultation-dates/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.consultation_dates</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/misc/dates/","title":"Dates","text":"<p>The <code>eds.dates</code> matcher detects and normalize dates within a medical document. We use simple regular expressions to extract date mentions.</p>"},{"location":"pipelines/misc/dates/#edsnlp.pipelines.misc.dates.factory.create_component--scope","title":"Scope","text":"<p>The <code>eds.dates</code> pipeline finds absolute (eg <code>23/08/2021</code>) and relative (eg <code>hier</code>, <code>la semaine derni\u00e8re</code>) dates alike. It also handles mentions of duration.</p> Type Example <code>absolute</code> <code>3 mai</code>, <code>03/05/2020</code> <code>relative</code> <code>hier</code>, <code>la semaine derni\u00e8re</code> <code>duration</code> <code>pendant quatre jours</code> <p>See the tutorial for a presentation of a full pipeline featuring the <code>eds.dates</code> component.</p>"},{"location":"pipelines/misc/dates/#edsnlp.pipelines.misc.dates.factory.create_component--usage","title":"Usage","text":"<pre><code>import spacy\n\nimport pendulum\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.dates\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac. \"\n    \"Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a un an pendant une semaine. \"\n    \"Il a \u00e9t\u00e9 diagnostiqu\u00e9 en mai 1995.\"\n)\n\ndoc = nlp(text)\n\ndates = doc.spans[\"dates\"]\ndates\n# Out: [23 ao\u00fbt 2021, il y a un an, mai 1995]\n\ndates[0]._.date.to_datetime()\n# Out: 2021-08-23T00:00:00+02:00\n\ndates[1]._.date.to_datetime()\n# Out: None\n\nnote_datetime = pendulum.datetime(2021, 8, 27, tz=\"Europe/Paris\")\n\ndates[1]._.date.to_datetime(note_datetime=note_datetime)\n# Out: 2020-08-27T00:00:00+02:00\n\ndate_2_output = dates[2]._.date.to_datetime(\n    note_datetime=note_datetime,\n    infer_from_context=True,\n    tz=\"Europe/Paris\",\n    default_day=15,\n)\ndate_2_output\n# Out: 1995-05-15T00:00:00+02:00\n\ndoc.spans[\"durations\"]\n# Out: [pendant une semaine]\n</code></pre>"},{"location":"pipelines/misc/dates/#edsnlp.pipelines.misc.dates.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.dates</code> pipeline declares two extensions on the <code>Span</code> object:</p> <ul> <li>the <code>span._.date</code> attribute of a date contains a parsed version of the date.</li> <li>the <code>span._.duration</code> attribute of a duration contains a parsed version of the   duration.</li> </ul> <p>As with other components, you can use the <code>span._.value</code> attribute to get either the parsed date or the duration depending on the span.</p>"},{"location":"pipelines/misc/dates/#edsnlp.pipelines.misc.dates.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the pipeline component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.dates</code> </p> <code>absolute</code> <p>List of regular expressions for absolute dates.</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>relative</code> <p>List of regular expressions for relative dates (eg <code>hier</code>, <code>la semaine prochaine</code>).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>duration</code> <p>List of regular expressions for durations (eg <code>pendant trois mois</code>).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>false_positive</code> <p>List of regular expressions for false positive (eg phone numbers, etc).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Where to look for dates in the doc. By default, look in the whole doc. You can combine this with the <code>merge_mode</code> argument for interesting results.</p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>merge_mode</code> <p>How to merge matched dates with the spans from <code>span_getter</code>, if given:</p> <ul> <li><code>intersect</code>: return only the matches that fall in the <code>span_getter</code> spans</li> <li><code>align</code>: if a date overlaps a span from <code>span_getter</code> (e.g. a date extracted   by a machine learning model), return the <code>span_getter</code> span instead, and   assign all the parsed information (<code>._.date</code> / <code>._.duration</code>) to it. Otherwise   don't return the date.</li> </ul> <p> TYPE: <code>Literal['intersect', 'align']</code> DEFAULT: <code>intersect</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> and <code>merge_mode</code> instead. Whether to look on dates in the whole document or in specific sentences:</p> <ul> <li>If <code>True</code>: Only look in the sentences of each entity in doc.ents</li> <li>If False: Look in the whole document</li> <li>If given a string <code>key</code> or list of string: Only look in the sentences of   each entity in <code>doc.spans[key]</code></li> </ul> <p> TYPE: <code>Union[bool, str, Iterable[str]]</code> DEFAULT: <code>False</code> </p> <code>detect_periods</code> <p>Whether to detect periods (experimental)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>detect_time</code> <p>Whether to detect time inside dates</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>period_proximity_threshold</code> <p>Max number of words between two dates to extract a period.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>as_ents</code> <p>Deprecated, use span_setter instead. Whether to treat dates as entities</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>spaCy attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>LOWER</code> </p> <code>date_label</code> <p>Label to use for dates</p> <p> TYPE: <code>str</code> DEFAULT: <code>date</code> </p> <code>duration_label</code> <p>Label to use for durations</p> <p> TYPE: <code>str</code> DEFAULT: <code>duration</code> </p> <code>period_label</code> <p>Label to use for periods</p> <p> TYPE: <code>str</code> DEFAULT: <code>period</code> </p> <code>span_setter</code> <p>How to set matches in the doc.</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'dates': ['date'], 'durations': ['duration'], ...</code> </p>"},{"location":"pipelines/misc/dates/#edsnlp.pipelines.misc.dates.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.dates</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/misc/measurements/","title":"Measurements","text":"<p>The <code>eds.measurements</code> matcher detects and normalizes numerical measurements within a medical document.</p> <p>Warning</p> <p>The <code>measurements</code> pipeline is still in active development and has not been rigorously validated. If you come across a measurement expression that goes undetected, please file an issue !</p>"},{"location":"pipelines/misc/measurements/#edsnlp.pipelines.misc.measurements.factory.create_component--scope","title":"Scope","text":"<p>The <code>eds.measurements</code> matcher can extract simple (e.g. <code>3cm</code>) measurements. It can also detect elliptic enumerations (eg <code>32, 33 et 34kg</code>) of measurements of the same type and split the measurements accordingly.</p> <p>The normalized value can then be accessed via the <code>span._.{measure_name}</code> attribute, for instance <code>span._.size</code> or <code>span._.weight</code> and be converted on the fly to a desired unit. Like for other components, the <code>span._.value</code> extension can also be used to access the normalized value for any measurement span.</p> <p>The current matcher annotates the following measurements out of the box:</p> Measurement name Example <code>size</code> <code>1m50</code>, <code>1.50m</code> <code>weight</code> <code>12kg</code>, <code>1kg300</code> <code>bmi</code> <code>BMI: 24</code>, <code>24 kg.m-2</code> <code>volume</code> <code>2 cac</code>, <code>8ml</code>"},{"location":"pipelines/misc/measurements/#edsnlp.pipelines.misc.measurements.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.measurements\",\n    config=dict(\n        measurements=[\"size\", \"weight\", \"bmi\"],\n        extract_ranges=True,\n    ),\n)\n\ntext = \"\"\"\nLe patient est admis hier, fait 1m78 pour 76kg.\nLes deux nodules b\u00e9nins sont larges de 1,2 et 2.4mm.\nBMI: 24.\n\nLe nodule fait entre 1 et 1.5 cm\n\"\"\"\n\ndoc = nlp(text)\n\nmeasurements = doc.spans[\"measurements\"]\n\nmeasurements\n# Out: [1m78, 76kg, 1,2, 2.4mm, 24, entre 1 et 1.5 cm]\n\nmeasurements[0]\n# Out: 1m78\n\nstr(measurements[0]._.size), str(measurements[0]._.value)\n# Out: ('1.78 m', '1.78 m')\n\nmeasurements[0]._.value.cm\n# Out: 178.0\n\nmeasurements[2]\n# Out: 1,2\n\nstr(measurements[2]._.value)\n# Out: '1.2 mm'\n\nstr(measurements[2]._.value.mm)\n# Out: 1.2\n\nmeasurements[4]\n# Out: 24\n\nstr(measurements[4]._.value)\n# Out: '24 kg_per_m2'\n\nstr(measurements[4]._.value.kg_per_m2)\n# Out: 24\n\nstr(measurements[5]._.value)\n# Out: 1-1.5 cm\n</code></pre> <p>To extract all sizes in centimeters, and average range measurements, you can use the following snippet:</p> <pre><code>sizes = [\n    sum(item.cm for item in m._.value) / len(m._.value)\n    for m in doc.spans[\"measurements\"]\n    if m.label_ == \"size\"\n]\nsizes\n# Out: [178.0, 0.12, 0.24, 1.25]\n</code></pre>"},{"location":"pipelines/misc/measurements/#edsnlp.pipelines.misc.measurements.factory.create_component--customization","title":"Customization","text":"<p>You can declare custom measurements by altering the patterns:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.measurements\",\n    config=dict(\n        measurements={\n            \"my_custom_surface_measurement\": {\n                # This measurement unit is homogenous to square meters\n                \"unit\": \"m2\",\n                # Handle cases like \"surface: 1.8\" (implied m2),\n                # vs \"surface: 50\" (implied cm2)\n                \"unitless_patterns\": [\n                    {\n                        \"terms\": [\"surface\", \"aire\"],\n                        \"ranges\": [\n                            {\"unit\": \"m2\", \"min\": 0, \"max\": 9},\n                            {\"unit\": \"cm2\", \"min\": 10, \"max\": 100},\n                        ],\n                    }\n                ],\n            },\n        }\n    ),\n)\n</code></pre>"},{"location":"pipelines/misc/measurements/#edsnlp.pipelines.misc.measurements.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.measurements</code> pipeline declares its extensions dynamically, depending on the <code>measurements</code> parameter: each measurement gets its own extension, and is assigned to a different span group.</p>"},{"location":"pipelines/misc/measurements/#edsnlp.pipelines.misc.measurements.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.measurements</code> </p> <code>measurements</code> <p>A mapping from measure names to MsrConfig Each measure's configuration has the following shape: <pre><code>{\n  # the unit (e.g. \"kg\"),\n  \"unit\": str,\n  \"unitless_patterns\": {\n    # preceding trigger terms\n    \"terms\": List[str],\n    # unitless ranges -&gt; unit patterns\n    \"ranges\": List[\n      {\"min\": int, \"max\": int, \"unit\": str},\n      {\"min\": int, \"unit\": str},\n      ...,\n    ],\n    ...\n  }\n}\n</code></pre></p> <p> TYPE: <code>Union[str, List[Union[str, MsrConfig]], Dict[str, MsrConfig]]</code> DEFAULT: <code>['weight', 'size', 'bmi', 'volume']</code> </p> <code>number_terms</code> <p>A mapping of numbers to their lexical variants</p> <p> TYPE: <code>Dict[str, List[str]]</code> DEFAULT: <code>{'0.125': ['\u215b'], '0.16666666': ['\u2159'], '0.2': ['...</code> </p> <code>stopwords</code> <p>A list of stopwords that do not matter when placed between a unitless trigger and a number</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['par', 'sur', 'de', 'a', ',', 'et']</code> </p> <code>unit_divisors</code> <p>A list of terms used to divide two units (like: m / s)</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['/', 'par']</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>ignore_excluded</code> <p>Whether to exclude pollution patterns when matching in the text</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>compose_units</code> <p>Whether to compose units (like \"m/s\" or \"m.s-1\")</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extract_ranges</code> <p>Whether to extract ranges (like \"entre 1 et 2 cm\")</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>range_patterns</code> <p>A list of \"{FROM} xx {TO} yy\" patterns to match range measurements</p> <p> TYPE: <code>List[Tuple[Optional[str], Optional[str]]]</code> DEFAULT: <code>[('De', '\u00e0'), ('De', 'a'), ('de', '\u00e0'), ('de', ...</code> </p> <code>after_snippet_limit</code> <p>Maximum word distance after to link a part of a measurement after its number</p> <p> TYPE: <code>int</code> DEFAULT: <code>6</code> </p> <code>before_snippet_limit</code> <p>Maximum word distance after to link a part of a measurement before its number</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>span_setter</code> <p>How to set the spans in the document. By default, each measurement will be assigned to its own span group (using either the \"name\" field of the config, or the key if you passed a dict), and to the \"measurements\" group.</p> <p> TYPE: <code>Optional[SpanSetterArg]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Where to look for measurements in the doc. By default, look in the whole doc. You can combine this with the <code>merge_mode</code> argument for interesting results.</p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>merge_mode</code> <p>How to merge matches with the spans from <code>span_getter</code>, if given:</p> <ul> <li><code>intersect</code>: return only the matches that fall in the <code>span_getter</code> spans</li> <li><code>align</code>: if a match overlaps a span from <code>span_getter</code> (e.g. a match   extracted by a machine learning model), return the <code>span_getter</code> span   instead, and assign all the parsed information (<code>._.date</code> / <code>._.duration</code>)   to it. Otherwise, don't return the date.</li> </ul> <p> TYPE: <code>Literal['intersect', 'align']</code> DEFAULT: <code>intersect</code> </p>"},{"location":"pipelines/misc/measurements/#edsnlp.pipelines.misc.measurements.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.measurements</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/misc/overview/","title":"Miscellaneous","text":"<p>This section regroups components that extract information that can be used by other components, but have little medical value in itself.</p> <p>For instance, the date detection and normalisation pipeline falls in this category.</p>"},{"location":"pipelines/misc/overview/#available-components","title":"Available components","text":"Component Description <code>eds.dates</code> Date extraction and normalisation <code>eds.consultation_dates</code> Identify consultation dates <code>eds.measurements</code> Measure extraction and normalisation <code>eds.sections</code> Section detection <code>eds.reason</code> Rule-based hospitalisation reason detection <code>eds.tables</code> Tables detection"},{"location":"pipelines/misc/reason/","title":"Reasons","text":"<p>The <code>eds.reason</code> matcher uses a rule-based algorithm to detect spans that relate to the reason of the hospitalisation. It was designed at AP-HP's EDS.</p>"},{"location":"pipelines/misc/reason/#edsnlp.pipelines.misc.reason.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and looks for spans of hospitalisation reasons. It is complete and can be run as is.</p> <pre><code>import spacy\n\ntext = \"\"\"COMPTE RENDU D'HOSPITALISATION du 11/07/2018 au 12/07/2018\nMOTIF D'HOSPITALISATION\nMonsieur Dupont Jean Michel, de sexe masculin, \u00e2g\u00e9e de 39 ans, n\u00e9e le 23/11/1978,\na \u00e9t\u00e9 hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nANT\u00c9C\u00c9DENTS\nAnt\u00e9c\u00e9dents m\u00e9dicaux :\nPremier \u00e9pisode d'asthme en mai 2018.\"\"\"\n\nnlp = spacy.blank(\"eds\")\n\n# Extraction of entities\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=dict(\n            respiratoire=[\n                \"asthmatique\",\n                \"asthme\",\n                \"toux\",\n            ]\n        )\n    ),\n)\n\n\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.reason\", config=dict(use_sections=True))\ndoc = nlp(text)\n\nreason = doc.spans[\"reasons\"][0]\nreason\n# Out: hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nreason._.is_reason\n# Out: True\n\nentities = reason._.ents_reason\nentities\n# Out: [asthme]\n\nentities[0].label_\n# Out: 'respiratoire'\n\nent = entities[0]\nent._.is_reason\n# Out: True\n</code></pre>"},{"location":"pipelines/misc/reason/#edsnlp.pipelines.misc.reason.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.reason</code> pipeline adds the key <code>reasons</code> to <code>doc.spans</code> and declares one extension, on the <code>Span</code> objects called <code>ents_reason</code>.</p> <p>The <code>ents_reason</code> extension is a list of named entities that overlap the <code>Span</code>, typically entities found in upstream components like <code>matcher</code>.</p> <p>It also declares the boolean extension <code>is_reason</code>. This extension is set to True for the Reason Spans but also for the entities that overlap the reason span.</p>"},{"location":"pipelines/misc/reason/#edsnlp.pipelines.misc.reason.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.reason</code> </p> <code>reasons</code> <p>Reason patterns</p> <p> TYPE: <code>Dict[str, Union[List[str], str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>Default token attribute to use to build the text to match on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>use_sections</code> <p>Whether or not use the <code>sections</code> matcher to improve results.</p> <p> TYPE: <code>(bool)</code> DEFAULT: <code>False</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/misc/reason/#edsnlp.pipelines.misc.reason.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.reason</code> matcher was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/misc/sections/","title":"Sections","text":"<p>The <code>eds.sections</code> component extracts section titles from clinical documents. A \"section\" is then defined as the span of text between two titles.</p> <p>Here is the list of sections that are currently targeted :</p> <ul> <li><code>allergies</code></li> <li><code>ant\u00e9c\u00e9dents</code></li> <li><code>ant\u00e9c\u00e9dents familiaux</code></li> <li><code>traitements entr\u00e9e</code></li> <li><code>conclusion</code></li> <li><code>conclusion entr\u00e9e</code></li> <li><code>habitus</code></li> <li><code>correspondants</code></li> <li><code>diagnostic</code></li> <li><code>donn\u00e9es biom\u00e9triques entr\u00e9e</code></li> <li><code>examens</code></li> <li><code>examens compl\u00e9mentaires</code></li> <li><code>facteurs de risques</code></li> <li><code>histoire de la maladie</code></li> <li><code>actes</code></li> <li><code>motif</code></li> <li><code>prescriptions</code></li> <li><code>traitements sortie</code></li> <li><code>evolution</code></li> <li><code>modalites sortie</code></li> <li><code>vaccinations</code></li> <li><code>introduction</code></li> </ul> <p>Remarks :</p> <ul> <li>section <code>introduction</code> corresponds to the span of text between the header   \"COMPTE RENDU D'HOSPITALISATION\" (usually denoting the beginning of the document)   and the title of the following detected section</li> <li>this matcher works well for hospitalization summaries (CRH), but not necessarily   for all types of documents (in particular for emergency or scan summaries   CR-IMAGERIE)</li> </ul> <p>Experimental</p> <p>Should you rely on <code>eds.sections</code> for critical downstream tasks, make sure to validate the results to make sure that the component works in your case.</p>"},{"location":"pipelines/misc/sections/#edsnlp.pipelines.misc.sections.factory.create_component--examples","title":"Examples","text":"<p>The following snippet detects section titles. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\n\ntext = \"\"\"\nCRU du 10/09/2021\nMotif :\nPatient admis pour suspicion de COVID\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans[\"section_titles\"]\n# Out: [Motif]\n</code></pre>"},{"location":"pipelines/misc/sections/#edsnlp.pipelines.misc.sections.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.sections</code> matcher adds two fields to the <code>doc.spans</code> attribute :</p> <ol> <li>The <code>section_titles</code> key contains the list of all section titles extracted using    the list declared in the <code>terms.py</code> module.</li> <li>The <code>sections</code> key contains a list of sections, ie spans of text between two    section titles (or the last title and the end of the document).</li> </ol> <p>If the document has entities before calling this matcher an attribute <code>section</code> is added to each entity.</p>"},{"location":"pipelines/misc/sections/#edsnlp.pipelines.misc.sections.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>sections</code> <p>Dictionary of terms to look for.</p> <p> TYPE: <code>Dict[str, List[str]]</code> DEFAULT: <code>{'allergies': ['allergies'], 'ant\u00e9c\u00e9dents': ['a...</code> </p> <code>attr</code> <p>Default attribute to match on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>add_patterns</code> <p>Whether add update patterns to match start / end of lines</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"pipelines/misc/sections/#edsnlp.pipelines.misc.sections.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.sections</code> matcher was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/misc/tables/","title":"Tables","text":"<p>The <code>eds.tables</code> matcher detects tables in a documents.</p>"},{"location":"pipelines/misc/tables/#edsnlp.pipelines.misc.tables.factory.create_component--examples","title":"Examples","text":"<p><pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.tables\")\n\ntext = \"\"\"\nSERVICE\nMEDECINE INTENSIVE \u2013\nREANIMATION\nR\u00e9animation / Surveillance Continue\nM\u00e9dicale\n\nCOMPTE RENDU D'HOSPITALISATION du 05/06/2020 au 10/06/2020\nMadame DUPONT Marie, n\u00e9e le 16/05/1900, \u00e2g\u00e9e de 20 ans, a \u00e9t\u00e9 hospitalis\u00e9e en\nr\u00e9animation du 05/06/1920 au 10/06/1920 pour intoxication m\u00e9dicamenteuse volontaire.\n\nExamens compl\u00e9mentaires\nH\u00e9matologie\nNum\u00e9ration\nLeucocytes \u00a6x10*9/L \u00a64.97 \u00a64.09-11\nH\u00e9maties \u00a6x10*12/L\u00a64.68 \u00a64.53-5.79\nH\u00e9moglobine \u00a6g/dL \u00a614.8 \u00a613.4-16.7\nH\u00e9matocrite \u00a6% \u00a644.2 \u00a639.2-48.6\nVGM \u00a6fL \u00a694.4 + \u00a679.6-94\nTCMH \u00a6pg \u00a631.6 \u00a627.3-32.8\nCCMH \u00a6g/dL \u00a633.5 \u00a632.4-36.3\nPlaquettes \u00a6x10*9/L \u00a6191 \u00a6172-398\nVMP \u00a6fL \u00a611.5 + \u00a67.4-10.8\n\nSur le plan neurologique : Devant la persistance d'une confusion \u00e0 distance de\nl'intoxication au\n...\n\n2/2Pat : &lt;NOM&gt; &lt;Prenom&gt;|F |&lt;date&gt; | &lt;ipp&gt; |Intitul\u00e9 RCP\n\"\"\"\n\ndoc = nlp(text)\n\n# A table span\ntable = doc.spans[\"tables\"][0]\n\n# Leucocytes \u00a6x10*9/L \u00a64.97 \u00a64.09-11\n# H\u00e9maties \u00a6x10*12/L\u00a64.68 \u00a64.53-5.79\n# H\u00e9moglobine \u00a6g/dL \u00a614.8 \u00a613.4-16.7\n# H\u00e9matocrite \u00a6% \u00a644.2 \u00a639.2-48.6\n# VGM \u00a6fL \u00a694.4 + \u00a679.6-94\n# TCMH \u00a6pg \u00a631.6 \u00a627.3-32.8\n# CCMH \u00a6g/dL \u00a633.5 \u00a632.4-36.3\n# Plaquettes \u00a6x10*9/L \u00a6191 \u00a6172-398\n# VMP \u00a6fL \u00a611.5 + \u00a67.4-10.8\n\n# Convert span to Pandas table\ndf = table._.to_pd_table()\ntype(df)\n# Out: pandas.core.frame.DataFrame\n</code></pre> The pandas DataFrame:</p> 0 1 2 3 0 Leucocytes x10*9/L 4.97 4.09-11 1 H\u00e9maties x10*12/L 4.68 4.53-5.79 2 H\u00e9moglobine g/dL 14.8 13.4-16.7 3 H\u00e9matocrite % 44.2 39.2-48.6 4 VGM fL 94.4 + 79.6-94 5 TCMH pg 31.6 27.3-32.8 6 CCMH g/dL 33.5 32.4-36.3 7 Plaquettes x10*9/L 191 172-398 8 VMP fL 11.5 + 7.4-10.8"},{"location":"pipelines/misc/tables/#edsnlp.pipelines.misc.tables.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.tables</code> pipeline declares the <code>span._.to_pd_table()</code> Span extension. This function returns a parsed pandas version of the table.</p>"},{"location":"pipelines/misc/tables/#edsnlp.pipelines.misc.tables.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.tables</code> </p> <code>tables_pattern</code> <p>The regex pattern to identify tables. The key of dictionary should be <code>tables</code></p> <p> TYPE: <code>Optional[Dict[str, str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr'. We can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"pipelines/misc/tables/#edsnlp.pipelines.misc.tables.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.tables</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/ner/adicap/","title":"Adicap","text":"<p>The <code>eds.adicap</code> pipeline component matches the ADICAP codes. It was developped to run on anapathology reports.</p> <p>Document type</p> <p>It was developped to work on anapathology reports. We recommend also to use the <code>eds</code> language (<code>spacy.blank(\"eds\")</code>)</p> <p>The compulsory characters of the ADICAP code are identified and decoded. These characters represent the following attributes:</p> Field [en] Field [fr] Attribute Sampling mode Mode de prelevement sampling_mode Technic Type de technique technic Organ and regions Appareils, organes et r\u00e9gions organ Pathology Pathologie g\u00e9n\u00e9rale pathology Pathology type Type de la pathologie pathology_type Behaviour type Type de comportement behaviour_type <p>The pathology field takes 4 different values corresponding to the 4 possible interpretations of the ADICAP code, which are : \"PATHOLOGIE G\u00c9N\u00c9RALE NON TUMORALE\", \"PATHOLOGIE TUMORALE\", \"PATHOLOGIE PARTICULIERE DES ORGANES\" and \"CYTOPATHOLOGIE\".</p> <p>Depending on the pathology value the behaviour type meaning changes, when the pathology is tumoral then it describes the malignancy of the tumor.</p> <p>For further details about the ADICAP code follow this link.</p> <ol><li><p><p>sant\u00e9 A., 2019. Th\u00e9saurus de la codification ADICAP - Index raisonn\u00e9 des l\u00e9sions.</p></p></li></ol>"},{"location":"pipelines/ner/adicap/#edsnlp.pipelines.ner.adicap.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.adicap\")\n\ntext = \"\"\"\nCOMPTE RENDU D\u2019EXAMEN\n\nAnt\u00e9riorit\u00e9(s) :  NEANT\n\n\nRenseignements cliniques :\nContexte d'exploration d'un carcinome canalaire infiltrant du quadrant sup\u00e9ro-\nexterne du sein droit. La l\u00e9sion biopsi\u00e9e ce jour est situ\u00e9e \u00e0 5,5 cm de la l\u00e9sion\ndu quadrant sup\u00e9ro-externe, \u00e0 l'union des quadrants inf\u00e9rieurs.\n\n\nMacrobiopsie 10G sur une zone de prise de contraste focale \u00e0 l'union des quadrants\ninf\u00e9rieurs du sein droit, mesurant 4 mm, class\u00e9e ACR4\n\n14 fragments ont \u00e9t\u00e9 communiqu\u00e9s fix\u00e9s en formol (lame n\u00b0 1a et lame n\u00b0 1b) . Il\nn'y a pas eu d'\u00e9chantillon congel\u00e9. Ces fragments ont \u00e9t\u00e9 inclus en paraffine en\ntotalit\u00e9 et coup\u00e9s sur plusieurs niveaux.\nHistologiquement, il s'agit d'un parenchyme mammaire fibroadipeux parfois\nl\u00e9g\u00e8rement dystrophique avec quelques petits kystes. Il n'y a pas d'hyperplasie\n\u00e9pith\u00e9liale, pas d'atypie, pas de prolif\u00e9ration tumorale. On note quelques\nsuffusions h\u00e9morragiques focales.\n\nConclusion :\nL\u00e9gers remaniements dystrophiques \u00e0 l'union des quadrants inf\u00e9rieurs du sein droit.\nAbsence d'atypies ou de prolif\u00e9ration tumorale.\n\nCodification :   BHGS0040\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (BHGS0040,)\n\nent = doc.ents[0]\n\nent.label_\n# Out: adicap\n\nent._.adicap.dict()\n# Out: {'code': 'BHGS0040',\n# 'sampling_mode': 'BIOPSIE CHIRURGICALE',\n# 'technic': 'HISTOLOGIE ET CYTOLOGIE PAR INCLUSION',\n# 'organ': \"SEIN (\u00c9GALEMENT UTILIS\u00c9 CHEZ L'HOMME)\",\n# 'pathology': 'PATHOLOGIE G\u00c9N\u00c9RALE NON TUMORALE',\n# 'pathology_type': 'ETAT SUBNORMAL - LESION MINEURE',\n# 'behaviour_type': 'CARACTERES GENERAUX'}\n</code></pre>"},{"location":"pipelines/ner/adicap/#edsnlp.pipelines.ner.adicap.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.adicap</code> </p> <code>pattern</code> <p>The regex pattern to use for matching ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>([A-Z]\\.?[A-Z]\\.?[A-Z]{2}\\.?(?:\\d{4}|\\d{4}|[A-Z...</code> </p> <code>prefix</code> <p>The regex pattern to use for matching the prefix before ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>(?i)(codification|adicap)</code> </p> <code>window</code> <p>Number of tokens to look for prefix. It will never go further the start of the sentence</p> <p> TYPE: <code>int</code> DEFAULT: <code>500</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>adicap</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'adicap': True}</code> </p>"},{"location":"pipelines/ner/adicap/#edsnlp.pipelines.ner.adicap.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.adicap</code> pipeline was developed by AP-HP's Data Science team. The codes were downloaded from the website of 'Agence du num\u00e9rique en sant\u00e9' (\"Th\u00e9saurus de la codification ADICAP - Index raisonn\u00e9 des l\u00e9sions\", sant\u00e9, 2019)</p>"},{"location":"pipelines/ner/cim10/","title":"CIM10","text":"<p>The <code>eds.cim10</code> pipeline component extract terms from documents using the CIM10 (French-language ICD) terminology as a reference.</p> <p>Very low recall</p> <p>When using the <code>exact</code> matching mode, this component has a very poor recall performance. We can use the <code>simstring</code> mode to retrieve approximate matches, albeit at the cost of a significantly higher computation time.</p>"},{"location":"pipelines/ner/cim10/#edsnlp.pipelines.ner.cim10.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.cim10\", config=dict(term_matcher=\"simstring\"))\n\ntext = \"Le patient est suivi pour fi\u00e8vres typho\u00efde et paratypho\u00efde.\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (fi\u00e8vres typho\u00efde et paratypho\u00efde,)\n\nent = doc.ents[0]\n\nent.label_\n# Out: cim10\n\nent.kb_id_\n# Out: A01\n</code></pre>"},{"location":"pipelines/ner/cim10/#edsnlp.pipelines.ner.cim10.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.cim10'</code> </p> <code>attr</code> <p>The default attribute to use for matching.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>'exact'</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher term matcher</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cim10'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'cim10': True}</code> </p> RETURNS DESCRIPTION <code>TerminologyMatcher</code>"},{"location":"pipelines/ner/cim10/#edsnlp.pipelines.ner.cim10.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.cim10</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/ner/covid/","title":"COVID","text":"<p>The <code>eds.covid</code> pipeline component detects mentions of COVID19.</p>"},{"location":"pipelines/ner/covid/#edsnlp.pipelines.ner.covid.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.covid\")\n\ntext = \"Le patient est admis pour une infection au coronavirus.\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (infection au coronavirus,)\n</code></pre>"},{"location":"pipelines/ner/covid/#edsnlp.pipelines.ner.covid.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.covid'</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>Union[str, Dict[str, str]]</code> DEFAULT: <code>'LOWER'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>patterns</code> <p>The regex pattern to use</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>patterns</code> </p> <code>label</code> <p>Label to use for matches</p> <p> TYPE: <code>str</code> DEFAULT: <code>'covid'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'covid': True}</code> </p> RETURNS DESCRIPTION <code>GenericMatcher</code>"},{"location":"pipelines/ner/covid/#edsnlp.pipelines.ner.covid.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.covid</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/ner/drugs/","title":"Drugs","text":"<p>The <code>eds.drugs</code> pipeline component detects mentions of French drugs (brand names and active ingredients) and adds them to <code>doc.ents</code>. Each drug is mapped to an ATC code through the Romedi terminology (Cossin et al., 2019). The ATC classifies drugs into groups.</p> <ol><li><p><p>Cossin S., Lebrun L., Lobre G., Loustau R., Jouhet V., Griffier R., Mougin F., Diallo G. and Thiessard F., 2019. Romedi: An Open Data Source About French Drugs on the Semantic Web. {Studies in Health Technology and Informatics}. 264, pp.79-82. 10.3233/SHTI190187</p></p></li></ol>"},{"location":"pipelines/ner/drugs/#edsnlp.pipelines.ner.drugs.factory.create_component--examples","title":"Examples","text":"<p>In this example, we are looking for an oral antidiabetic medication (ATC code: A10B).</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.drugs\", config=dict(term_matcher=\"exact\"))\n\ntext = \"Traitement habituel: Kard\u00e9gic, cardensiel (bisoprolol), glucophage, lasilix\"\n\ndoc = nlp(text)\n\ndrugs_detected = [(x.text, x.kb_id_) for x in doc.ents]\n\ndrugs_detected[0]\n# Out: ('Kard\u00e9gic', 'B01AC06')\n\nlen(drugs_detected)\n# Out: 5\n\noral_antidiabetics_detected = list(\n    filter(lambda x: (x[1].startswith(\"A10B\")), drugs_detected)\n)\noral_antidiabetics_detected\n# Out: [('glucophage', 'A10BA02')]\n</code></pre> <p>Glucophage is the brand name of a medication that contains metformine, the first-line medication for the treatment of type 2 diabetes.</p>"},{"location":"pipelines/ner/drugs/#edsnlp.pipelines.ner.drugs.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.drugs'</code> </p> <code>attr</code> <p>The default attribute to use for matching.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>'exact'</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher term matcher</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'drug'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'drug': True}</code> </p> RETURNS DESCRIPTION <code>TerminologyMatcher</code>"},{"location":"pipelines/ner/drugs/#edsnlp.pipelines.ner.drugs.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.drugs</code> pipeline was developed by the IAM team and CHU de Bordeaux's Data Science team.</p>"},{"location":"pipelines/ner/overview/","title":"Named Entity Recognition Components","text":"<p>We provide several Named Entity Recognition (NER) components. Named Entity Recognition is the task of identifying short relevant spans of text, named entities, and classifying them into pre-defined categories. In the case of clinical documents, these entities can be scores, disorders, behaviors, codes, dates, measurements, etc.</p>"},{"location":"pipelines/ner/overview/#edsnlp.pipelines.base.SpanSetterArg","title":"Span setters: where are stored extracted entities ?","text":"<p>A component assigns entities to a document by adding them to the <code>doc.ents</code> or <code>doc.spans[group]</code> attributes. <code>doc.ents</code> only supports non overlapping entities, therefore, if two entities overlap, the longest one will be kept. <code>doc.spans[group]</code> on the other hand, can contain overlapping entities. To control where entities are added, you can use the <code>span_setter</code> argument in any of these component.</p> <p>Valid values for the <code>span_setter</code> argument of a component can be :</p> <ul> <li>a (doc, matches) -&gt; None callable</li> <li>a span group name</li> <li>a list of span group names</li> <li>a dict of group name to True or list of labels</li> </ul> <p>The group name <code>\"ents\"</code> is a special case, and will add the matches to <code>doc.ents</code></p>"},{"location":"pipelines/ner/overview/#edsnlp.pipelines.base.SpanSetterArg--examples","title":"Examples","text":"<ul> <li><code>span_setter=[\"ents\", \"ckd\"]</code> will add the matches to both <code>doc.ents</code> and <code>doc.spans[\"ckd\"]</code>. It is equivalent to <code>{\"ents\": True, \"ckd\": True}</code>.</li> <li><code>span_setter={\"ents\": [\"foo\", \"bar\"]}</code> will add the matches with label \"foo\" and \"bar\" to <code>doc.ents</code>.</li> <li><code>span_setter=\"ents\"</code> will add all matches only to <code>doc.ents</code>.</li> <li><code>span_setter=\"ckd\"</code> will add all matches only to <code>doc.spans[\"ckd\"]</code>.</li> </ul>"},{"location":"pipelines/ner/overview/#available-components","title":"Available components","text":"Component Description <code>eds.covid</code> A COVID mentions detector <code>eds.charlson</code> A Charlson score extractor <code>eds.sofa</code> A SOFA score extractor <code>eds.elston_ellis</code> An Elston &amp; Ellis code extractor <code>eds.emergency_priority</code> A priority score extractor <code>eds.emergency_ccmu</code> A CCMU score extractor <code>eds.emergency_gemsa</code> A GEMSA score extractor <code>eds.tnm</code> A TNM score extractor <code>eds.adicap</code> A ADICAP codes extractor <code>eds.drugs</code> A drug mentions extractor <code>eds.cim10</code> A CIM10 terminology matcher <code>eds.umls</code> An UMLS terminology matcher <code>eds.ckd</code> CKD extractor <code>eds.copd</code> COPD extractor <code>eds.cerebrovascular_accident</code> Cerebrovascular accident extractor <code>eds.congestive_heart_failure</code> Congestive heart failure extractor <code>eds.connective_tissue_disease</code> Connective tissue disease extractor <code>eds.dementia</code> Dementia extractor <code>eds.diabetes</code> Diabetes extractor <code>eds.hemiplegia</code> Hemiplegia extractor <code>eds.leukemia</code> Leukemia extractor <code>eds.liver_disease</code> Liver disease extractor <code>eds.lymphoma</code> Lymphoma extractor <code>eds.myocardial_infarction</code> Myocardial infarction extractor <code>eds.peptic_ulcer_disease</code> Peptic ulcer disease extractor <code>eds.peripheral_vascular_disease</code> Peripheral vascular disease extractor <code>eds.solid_tumor</code> Solid tumor extractor <code>eds.alcohol</code> Alcohol consumption extractor <code>eds.tobacco</code> Tobacco consumption extractor"},{"location":"pipelines/ner/tnm/","title":"TNM","text":"<p>The <code>eds.tnm</code> component extracts TNM mentions from clinical documents.</p> <ol><li><p><p>Kempf E., Priou S., Lam\\'e G., Daniel C., Bellamine A., Sommacale D., Belkacemi y., Bey R., Galula G., Taright N., Tannier X., Rance B., Flicoteaux R., Hemery F., Audureau E., Chatellier G. and Tournigand C., 2022. Impact of two waves of Sars-Cov2 outbreak on the number, clinical presentation, care trajectories and survival of patients newly referred for a colorectal cancer: A French multicentric cohort study from a large group of University hospitals. {International Journal of Cancer}. 150, pp.1609-1618. 10.1002/ijc.33928</p></p></li></ol>"},{"location":"pipelines/ner/tnm/#edsnlp.pipelines.ner.tnm.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.tnm\")\n\ntext = \"TNM: pTx N1 M1\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (pTx N1 M1,)\n\nent = doc.ents[0]\nent._.tnm.dict()\n# {'modifier': 'p',\n#  'tumour': None,\n#  'tumour_specification': 'x',\n#  'node': '1',\n#  'node_specification': None,\n#  'metastasis': '1',\n#  'resection_completeness': None,\n#  'version': None,\n#  'version_year': None}\n</code></pre>"},{"location":"pipelines/ner/tnm/#edsnlp.pipelines.ner.tnm.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.tnm</code> </p> <code>pattern</code> <p>The regex pattern to use for matching ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>(?:\\b|^)(?&lt;=\\(?(?P&lt;version&gt;uicc|accj|tnm|UICC|A...</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>tnm</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'tnm': True}</code> </p>"},{"location":"pipelines/ner/tnm/#edsnlp.pipelines.ner.tnm.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The TNM score is based on the development of S. Priou, B. Rance and E. Kempf (Kempf et al., 2022).</p>"},{"location":"pipelines/ner/umls/","title":"UMLS","text":"<p>The <code>eds.umls</code> pipeline component matches the UMLS (Unified Medical Language System from NIH) terminology.</p> <p>Very low recall</p> <p>When using the <code>exact</code> matching mode, this component has a very poor recall performance. We can use the <code>simstring</code> mode to retrieve approximate matches, albeit at the cost of a significantly higher computation time.</p>"},{"location":"pipelines/ner/umls/#edsnlp.pipelines.ner.umls.factory.create_component--examples","title":"Examples","text":"<p><code>eds.umls</code> is an additional module that needs to be setup by:</p> <ol> <li><code>pip install -U umls_downloader</code></li> <li>Signing up for a UMLS Terminology    Services Account. After filling a short form, you will receive your token API    within a few days.</li> <li>Set <code>UMLS_API_KEY</code> locally: <code>export UMLS_API_KEY=your_api_key</code></li> </ol> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.umls\")\n\ntext = \"Grosse toux: le malade a \u00e9t\u00e9 mordu par des Amphibiens \" \"sous le genou\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (toux, a, par, Amphibiens, genou)\n\nent = doc.ents[0]\n\nent.label_\n# Out: umls\n\nent._.umls\n# Out: C0010200\n</code></pre> <p>You can easily change the default languages and sources with the <code>pattern_config</code> argument:</p> <pre><code>import spacy\n\n# Enable the French and English languages, through the French MeSH and LOINC\npattern_config = dict(languages=[\"FRE\", \"ENG\"], sources=[\"MSHFRE\", \"LNC\"])\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.umls\", config=dict(pattern_config=pattern_config))\n</code></pre> <p>See more options of languages and sources here.</p>"},{"location":"pipelines/ner/umls/#edsnlp.pipelines.ner.umls.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.umls'</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>Union[str, Dict[str, str]]</code> DEFAULT: <code>'NORM'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The term matcher to use, either \"exact\" or \"simstring\"</p> <p> TYPE: <code>TerminologyTermMatcher</code> DEFAULT: <code>'exact'</code> </p> <code>term_matcher_config</code> <p>The configuration for the term matcher</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>pattern_config</code> <p>The pattern retriever configuration</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>dict(languages=['FRE'], sources=None)</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'umls'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'umls': True}</code> </p>"},{"location":"pipelines/ner/umls/#edsnlp.pipelines.ner.umls.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.umls</code> pipeline was developed by AP-HP's Data Science team and INRIA SODA's team.</p>"},{"location":"pipelines/ner/behaviors/alcohol/","title":"Alcohol consumption","text":"<p>The <code>eds.alcohol</code> pipeline component extracts mentions of alcohol consumption. It won't match occasional consumption, nor acute intoxication.</p> Details of the used patterns <pre><code># fmt: off\ndefault_patterns = dict(\n    source=\"alcohol\",\n    regex=[\n        r\"\\balco[ol]\",\n        r\"\\bethyl\",\n        r\"(?&lt;!(25.?)|(sevrage)).?\\boh\\b\",\n        r\"exogenose\",\n        r\"delirium.tremens\",\n    ],\n    exclude=[\n        dict(\n            regex=[\n                \"occasion\",\n                \"episod\",\n                \"festi\",\n                \"rare\",\n                \"libre\",  # OH-libres\n                \"aigu\",\n            ],\n            window=(-3, 5),\n        ),\n        dict(\n            regex=[\"pansement\", \"compress\"],\n            window=-3,\n        ),\n    ],\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"stopped\",\n            regex=r\"(?&lt;!non )(?&lt;!pas )(sevr|arret|stop|ancien)\",\n            window=(-3, 5),\n        ),\n        dict(\n            name=\"zero_after\",\n            regex=r\"^[a-z]*\\s*:?[\\s-]*(0|oui|non(?! sevr))\",\n            window=6,\n        ),\n    ],\n)\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/behaviors/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"PRESENT\"</code></li> <li><code>\"ABSTINENCE\"</code> if the patient stopped its consumption</li> <li><code>\"ABSENT\"</code> if the patient has no alcohol dependence</li> </ul> </li> </ul>"},{"location":"pipelines/ner/behaviors/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.alcohol\")\n</code></pre> <p>Below are a few examples:</p> 12345678 <pre><code>text = \"Patient alcoolique.\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [alcoolique]\n</code></pre> <pre><code>text = \"OH chronique.\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [OH]\n</code></pre> <pre><code>text = \"Prise d'alcool occasionnelle\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Application d'un pansement alcoolis\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Alcoolisme sevr\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcoolisme sevr\u00e9]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevr\u00e9]}\n</code></pre> <pre><code>text = \"Alcoolisme non sevr\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcoolisme]\n</code></pre> <pre><code>text = \"Alcool: 0\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcool: 0]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'zero_after': [0]}\n</code></pre> <pre><code>text = \"Le patient est en cours de sevrage \u00e9thylotabagique\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [sevrage \u00e9thylotabagique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevrage]}\n</code></pre>"},{"location":"pipelines/ner/behaviors/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.alcohol</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>{'source': 'alcohol', 'regex': ['\\\\balco[ol]', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>alcohol</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'alcohol': True}</code> </p>"},{"location":"pipelines/ner/behaviors/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.alcohol</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/behaviors/overview/","title":"Behaviors","text":""},{"location":"pipelines/ner/behaviors/overview/#presentation","title":"Presentation","text":"<p>EDS-NLP offers two components to extract behavioral patterns, namely the tobacco and alcohol consumption status. Each component is based on the ContextualMatcher component. Some general considerations about those components:</p> <ul> <li>Extracted entities are stored in <code>doc.ents</code> and <code>doc.spans</code>. For instance, the <code>eds.tobacco</code> component stores matches in <code>doc.spans[\"tobacco\"]</code>.</li> <li>The matched comorbidity is also available under the <code>ent.label_</code> of each match.</li> <li>Matches have an associated <code>_.status</code> attribute taking the value <code>0</code>, <code>1</code>, or <code>2</code>. A corresponding <code>_.detailed_status</code> attribute stores the human-readable status, which can be component-dependent. See each component documentation for more details.</li> <li>Some components add additional information to matches. For instance, the <code>tobacco</code> adds, if relevant, extracted pack-year (= paquet-ann\u00e9e). Those information are available under the <code>ent._.assigned</code> attribute.</li> <li> <p>Those components work on normalized documents. Please use the <code>eds.normalizer</code> pipeline with the following parameters:   <pre><code>nlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\n</code></pre></p> </li> <li> <p>Those components should be used with a qualification pipeline to avoid extracted unwanted matches. At the very least, you can use available rule-based qualifiers (<code>eds.negation</code>, <code>eds.hypothesis</code> and <code>eds.family</code>). Better, a machine learning qualification component was developed and trained specifically for those components. For privacy reason, the model isn't publicly available yet.</p> <p>Use the ML model</p> <p>The model will soon be available in the models catalogue of AP-HP's CDW.</p> </li> </ul>"},{"location":"pipelines/ner/behaviors/overview/#usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(\"eds.tobacco\")\nnlp.add_pipe(\"eds.diabetes\")\n\ntext = \"\"\"\nCompte-rendu de consultation.\n\nJe vois ce jour M. SCOTT pour le suivi de sa r\u00e9tinopathie diab\u00e9tique.\nLe patient va bien depuis la derni\u00e8re fois.\nJe le f\u00e9licite pour la poursuite de son sevrage tabagique (toujours \u00e0 10 paquet-ann\u00e9e).\n\nSur le plan de son diab\u00e8te, la glyc\u00e9mie est stable.\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans\n# Out: {\n# 'pollutions': [],\n# 'tobacco': [sevrage tabagique (toujours \u00e0 10 paquet-ann\u00e9e],\n# 'diabetes': [r\u00e9tinopathie diab\u00e9tique, diab\u00e8te]\n# }\n\ntobacco_matches = doc.spans[\"tobacco\"]\ntobacco_matches[0]._.detailed_status\n# Out: \"ABSTINENCE\" #\n\ntobacco_matches[0]._.assigned[\"PA\"]  # paquet-ann\u00e9e\n# Out: 10 # (1)\n\n\ndiabetes = doc.spans[\"diabetes\"]\n(diabetes[0]._.detailed_status, diabetes[1]._.detailed_status)\n# Out: ('WITH_COMPLICATION', 'WITHOUT_COMPLICATION') # (2)\n</code></pre> <ol> <li>Here we see an example of additional information that can be extracted</li> <li>Here we see the importance of document-level aggregation to extract the correct severity of each comorbidity.</li> </ol> <ol></ol>"},{"location":"pipelines/ner/behaviors/tobacco/","title":"Tobacco consumption","text":"<p>The <code>eds.tobacco</code> pipeline component extracts mentions of tobacco consumption.</p> Details of the used patterns <pre><code># fmt: off\nPA = r\"(?:\\bp/?a\\b|paquets?.?annee)\"\nQUANTITY = r\"(?P&lt;quantity&gt;[\\d]{1,3})\"\nPUNCT = r\"\\.,-;\\(\\)\"\n\ndefault_patterns = [\n    dict(\n        source=\"tobacco\",\n        regex=[\n            r\"tabagi\",\n            r\"tabac\",\n            r\"\\bfume\\b\",\n            r\"\\bfumeu\",\n            r\"\\bpipes?\\b\",\n        ],\n        exclude=dict(\n            regex=[\n                \"occasion\",\n                \"moder\",\n                \"quelqu\",\n                \"festi\",\n                \"rare\",\n                \"sujet\",  # Example : Chez le sujet fumeur ... generic sentences\n            ],\n            window=(-3, 5),\n        ),\n        regex_attr=\"NORM\",\n        assign=[\n            dict(\n                name=\"stopped\",\n                regex=r\"(?&lt;!non )(?&lt;!pas )(\\bex\\b|sevr|arret|stop|ancien)\",\n                window=(-3, 15),\n            ),\n            dict(\n                name=\"zero_after\",\n                regex=r\"^[a-z]*\\s*:?[\\s-]*(0|non(?! sevr))\",\n                window=6,\n            ),\n            dict(\n                name=\"PA\",\n                regex=rf\"{QUANTITY}[^{PUNCT}]{{0,10}}{PA}|{PA}[^{PUNCT}]{{0,10}}{QUANTITY}\",\n                window=(-10, 10),\n                reduce_mode=\"keep_first\",\n            ),\n            dict(\n                name=\"secondhand\",\n                regex=\"(passif)\",\n                window=5,\n                reduce_mode=\"keep_first\",\n            ),\n        ],\n    )\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/behaviors/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"PRESENT\"</code></li> <li><code>\"ABSTINENCE\"</code> if the patient stopped its consumption</li> <li><code>\"ABSENT\"</code> if the patient has no tobacco dependence</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>PA</code>: the mentioned year-pack (= paquet-ann\u00e9e)</li> <li><code>secondhand</code>: if secondhand smoking</li> </ul> </li> </ul>"},{"location":"pipelines/ner/behaviors/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.tobacco\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Tabagisme \u00e9valu\u00e9 \u00e0 15 PA\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabagisme \u00e9valu\u00e9 \u00e0 15 PA]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'PA': 15}\n</code></pre> <pre><code>text = \"Patient tabagique\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [tabagique]\n</code></pre> <pre><code>text = \"Tabagisme festif\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"On a un tabagisme ancien\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [tabagisme ancien]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [ancien]}\n</code></pre> <pre><code>text = \"Tabac: 0\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabac: 0]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'zero_after': [0]}\n</code></pre> <pre><code>text = \"Tabagisme passif\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabagisme passif]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'secondhand': passif}\n</code></pre> <pre><code>text = \"Tabac: sevr\u00e9 depuis 5 ans\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabac: sevr\u00e9]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevr\u00e9]}\n</code></pre>"},{"location":"pipelines/ner/behaviors/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.tobacco</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'tobacco', 'regex': ['tabagi', 'tab...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>tobacco</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'tobacco': True}</code> </p>"},{"location":"pipelines/ner/behaviors/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.tobacco</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/aids/","title":"AIDS","text":"<p>The <code>eds.aids</code> pipeline component extracts mentions of AIDS. It will notably match:</p> <ul> <li>Mentions of VIH/HIV at the SIDA/AIDS stage</li> <li>Mentions of VIH/HIV with opportunistic(s) infection(s)</li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre> <p>On HIV infection</p> <p>pre-AIDS HIV infection are not extracted, only AIDS.</p>"},{"location":"pipelines/ner/disorders/aids/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>opportunist</code>: list of opportunist infections extracted around the HIV mention</li> <li><code>stage</code>: stage of the HIV infection</li> </ul> </li> </ul>"},{"location":"pipelines/ner/disorders/aids/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.aids\")\n</code></pre> <p>Below are a few examples:</p> SIDAVIHCoinfectionVIH stade SIDA <pre><code>text = \"Patient atteint du VIH au stade SIDA.\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH au stade SIDA]\n</code></pre> <pre><code>text = \"Patient atteint du VIH.\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Il y a un VIH avec coinfection pneumocystose\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'opportunist': [coinfection, pneumocystose]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un VIH stade C\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': [C]}\n</code></pre>"},{"location":"pipelines/ner/disorders/aids/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.aids</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'aids', 'regex': ['(vih.{1,5}stade....</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>aids</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'aids': True}</code> </p>"},{"location":"pipelines/ner/disorders/aids/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.aids</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/cerebrovascular-accident/","title":"Cerebrovascular accident","text":"<p>The <code>eds.cerebrovascular_accident</code> pipeline component extracts mentions of cerebrovascular accident. It will notably match:</p> <ul> <li>Mentions of AVC/AIT</li> <li>Mentions of bleeding, hemorrhage, thrombus, ischemia, etc., localized in the brain</li> </ul> Details of the used patterns <pre><code># fmt: off\nimport re\n\nfrom edsnlp.utils.resources import get_AVC_care_site\n\nfrom ..terms import BRAIN, HEART, PERIPHERAL\n\nAVC_CARE_SITES_REGEX = [\n    r\"\\b\" + re.escape(cs.strip()) + r\"\\b\" for cs in get_AVC_care_site(prefix=True)\n] + [\n    r\"h[o\u00f4]p\",\n    r\"\\brcp\",\n    r\"service\",\n    r\"\\bsau\",\n    r\"ap.?hp\",\n    r\"\\burg\",\n    r\"finess\",\n    r\"\\bsiret\",\n    r\"[\u00e0a] avc\",\n    r\"consult\",\n]\n\navc = dict(\n    source=\"avc\",\n    regex=[\n        r\"\\bavc\\b\",\n    ],\n    exclude=[\n        dict(\n            regex=AVC_CARE_SITES_REGEX,\n            window=(-5, 5),\n            regex_flags=re.S | re.I,\n            limit_to_sentence=False,\n        ),\n        dict(\n            regex=r\"\\b[a-z]\\.\",\n            window=2,\n            limit_to_sentence=False,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"(hemorr?agie|hematome)\",\n        r\"angiopath\",\n        r\"angioplasti\",\n        r\"infarctus\",\n        r\"occlusion\",\n        r\"saignement\",\n        r\"embol\",\n        r\"vascularite\",\n        r\"\\bhsd\\b\",\n        r\"thrombos\",\n        r\"thrombol[^y]\",\n        r\"thrombophi\",\n        r\"thrombi[^n]\",\n        r\"thrombus\",\n        r\"thrombectomi\",\n        r\"phleb\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=[\n        dict(\n            regex=r\"pulmo|poumon\",\n            window=4,\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"brain_localized\",\n            regex=\"(\" + r\"|\".join(BRAIN) + \")\",\n            window=(-15, 15),\n            limit_to_sentence=False,\n            include_assigned=False,\n        ),\n    ],\n)\n\ngeneral = dict(\n    source=\"general\",\n    regex=[\n        r\"accident.{1,5}vasculaires.{1,5}cereb\",\n        r\"accident.{1,5}vasculaire.{1,5}ischemi\",\n        r\"accident.{1,5}ischemi\",\n        r\"moya.?moya\",\n        r\"occlusion.{1,5}(artere|veine).{1,20}retine\",\n        r\"vasculopathies?.cerebrales?.ischemique\",\n        r\"maladies?.des.petites.arteres\",\n        r\"maladies?.des.petits.vaisseaux\",\n        r\"thrombolyse\",\n        r\"\\bsusac\\b\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bAIC\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nAIT = dict(\n    source=\"AIT\",\n    regex=[\n        r\"\\bAIC\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n        r\"\\bAIT\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nischemia = dict(\n    source=\"ischemia\",\n    regex=[\n        r\"ischemi\",\n    ],\n    exclude=[\n        dict(\n            regex=PERIPHERAL + HEART,\n            window=(-7, 7),\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"brain\",\n            regex=\"(\" + r\"|\".join(BRAIN) + \")\",\n            window=(-10, 15),\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    avc,\n    with_localization,\n    general,\n    acronym,\n    AIT,\n    ischemia,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/cerebrovascular-accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/cerebrovascular-accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.cerebrovascular_accident\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Patient hospitalis\u00e9 \u00e0 AVC.\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Hospitalisation pour un AVC.\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [AVC]\n</code></pre> <pre><code>text = \"Saignement intracranien\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Saignement]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [intracranien]}\n</code></pre> <pre><code>text = \"Thrombose p\u00e9riph\u00e9rique\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Thrombose sylvienne\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Thrombose]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [sylvienne]}\n</code></pre> <pre><code>text = \"Infarctus c\u00e9r\u00e9bral\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Infarctus]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [c\u00e9r\u00e9bral]}\n</code></pre> <pre><code>text = \"Soign\u00e9 via un thrombolyse\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [thrombolyse]\n</code></pre>"},{"location":"pipelines/ner/disorders/cerebrovascular-accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.cerebrovascular_accident</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'avc', 'regex': ['\\\\bavc\\\\b'], 'exc...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>cerebrovascular_accident</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'cerebrovascular_accident': True}</code> </p>"},{"location":"pipelines/ner/disorders/cerebrovascular-accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.cerebrovascular_accident</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/ckd/","title":"CKD","text":"<p>The <code>eds.CKD</code> pipeline component extracts mentions of CKD (Chronic Kidney Disease). It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Kidney transplantation</li> <li>Chronic dialysis</li> <li>Renal failure from stage 3 to 5. The stage is extracted by trying 3 methods:<ul> <li>Extracting the mentioned stage directly (\"IRC stade IV\")</li> <li>Extracting the severity directly (\"IRC terminale\")</li> <li>Extracting the mentioned GFR (DFG in french) (\"IRC avec DFG estim\u00e9 \u00e0 30   mL/min/1,73m2)\")</li> </ul> </li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/ckd/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>stage</code>: mentioned renal failure stage</li> <li><code>status</code>: mentioned renal failure severity (e.g. mod\u00e9r\u00e9e, s\u00e9v\u00e8re, terminale,   etc.)</li> <li><code>dfg</code>: mentioned DFG</li> </ul> </li> </ul>"},{"location":"pipelines/ner/disorders/ckd/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.CKD\")\n</code></pre> <p>Below are a few examples:</p> 1234567891011 <pre><code>text = \"Patient atteint d'une glom\u00e9rulopathie.\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [glom\u00e9rulopathie]\n</code></pre> <pre><code>text = \"Patient atteint d'une tubulopathie aig\u00fce.\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Patient transplant\u00e9 r\u00e9nal\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [transplant\u00e9 r\u00e9nal]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une insuffisance r\u00e9nale aig\u00fce sur chronique\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [insuffisance r\u00e9nale aig\u00fce sur chronique]\n</code></pre> <pre><code>text = \"Le patient a \u00e9t\u00e9 dialys\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Le patient est dialys\u00e9 chaque lundi\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [dialys\u00e9 chaque lundi]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'chronic': [lundi]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC s\u00e9v\u00e8re\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC s\u00e9v\u00e8re]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'status': s\u00e9v\u00e8re}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC au stade IV\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC au stade IV]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': IV}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC avec DFG \u00e0 30\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC avec DFG \u00e0 30]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'dfg': 30}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une maladie r\u00e9nale avec DFG \u00e0 110\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"pipelines/ner/disorders/ckd/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.ckd</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['glomerulonephrit...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>ckd</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'ckd': True}</code> </p>"},{"location":"pipelines/ner/disorders/ckd/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.CKD</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/congestive-heart-failure/","title":"Congestive heart failure","text":"<p>The <code>eds.congestive_heart_failure</code> pipeline component extracts mentions of congestive heart failure. It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Heart transplantation</li> <li>AF (Atrial Fibrillation)</li> <li>Pacemaker</li> </ul> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import ASYMPTOMATIC\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"defaillance.{1,10}cardi\",\n        r\"(\u0153|oe)deme.{1,10}pulmon\",\n        r\"(\u0153|oe)deme.{1,10}poumon\",\n        r\"decompensation.{1,10}card\",\n        r\"choc.{1,30}cardio\",\n        r\"greffe.{1,10}c(\u0153|oe)ur\",\n        r\"greffe.{1,10}cardia\",\n        r\"transplantation.{1,10}c(\u0153|oe)ur\",\n        r\"transplantation.{1,10}cardia\",\n        r\"arret.{1,10}cardi\",\n        r\"c(\u0153|oe)ur pulmo\",\n        r\"foie.card\",\n        r\"pace.?maker\",\n        r\"stimulateur.cardiaque\",\n        r\"valve.{1,30}(meca|artific)\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nsymptomatic = dict(\n    source=\"symptomatic\",\n    regex=[\n        r\"cardiopathi\",\n        r\"cardiomyopathi\",\n        r\"d(i|y)sfonction.{1,15}(ventricul|\\bvg|cardiaque)\",\n        r\"valvulopathie\",\n        r\"\\bic\\b.{1,10}(droite|gauche)\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=ASYMPTOMATIC + [r\"(?&lt;!\\bnon.)ischem\"],  # Exclusion of ischemic events\n        window=5,\n    ),\n)\n\nwith_minimum_severity = dict(\n    source=\"min_severity\",\n    regex=[\n        r\"insuffisance.{1,10}(\\bcardi|\\bdiasto|\\bventri|\\bmitral|tri.?cusp)\",\n        r\"(retrecissement|stenose).(aortique|mitral)\",\n        r\"\\brac\\b\",\n        r\"\\brm\\b\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=ASYMPTOMATIC + [\"minime\", \"modere\", r\"non.serre\"],\n        window=5,\n    ),\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bOAP\\b\",\n        r\"\\bCMH\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nAF_main_pattern = dict(\n    source=\"AF_main\",\n    regex=[\n        r\"fibrill?ation.{1,3}(atriale|auriculaire|ventriculaire)\",\n        r\"flutter\",\n        r\"brady.?arythmie\",\n        r\"pace.?maker\",\n    ],\n)\n\nAF_acronym = dict(\n    source=\"AF_acronym\",\n    regex=[\n        r\"\\bFA\\b\",\n        r\"\\bAC.?FA\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    symptomatic,\n    acronym,\n    AF_main_pattern,\n    AF_acronym,\n    with_minimum_severity,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/congestive-heart-failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component--usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.congestive_heart_failure\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Pr\u00e9sence d'un oed\u00e8me pulmonaire\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [oed\u00e8me pulmonaire]\n</code></pre> <pre><code>text = \"Le patient est \u00e9quip\u00e9 d'un pace-maker\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [pace-maker]\n</code></pre> <pre><code>text = \"Un cardiopathie non d\u00e9compens\u00e9e\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Insuffisance cardiaque\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [Insuffisance cardiaque]\n</code></pre> <pre><code>text = \"Insuffisance cardiaque minime\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"pipelines/ner/disorders/congestive-heart-failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>(str)</code> DEFAULT: <code>eds.congestive_heart_failure</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['defaillance.{1,1...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>congestive_heart_failure</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'congestive_heart_failure': True}</code> </p>"},{"location":"pipelines/ner/disorders/congestive-heart-failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.congestive_heart_failure</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/connective-tissue-disease/","title":"Connective tissue disease","text":"<p>The <code>eds.connective_tissue_disease</code> pipeline component extracts mentions of connective tissue diseases.</p> Details of the used patterns <pre><code># fmt: off\nTO_EXCLUDE = r\"(?&lt;!a )((\\bacc\\b)|anti.?coag|anti.?corps|buschke|(\\bac\\b)|(\\bbio))\"\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"arthrites.{1,5}juveniles.{1,5}idiopa\",\n        r\"myosite\",\n        r\"myopathie.{1,5}inflammatoire\",\n        r\"polyarthrite.{1,5}chronique.{1,5}evol\",\n        r\"polymyosie\",\n        r\"polyarthrites.{1,5}(rhizo|rhuma)\",\n        r\"sclerodermie\",\n        r\"connectivite\",\n        r\"sarcoidose\",\n    ],\n    exclude=dict(\n        regex=[TO_EXCLUDE],\n        window=(-7, 7),\n    ),\n    regex_attr=\"NORM\",\n)\n\nlupus = dict(\n    source=\"lupus\",\n    regex=[\n        r\"\\blupus\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nlupique = dict(\n    source=\"lupique\",\n    regex=[\n        r\"\\blupique\",\n    ],\n    exclude=dict(\n        regex=[TO_EXCLUDE],\n        window=(-7, 7),\n    ),\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronyms\",\n    regex=[\n        r\"\\bAJI\\b\",\n        r\"\\bLED\\b\",\n        r\"\\bPCE\\b\",\n        r\"\\bCREST\\b\",\n        r\"\\bPPR\\b\",\n        r\"\\bMICI\\b\",\n        r\"\\bMNAI\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nnamed_disease = dict(\n    source=\"named_disease\",\n    regex=[\n        r\"libman.?lack\",\n        r\"\\bstill\",\n        r\"felty\",\n        r\"forestier.?certon\",\n        r\"gou(g|j)erot\",\n        r\"raynaud\",\n        r\"thibierge.?weiss\",\n        r\"sjogren\",\n        r\"gou(g|j)erot.?sjogren\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    lupus,\n    lupique,\n    acronym,\n    named_disease,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/connective-tissue-disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/connective-tissue-disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.connective_tissue_disease\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Pr\u00e9sence d'une scl\u00e9rodermie.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [scl\u00e9rodermie]\n</code></pre> <pre><code>text = \"Patient atteint d'un lupus.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [lupus]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'anticoagulants lupiques,\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Il y a une MICI.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [MICI]\n</code></pre> <pre><code>text = \"Syndrome de Raynaud\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [Raynaud]\n</code></pre>"},{"location":"pipelines/ner/disorders/connective-tissue-disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.connective_tissue_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['arthrites.{1,5}j...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>connective_tissue_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'connective_tissue_disease': True}</code> </p>"},{"location":"pipelines/ner/disorders/connective-tissue-disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.connective_tissue_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/copd/","title":"COPD","text":"<p>The <code>eds.copd</code> pipeline component extracts mentions of COPD (Chronic obstructive pulmonary disease). It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Pulmonary hypertension</li> <li>Long-term oxygen therapy</li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/copd/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/copd/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.copd\")\n</code></pre> <p>Below are a few examples:</p> 123456 <pre><code>text = \"Une fibrose interstitielle diffuse idiopathique\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [fibrose interstitielle diffuse idiopathique]\n</code></pre> <pre><code>text = \"Patient atteint de pneumoconiose\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [pneumoconiose]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une HTAP.\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [HTAP]\n</code></pre> <pre><code>text = \"On voit une hypertension pulmonaire minime\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"La patiente a \u00e9t\u00e9 mis sous oxyg\u00e9norequ\u00e9rance\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"La patiente est sous oxyg\u00e9norequ\u00e9rance au long cours\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [oxyg\u00e9norequ\u00e9rance au long cours]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'long': [long cours]}\n</code></pre>"},{"location":"pipelines/ner/disorders/copd/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.copd</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['alveolites.{1,5}...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>copd</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'copd': True}</code> </p>"},{"location":"pipelines/ner/disorders/copd/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.copd</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/dementia/","title":"Dementia","text":"<p>The <code>eds.dementia</code> pipeline component extracts mentions of dementia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"demence\",\n        r\"dementiel\",\n        r\"corps de le[vw]y\",\n        r\"deficits?.chroniques?.cognitif\",\n        r\"troubles?.mnesique?\",\n        r\"troubles?.praxique\",\n        r\"troubles?.attentionel\",\n        r\"troubles?.degeneratif.{1,15}fonctions.{1,5}sup\",\n        r\"maladies?.cerebrales?.degen\",\n        r\"troubles?.neurocogn\",\n        r\"deficits?.cognitif\",\n        r\"(trouble|dysfonction).{1,20} cogniti\",\n        r\"atteinte.{1,7}spheres?cogniti\",\n        r\"syndrome.{1,10}(frontal|neuro.deg)\",\n        r\"dysfonction.{1,25}cogni\",\n        r\"(?&lt;!specialisee )alzheimer\",\n        r\"demence.{1,20}(\\balz|\\bpark)\",\n        r\"binswanger\",\n        r\"gehring\",\n        r\"\\bpick\",\n        r\"de guam\",\n        r\"[kc]reutzfeld.{1,5}ja[ck]ob\",\n        r\"huntington\",\n        r\"korsako[fv]\",\n        r\"atrophie.{1,10}(cortico|hippocamp|cereb|lobe)\",\n    ],\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bSLA\\b\",\n        r\"\\bDFT\\b\",\n        r\"\\bDFT\",\n        r\"\\bTNC\\b\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=r\"\\banti\",  # anticorps\n        window=-15,\n        regex_attr=\"NORM\",\n    ),\n)\n\ncharcot = dict(\n    source=\"charcot\",\n    regex=[\n        r\"maladie.{1,10}charcot\",\n    ],\n    exclude=dict(\n        regex=[\n            \"pied de\",\n            \"marie.?tooth\",\n        ],\n        window=(-3, 3),\n    ),\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    charcot,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/dementia/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/dementia/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.dementia\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"D'importants d\u00e9ficits cognitifs\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [d\u00e9ficits cognitifs]\n</code></pre> <pre><code>text = \"Patient atteint de d\u00e9mence\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [d\u00e9mence]\n</code></pre> <pre><code>text = \"On retrouve des anti-SLA\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une maladie de Charcot\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [maladie de Charcot]\n</code></pre>"},{"location":"pipelines/ner/disorders/dementia/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.dementia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['demence', 'demen...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>dementia</code> </p> <code>span_setter</code> <p>The span setter to use</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'dementia': True}</code> </p>"},{"location":"pipelines/ner/disorders/dementia/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.dementia</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/diabetes/","title":"Diabetes","text":"<p>The <code>eds.diabetes</code> pipeline component extracts mentions of diabetes.</p> Details of the used patterns <pre><code># fmt: off\nCOMPLICATIONS = [\n    r\"nephropat\",\n    r\"neuropat\",\n    r\"retinopat\",\n    r\"glomerulopathi\",\n    r\"glomeruloscleros\",\n    r\"angiopathi\",\n    r\"origine\",\n]\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"\\bds?n?id\\b\",\n        r\"\\bdiabet[^o]\",\n        r\"\\bdb\\b\",\n        r\"\\bdt.?(i|ii|1|2)\\b\",\n    ],\n    exclude=dict(\n        regex=[\n            \"insipide\",\n            \"nephrogenique\",\n            \"aigu\",\n            r\"\\bdr\\b\",  # Dr. ...\n            \"endocrino\",  # Section title\n            \"soins aux pieds\",  # Section title\n            \"nutrition\",  # Section title\n            r\"\\s?:\\n+\\W+(?!oui|non|\\W)\",  # General pattern for section title\n        ],\n        window=(-5, 5),\n    ),\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"complicated_before\",\n            regex=r\"(\" + r\"|\".join(COMPLICATIONS + [\"origine\"]) + r\")\",\n            window=-3,\n        ),\n        dict(\n            name=\"complicated_after\",\n            regex=r\"(\"\n            + r\"|\".join([r\"(?&lt;!sans )compli\", r\"(?&lt;!a)symptomatique\"] + COMPLICATIONS)\n            + r\")\",\n            window=12,\n        ),\n        dict(\n            name=\"type\",\n            regex=r\"type.(i|ii|1|2)\",\n            window=6,\n        ),\n        dict(\n            name=\"insulin\",\n            regex=r\"insulino.?(dep|req)\",\n            window=6,\n        ),\n        dict(\n            name=\"corticoid\",\n            regex=r\"(bctc\\b|cortico(?:.?induit)?)\",\n            window=6,\n        ),\n    ],\n)\n\ncomplicated_pattern = dict(\n    source=\"complicated\",\n    regex=[\n        r\"(mal|maux).perforants?(.plantaire)?\",\n        r\"pieds? diabeti\",\n    ],\n    exclude=dict(\n        regex=\"soins aux\",  # Section title\n        window=-2,\n    ),\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    complicated_pattern,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"WITH_COMPLICATION\"</code> if the diabetes is  complicated (e.g., via organ    damages)</li> <li><code>\"WITHOUT_COMPLICATION\"</code> otherwise</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>type</code>: type of diabetes (I or II)</li> <li><code>insulin</code>: if the diabetes is insulin-dependent</li> <li><code>corticoid</code>: if the diabetes is corticoid-induced</li> </ul> </li> </ul>"},{"location":"pipelines/ner/disorders/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.diabetes\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Pr\u00e9sence d'un DT2\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [DT2]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un DNID\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [DNID]\n</code></pre> <pre><code>text = \"Patient diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [diab\u00e9tique]\n</code></pre> <pre><code>text = \"Un diab\u00e8te insipide\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Atteinte neurologique d'origine diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [origine diab\u00e9tique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n\nspan._.assigned\n# Out: {'complicated_before': [origine]}\n</code></pre> <pre><code>text = \"Une r\u00e9tinopathie diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [r\u00e9tinopathie diab\u00e9tique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n\nspan._.assigned\n# Out: {'complicated_before': [r\u00e9tinopathie]}\n</code></pre> <pre><code>text = \"Il y a un mal perforant plantaire\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [mal perforant plantaire]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n</code></pre>"},{"location":"pipelines/ner/disorders/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.diabetes</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['\\\\bds?n?id\\\\b', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>diabetes</code> </p> <code>span_setter</code> <p>The span setter to use</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'diabetes': True}</code> </p>"},{"location":"pipelines/ner/disorders/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.diabetes</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/hemiplegia/","title":"Hemiplegia","text":"<p>The <code>eds.hemiplegia</code> pipeline component extracts mentions of hemiplegia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"hemiplegi\",\n        r\"tetraplegi\",\n        r\"quadriplegi\",\n        r\"paraplegi\",\n        r\"neuropathie.{1,25}motrice.{1,30}type [5V]\",\n        r\"charcot.?marie.?tooth\",\n        r\"locked.?in\",\n        r\"syndrome.{1,5}(enfermement|verrouillage)|(desafferen)\",\n        r\"paralysie.{1,10}hemicorps\",\n        r\"paralysie.{1,10}jambe\",\n        r\"paralysie.{1,10}membre\",\n        r\"paralysie.{1,10}cote\",\n        r\"paralysie.{1,5}cerebrale.{1,5}spastique\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLIS\\b\",\n        r\"\\bNMSH\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.hemiplegia\")\n</code></pre> <p>Below are a few examples:</p> 123 <pre><code>text = \"Patient h\u00e9mipl\u00e9gique\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [h\u00e9mipl\u00e9gique]\n</code></pre> <pre><code>text = \"Paralysie des membres inf\u00e9rieurs\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [Paralysie des membres]\n</code></pre> <pre><code>text = \"Patient en LIS\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [LIS]\n</code></pre>"},{"location":"pipelines/ner/disorders/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.hemiplegia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['hemiplegi', 'tet...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>hemiplegia</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'hemiplegia': True}</code> </p>"},{"location":"pipelines/ner/disorders/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.hemiplegia</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/leukemia/","title":"Leukemia","text":"<p>The <code>eds.leukemia</code> pipeline component extracts mentions of leukemia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"leucemie\",\n        r\"(syndrome.)?myeloproliferatif\",\n        r\"m[yi]eloprolifer\",\n    ],\n    exclude=dict(\n        regex=[\n            \"plasmocyte\",\n            \"benin\",\n            \"benign\",\n        ],\n        window=5,\n    ),\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLAM\\b\",\n        r\"\\bLAM.?[0-9]\",\n        r\"\\bLAL\\b\",\n        r\"\\bLMC\\b\",\n        r\"\\bLCE\\b\",\n        r\"\\bLMM[JC]\\b\",\n        r\"\\bLCN\\b\",\n        r\"\\bAREB\\b\",\n        r\"\\bAPMF\\b\",\n        r\"\\bLLC\\b\",\n        r\"\\bSMD\\b\",\n        r\"LA my[\u00e9\u00e8e]lomonocytaire\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=\"anti\",\n        window=-20,\n    ),\n)\n\nother = dict(\n    source=\"other\",\n    regex=[\n        r\"myelofibrose\",\n        r\"vaquez\",\n        r\"thrombocytemie.{1,3}essentielle\",\n        r\"splenomegalie.{1,3}myeloide\",\n        r\"mastocytose.{1,5}maligne\",\n        r\"polyglobulie.{1,10}essentielle\",\n        r\"letterer.?siwe\",\n        r\"anemie.refractaire.{1,20}blaste\",\n        r\"m[iy]elod[iy]splasi\",\n        r\"syndrome.myelo.?dysplasique\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    other,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.leukemia\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Sydrome my\u00e9loprolif\u00e9ratif\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [my\u00e9loprolif\u00e9ratif]\n</code></pre> <pre><code>text = \"Sydrome my\u00e9loprolif\u00e9ratif b\u00e9nin\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Patient atteint d'une LAM\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [LAM]\n</code></pre> <pre><code>text = \"Une maladie de Vaquez\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [Vaquez]\n</code></pre>"},{"location":"pipelines/ner/disorders/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.leukemia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['leucemie', '(syn...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>leukemia</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'leukemia': True}</code> </p>"},{"location":"pipelines/ner/disorders/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.leukemia</code> component was developed by AP-HP's Data Science team with a team  of medical experts. A paper describing in details the development of those  components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/liver-disease/","title":"Liver disease","text":"<p>The <code>eds.liver_disease</code> pipeline component extracts mentions of liver disease.</p> Details of the used patterns <pre><code># fmt: off\nmild = dict(\n    source=\"mild\",\n    regex=[\n        r\"cholangites?.{1,10}(sclero|secondaire)\",\n        r\"fibrose.{1,10}(hepatique|foie)\",\n        r\"hepatite.{1,15}chronique\",\n        r\"hepatopathie\",\n        r\"\\bnash\\b\",\n        r\"(maladie|sydrome).{1,10}Hanot\",\n        r\"surinfections.{1,5}delta\",\n        r\"\\bcbp\\b\",\n        r\"\\bmaf\\b\",\n        r\"(maladie|syndrome).{1,8}hanot\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=\"\\bdots?\\b\",\n        window=-5,\n    ),\n)\n\nmoderate_severe = dict(\n    source=\"moderate_severe\",\n    regex=[\n        r\"cirrhose\",\n        r\"necrose.{1,10}(hepati|foie)\",\n        r\"varice.{1,10}(estomac|oesopha|gastr)\",\n        r\"\\bvo\\b.{1,5}(stade|grade).(1|2|3|i{1,3})\",\n        r\"hypertension.{1,5}portale\",\n        r\"scleroses.{1,5}hepatoportale\",\n        r\"sydrome.{1,10}hepato.?ren\",\n        r\"insuffisance.{1,5}hepa\",\n        r\"encephalopathie.{1,5}hepa\",\n        r\"\\btips\\b\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ntransplant = dict(\n    source=\"transplant\",\n    regex=[\n        r\"(?&lt;!pre.?)(greffe|transplant).{1,12}(hepatique|foie)\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=\"chc\",\n        window=(-5, 5),\n    ),\n)\n\ndefault_patterns = [\n    mild,\n    moderate_severe,\n    transplant,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/liver-disease/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"MILD\"</code> for mild liver diseases</li> <li><code>\"MODERATE_TO_SEVERE\"</code> else</li> </ul> </li> </ul>"},{"location":"pipelines/ner/disorders/liver-disease/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.liver_disease\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Il y a une fibrose h\u00e9patique\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [fibrose h\u00e9patique]\n</code></pre> <pre><code>text = \"Une h\u00e9patite B chronique\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [h\u00e9patite B chronique]\n</code></pre> <pre><code>text = \"Le patient consulte pour une cirrhose\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [cirrhose]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: MODERATE_TO_SEVERE\n</code></pre> <pre><code>text = \"Greffe h\u00e9patique.\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [Greffe h\u00e9patique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: MODERATE_TO_SEVERE\n</code></pre>"},{"location":"pipelines/ner/disorders/liver-disease/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.liver_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'mild', 'regex': ['cholangites?.{1,...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>liver_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'liver_disease': True}</code> </p>"},{"location":"pipelines/ner/disorders/liver-disease/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.liver_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/lymphoma/","title":"Lymphoma","text":"<p>The <code>eds.lymphoma</code> pipeline component extracts mentions of lymphoma.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"lymphom(?:.{1,10}hodgkin)\",\n        r\"lymphom\",\n        r\"lymphangio\",\n        r\"sezary\",\n        r\"burkitt\",\n        r\"kaposi\",\n        r\"hodgkin\",\n        r\"amylose\",\n        r\"plasm[ao]cytome\",\n        r\"lympho.{1,3}sarcome\",\n        r\"lympho.?prolif\",\n        r\"hemopathie.{1,10}lymphoide\",\n        r\"macroglobulinemie\",\n        r\"immunocytome\",\n        r\"maladie.des.chaine\",\n        r\"histiocytose.{1,5}(maligne|langerhans)\",\n        r\"waldenst(ro|or)m\",\n        r\"mycos.{1,10}fongoide\",\n        r\"myelome\",\n        r\"maladie.{1,5}immunoproliferative.{1,5}maligne\",\n        r\"leucemie.{1,10}plasmocyte\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLNH\\b\",\n        r\"\\bLH\\b\",\n        r\"\\bEATL\\b\",\n        r\"\\bLAGC\\b\",\n        r\"\\bLDGCB\\b\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=[\"/L\", \"/mL\"],\n        window=10,\n    ),\n)\n\n\ngammapathy = dict(\n    source=\"gammapathy\",\n    regex=[\n        r\"gammapathie monoclonale\",\n    ],\n    exclude=dict(\n        regex=[\n            \"benin\",\n            \"benign\",\n            \"signification.indeter\",\n            \"NMSI\",\n            \"MGUS\",\n        ],\n        window=(0, 5),\n    ),\n    regex_attr=\"NORM\",\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    # gammapathy,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul> <p>Monoclonal gammapathy</p> <p>Monoclonal gammapathies are not extracted by this pipeline</p>"},{"location":"pipelines/ner/disorders/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.lymphoma\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Un lymphome de Hodgkin.\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [lymphome de Hodgkin]\n</code></pre> <pre><code>text = \"Atteint d'un Waldenst\u00f6rm\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [Waldenst\u00f6rm]\n</code></pre> <pre><code>text = \"Un LAGC\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [LAGC]\n</code></pre> <pre><code>text = \"anti LAGC: 10^4/mL\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"pipelines/ner/disorders/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.lymphoma</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'main', 'regex': ['lymphom(?:.{1,10...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>lymphoma</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'lymphoma': True}</code> </p>"},{"location":"pipelines/ner/disorders/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.lymphoma</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/myocardial-infarction/","title":"Myocardial infarction","text":"<p>The <code>eds.myocardial_infarction</code> pipeline component extracts mentions of myocardial infarction. It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Mentions of stents with a heart localization</li> </ul> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import HEART\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"coronaropathie\",\n        r\"angor.{1,5}instable\",\n        r\"cardiopathie(?!.{0,20}non).{0,20}(ischem|arteriosc)\",\n        r\"cardio.?myopathie(?!.{0,20}non).{0,20}(ischem|arteriosc)\",\n        r\"ischemi.{1,15}myocard\",\n        r\"syndrome.{1,5}corona.{1,10}aigu\",\n        r\"syndrome.{1,5}corona.{1,10}st\",\n        r\"pontage.{1,5}mammaire\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"\\bstent\",\n        r\"endoprothese\",\n        r\"pontage\",\n        r\"anevr[iy]sme\",\n        \"infarctus\",\n        r\"angioplasti\",\n    ],\n    assign=[\n        dict(\n            name=\"heart_localized\",\n            regex=\"(\" + r\"|\".join(HEART) + \")\",\n            window=(-10, 10),\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bidm\\b\",\n        r\"\\bsca\\b\",\n        r\"\\batl\\b\",\n    ],\n    regex_attr=\"NORM\",\n    assign=dict(\n        name=\"segment\",\n        regex=r\"st([+-])\",\n        window=2,\n    ),\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    with_localization,\n    acronym,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/myocardial-infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>heart_localized</code>: localization of the stent or bypass</li> </ul> </li> </ul>"},{"location":"pipelines/ner/disorders/myocardial-infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.myocardial_infarction\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Une cardiopathie isch\u00e9mique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [cardiopathie isch\u00e9mique]\n</code></pre> <pre><code>text = \"Une cardiopathie non-isch\u00e9mique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un stent sur la marginale\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [stent sur la marginale]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'heart_localized': [marginale]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un stent p\u00e9riph\u00e9rique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"infarctus du myocarde\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [infarctus du myocarde]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'heart_localized': [myocarde]}\n</code></pre>"},{"location":"pipelines/ner/disorders/myocardial-infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.myocardial_infarction</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['coronaropathie',...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>myocardial_infarction</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'myocardial_infarction': True}</code> </p>"},{"location":"pipelines/ner/disorders/myocardial-infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.myocardial_infarction</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/overview/","title":"Disorders","text":""},{"location":"pipelines/ner/disorders/overview/#presentation","title":"Presentation","text":"<p>The following components extract 16 different conditions from the Charlson Comorbidity Index. Each component is based on the ContextualMatcher component. Some general considerations about those components:</p> <ul> <li>Extracted entities are stored in <code>doc.ents</code> and <code>doc.spans</code>. For instance, the <code>eds.tobacco</code> component stores matches in <code>doc.spans[\"tobacco\"]</code>.</li> <li>The matched comorbidity is also available under the <code>ent.label_</code> of each match.</li> <li>Matches have an associated <code>_.status</code> attribute taking the value <code>0</code>, <code>1</code>, or <code>2</code>. A corresponding <code>_.detailed_status</code> attribute stores the human-readable status, which can be component-dependent. See each component documentation for more details.</li> <li>Some components add additional information to matches. For instance, the <code>tobacco</code> adds, if relevant, extracted pack-year (= paquet-ann\u00e9e). Those information are available under the <code>ent._.assigned</code> attribute.</li> <li> <p>Those components work on normalized documents. Please use the <code>eds.normalizer</code> pipeline with the following parameters:</p> <pre><code>nlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\n</code></pre> </li> <li> <p>Those components should be used with a qualification pipeline to avoid extracted unwanted matches. At the very least, you can use available rule-based qualifiers (<code>eds.negation</code>, <code>eds.hypothesis</code> and <code>eds.family</code>). Better, a machine learning qualification component was developed and trained specifically for those components. For privacy reason, the model isn't publicly available yet.</p> <p>Use the ML model</p> <p>The model will soon be available in the models catalogue of AP-HP's CDW.</p> </li> </ul> <p>On the medical definition of the comorbidities</p> <p>Those components were developped to extract chronic and symptomatic conditions only.</p>"},{"location":"pipelines/ner/disorders/overview/#aggregation","title":"Aggregation","text":"<p>For relevant phenotyping, matches should be aggregated at the document-level. For instance, a document might mention a complicated diabetes at the beginning (\"Le patient a une r\u00e9tinopathie diab\u00e9tique\"), and then refer to this diabetes without mentionning that it is complicated anymore (\"Concernant son diab\u00e8te, le patient ...\"). Thus, a good and simple aggregation rule is, for each comorbidity, to</p> <ul> <li>disregard all entities tagged as irrelevant by the qualification component(s)</li> <li>take the maximum (i.e., the most severe) status of the leftover entities</li> </ul> <p>An implementation of this rule is presented here</p>"},{"location":"pipelines/ner/disorders/peptic-ulcer-disease/","title":"Peptic ulcer disease","text":"<p>The <code>eds.peptic_ulcer_disease</code> pipeline component extracts mentions of peptic ulcer disease.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"ulcere.{1,10}gastr\",\n        r\"ulcere.{1,10}duoden\",\n        r\"ulcere.{1,10}antra\",\n        r\"ulcere.{1,10}pept\",\n        r\"ulcere.{1,10}estomac\",\n        r\"ulcere.{1,10}curling\",\n        r\"ulcere.{1,10}bulb\",\n        r\"(\u0153|oe)sophagites.{1,5}pepti.{1,10}ulcer\",\n        r\"gastrite.{1,20}ulcer\",\n        r\"antrite.{1,5}ulcer\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bUGD\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ngeneric = dict(\n    source=\"generic\",\n    regex=r\"ulcere\",\n    regex_attr=\"NORM\",\n    assign=dict(\n        name=\"is_peptic\",\n        regex=r\"\\b(gastr|digest)\",\n        window=(-20, 20),\n        limit_to_sentence=False,\n    ),\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    generic,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/peptic-ulcer-disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that matches, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/peptic-ulcer-disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.peptic_ulcer_disease\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Beaucoup d'ulc\u00e8res gastriques\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [ulc\u00e8res gastriques]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'UGD\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [UGD]\n</code></pre> <pre><code>text = \"La patient \u00e0 des ulc\u00e8res\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Au niveau gastrique: blabla blabla blabla blabla blabla quelques ulc\u00e8res\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [ulc\u00e8res]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'is_peptic': [gastrique]}\n</code></pre>"},{"location":"pipelines/ner/disorders/peptic-ulcer-disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.peptic_ulcer_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['ulcere.{1,10}gas...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>peptic_ulcer_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'peptic_ulcer_disease': True}</code> </p>"},{"location":"pipelines/ner/disorders/peptic-ulcer-disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.peptic_ulcer_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/peripheral-vascular-disease/","title":"Peripheral vascular disease","text":"<p>The <code>eds.peripheral_vascular_disease</code> pipeline component extracts mentions of peripheral vascular disease.</p> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import ASYMPTOMATIC, BRAIN, HEART, PERIPHERAL\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bAOMI\\b\",\n        r\"\\bACOM\\b\",\n        r\"\\bTAO\\b\",\n        r\"\\bSAPL\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n        r\"\\bSCS\\b\",\n        r\"\\bTVP\\b\",\n        r\"\\bCAPS\\b\",\n        r\"\\bMTEV\\b\",\n        r\"\\bPTT\\b\",\n        r\"\\bMAT\\b\",\n        r\"\\bSHU\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nother = dict(\n    source=\"other\",\n    regex=[\n        r\"\\bbuerger\",\n        r\"takayasu\",\n        r\"\\bhorton\",\n        r\"wegener\",\n        r\"churg.{1,10}strauss\",\n        r\"\\bsneddon\",\n        r\"budd.chiari\",\n        r\"infarctus.{1,5}(renal|splenique|polaire|pulmo)\",\n        r\"ulcere.{1,5}arter\",\n        r\"syndrome.?hemolytique.{1,8}uremique\",\n        r\"granulomatose.{1,10}polyangeite\",\n        r\"occlusion.{1,10}(artere|veine).{1,20}retine\",\n        r\"syndrome.{1,20}anti.?phospho\",\n        r\"embolie.{1,5}pulm\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"angiopathie\",\n        r\"arteriopathies.{1,5}obliterante\",\n        r\"gangren\",\n        r\"claudication\",\n        r\"dissection.{1,10}(aort|arter)\",\n        r\"tromboangeit\",\n        r\"tromboarterit\",\n        r\"(pontage|angioplastie).{1,10}(\\bfem|\\bpop|\\bren|\\bjamb)\",\n        r\"arterite\",\n        r\"(ischemie|infarctus).{1,10}mesenterique\",\n        r\"endarteriectomie\",\n        r\"vascularite\",\n        r\"occlusion.{1,10}terminaisons? carotid\",\n        r\"cryoglobulinemie\",\n        r\"colite.{1,5}ischemi\",\n        r\"embole.{1,10}cholesterol\",\n        r\"purpura.?thrombopenique.?idiopa\",\n        r\"micro.?angiopathie.?thrombotique\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART + ASYMPTOMATIC + [r\"inr\\srecommande\\ssous\\savk\"],\n            window=(-8, 8),\n            limit_to_sentence=False,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nthrombosis = dict(\n    source=\"thrombosis\",\n    regex=[\n        r\"thrombos\",\n        r\"thrombol[^y]\",\n        r\"thrombophi\",\n        r\"thrombi[^n]\",\n        r\"thrombus\",\n        r\"thrombectomi\",\n        r\"thrombo.?embo\",\n        r\"phlebit\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART + [\"superficiel\", \"\\biv\\b\", \"intra.?vein\"],\n            window=(-15, 15),\n            limit_to_sentence=False,\n        ),\n        dict(\n            regex=[\n                \"pre\",\n                \"anti\",\n                \"bilan\",\n            ],\n            window=-4,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\n\nischemia = dict(\n    source=\"ischemia\",\n    regex=[\n        r\"ischemi\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART,\n            window=(-7, 7),\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"peripheral\",\n            regex=\"(\" + r\"|\".join(PERIPHERAL) + \")\",\n            window=15,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nep = dict(\n    source=\"ep\",\n    regex=r\"\\bEP(?![\\w\\./-])\",\n    regex_attr=\"TEXT\",\n    exclude=[\n        dict(\n            regex=[\n                r\"fibreux\",\n                r\"retin\",\n                r\"\\bfove\",\n                r\"\\boct\\b\",\n                r\"\\bmacula\",\n                r\"prosta\",\n                r\"\\bip\\b\",\n                r\"protocole\",\n                r\"seance\",\n                r\"echange\",\n                r\"ritux\",\n                r\"ivig\",\n                r\"ig.?iv\",\n                r\"\\bctc\",\n                r\"corticoide\",\n                r\"serum\",\n                r\"\\bcure\",\n                r\"plasma\",\n                r\"mensuel\",\n                r\"semaine\",\n                r\"serologi\",\n                r\"espaces.porte\",\n                r\"projet\",\n                r\"bolus\",\n            ],\n            window=(-25, 25),\n            limit_to_sentence=False,\n            regex_attr=\"NORM\",\n        ),\n        dict(\n            regex=[r\"rdv\", r\"les\", r\"des\", r\"angine\"],\n            window=(-3, 0),\n            regex_attr=\"NORM\",\n        ),\n    ],\n)\n\nhypertension = dict(\n    source=\"main\",\n    regex=[\n        r\"\\bhta\\b\",\n        r\"hyper.?tension.?arte\",\n        r\"hyper.?tendu\",\n        r\"hyper.?tension.?essenti\",\n        r\"hypertensi\",\n    ],\n    exclude=dict(\n        regex=\"(pulmo|porta)\",\n        window=3,\n    ),\n)\n\ndefault_patterns = [\n    acronym,\n    other,\n    with_localization,\n    thrombosis,\n    ep,\n    ischemia,\n    hypertension,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/peripheral-vascular-disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"pipelines/ner/disorders/peripheral-vascular-disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.peripheral_vascular_disease\")\n</code></pre> <p>Below are a few examples:</p> 12345678910111213 <pre><code>text = \"Un AOMI\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [AOMI]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un infarctus r\u00e9nal\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [infarctus r\u00e9nal]\n</code></pre> <pre><code>text = \"Une angiopathie c\u00e9r\u00e9brale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une angiopathie\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [angiopathie]\n</code></pre> <pre><code>text = \"Une thrombose c\u00e9r\u00e9brale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une thrombose des veines superficielles\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une thrombose\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [thrombose]\n</code></pre> <pre><code>text = \"Effectuer un bilan pre-trombose\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une isch\u00e9mie des MI est remarqu\u00e9e.\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [isch\u00e9mie des MI]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'peripheral': [MI]}\n</code></pre> <pre><code>text = \"Plusieurs cas d'EP\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [EP]\n</code></pre> <pre><code>text = \"Effectuer des cures d'EP\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Le patient est hypertendu\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [hypertendu]\n</code></pre> <pre><code>text = \"Une hypertension portale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"pipelines/ner/disorders/peripheral-vascular-disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.peripheral_vascular_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'acronym', 'regex': ['\\\\bAOMI\\\\b', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>peripheral_vascular_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'peripheral_vascular_disease': T...</code> </p>"},{"location":"pipelines/ner/disorders/peripheral-vascular-disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.peripheral_vascular_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/disorders/solid-tumor/","title":"Solid tumor","text":"<p>The <code>eds.solid_tumor</code> pipeline component extracts mentions of solid tumors. It will notably match:</p> Details of the used patterns <pre><code># fmt: off\nBENINE = r\"benign|benin|(grade.?\\b[i1]\\b)\"\nSTAGE = r\"stade ([^\\s]*)\"\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"carcinom(?!.{0,10}in.?situ)\",\n        r\"seminome\",\n        r\"(?&lt;!lympho)(?&lt;!lympho-)sarcome\",\n        r\"blastome\",\n        r\"cancer([^o]|\\s|\\b)\",\n        r\"adamantinome\",\n        r\"chordome\",\n        r\"craniopharyngiome\",\n        r\"melanome\",\n        r\"neoplasie\",\n        r\"neoplasme\",\n        r\"linite\",\n        r\"melanome\",\n        r\"mesoteliome\",\n        r\"mesotheliome\",\n        r\"seminome\",\n        r\"myxome\",\n        r\"paragangliome\",\n        r\"craniopharyngiome\",\n        r\"k .{0,5}(prostate|sein)\",\n        r\"pancoast.?tobias\",\n        r\"syndrome.{1,10}lynch\",\n        r\"li.?fraumeni\",\n        r\"germinome\",\n        r\"adeno[\\s-]?k\",\n        r\"thymome\",\n        r\"\\bnut\\b\",\n        r\"\\bgist\\b\",\n        r\"\\bchc\\b\",\n        r\"\\badk\\b\",\n        r\"\\btves\\b\",\n        r\"\\btv.tves\\b\",\n        r\"lesion.{1,20}tumor\",\n        r\"tumeur\",\n        r\"carcinoid\",\n        r\"histiocytome\",\n        r\"ependymome\",\n        # r\"primitif\", Trop de FP\n    ],\n    exclude=dict(\n        regex=BENINE,\n        window=(0, 5),\n    ),\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"metastasis\",\n            regex=r\"(metasta|multinodul)\",\n            window=(-3, 7),\n            reduce_mode=\"keep_last\",\n        ),\n        dict(\n            name=\"stage\",\n            regex=STAGE,\n            window=7,\n            reduce_mode=\"keep_last\",\n        ),\n    ],\n)\n\nmetastasis_pattern = dict(\n    source=\"metastasis\",\n    regex=[\n        r\"cellule.{1,5}tumorale.{1,5}circulantes\",\n        r\"metasta\",\n        r\"multinodul\",\n        r\"carcinose\",\n        r\"ruptures.{1,5}corticale\",\n        r\"envahissement.{0,15}parties\\smolle\",\n        r\"(localisation|lesion)s?.{0,20}second\",\n        r\"(lymphangite|meningite).{1,5}carcinomateuse\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=r\"goitre\",\n        window=-3,\n    ),\n)\n\ndefault_patterns = [\n    main_pattern,\n    metastasis_pattern,\n]\n# fmt: on\n</code></pre>"},{"location":"pipelines/ner/disorders/solid-tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"METASTASIS\"</code> for tumors at the metastatic stage</li> <li><code>\"LOCALIZED\"</code> else</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>stage</code>: stage of the tumor</li> </ul> </li> </ul>"},{"location":"pipelines/ner/disorders/solid-tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.solid_tumor\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Pr\u00e9sence d'un carcinome intra-h\u00e9patique.\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [carcinome]\n</code></pre> <pre><code>text = \"Patient avec un K sein.\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [K sein]\n</code></pre> <pre><code>text = \"Il y a une tumeur b\u00e9nigne\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Tumeur m\u00e9tastas\u00e9e\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Tumeur m\u00e9tastas\u00e9e]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n\nspan._.assigned\n# Out: {'metastasis': m\u00e9tastas\u00e9e}\n</code></pre> <pre><code>text = \"Cancer du poumon au stade 4\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Cancer du poumon au stade 4]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n\nspan._.assigned\n# Out: {'stage': 4}\n</code></pre> <pre><code>text = \"Cancer du poumon au stade 2\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Cancer du poumon au stade 2]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': 2}\n</code></pre> <pre><code>text = \"Pr\u00e9sence de nombreuses l\u00e9sions secondaires\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [l\u00e9sions secondaires]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n</code></pre>"},{"location":"pipelines/ner/disorders/solid-tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.solid_tumor</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['carcinom(?!.{0,1...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>solid_tumor</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'solid_tumor': True}</code> </p> <code>use_tnm</code> <p>Whether to use TNM scores matching as well</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/ner/disorders/solid-tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.solid_tumor</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"pipelines/ner/scores/charlson/","title":"Charlson","text":"<p>The <code>eds.charlson</code> component extracts the Charlson Comorbidity Index.</p>"},{"location":"pipelines/ner/scores/charlson/#edsnlp.pipelines.ner.scores.charlson.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.charlson\")\n\ntext = \"\"\"\nCharlson \u00e0 l'admission: 7.\nCharlson:\nOMS:\n\"\"\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (Charlson \u00e0 l'admission: 7,)\n</code></pre> <p>We can see that only one occurrence was extracted. The second mention of Charlson in the text doesn't contain any numerical value, so it isn't extracted.</p>"},{"location":"pipelines/ner/scores/charlson/#edsnlp.pipelines.ner.scores.charlson.factory.create_component--extensions","title":"Extensions","text":"<p>Each extraction exposes 2 extensions:</p> <pre><code>ent = doc.ents[0]\n\nent._.score_name\n# Out: 'charlson'\n\nent._.score_value\n# Out: 7\n</code></pre>"},{"location":"pipelines/ner/scores/charlson/#edsnlp.pipelines.ner.scores.charlson.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'charlson'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'charlson': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"pipelines/ner/scores/elston-ellis/","title":"Elston-Ellis","text":"<p>Matcher for the Elston-Ellis score.</p>"},{"location":"pipelines/ner/scores/elston-ellis/#edsnlp.pipelines.ner.scores.elston_ellis.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.elston_ellis\")\n</code></pre>"},{"location":"pipelines/ner/scores/elston-ellis/#edsnlp.pipelines.ner.scores.elston_ellis.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'TEXT'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'elston_ellis'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'elston_ellis': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"pipelines/ner/scores/emergency-ccmu/","title":"Emergency CCMU","text":"<p>Matcher for explicit mentions of the French CCMU emergency score.</p>"},{"location":"pipelines/ner/scores/emergency-ccmu/#edsnlp.pipelines.ner.scores.emergency.ccmu.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.emergency_ccmu\")\n</code></pre>"},{"location":"pipelines/ner/scores/emergency-ccmu/#edsnlp.pipelines.ner.scores.emergency.ccmu.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value otherwise</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emergency_ccmu'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'emergency_ccmu': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"pipelines/ner/scores/emergency-gemsa/","title":"Emergency GEMSA","text":"<p>Matcher for explicit mentions of the French GEMSA emergency score.</p>"},{"location":"pipelines/ner/scores/emergency-gemsa/#edsnlp.pipelines.ner.scores.emergency.gemsa.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.emergency_gemsa\")\n</code></pre>"},{"location":"pipelines/ner/scores/emergency-gemsa/#edsnlp.pipelines.ner.scores.emergency.gemsa.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value otherwise</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emergency_gemsa'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'emergency_gemsa': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"pipelines/ner/scores/emergency-priority/","title":"Emergency Priority","text":"<p>Matcher for explicit mentions of the French priority emergency score.</p>"},{"location":"pipelines/ner/scores/emergency-priority/#edsnlp.pipelines.ner.scores.emergency.priority.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.emergency_priority\")\n</code></pre>"},{"location":"pipelines/ner/scores/emergency-priority/#edsnlp.pipelines.ner.scores.emergency.priority.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emergency_priority'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'emergency_priority': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"pipelines/ner/scores/overview/","title":"Scores Overview","text":"<p>EDS-NLP provides multiple matchers for typical scores (Charlson, SOFA...) found in clinical documents. To extract a score, the matcher:</p> <ul> <li>extracts the score's name via the provided regular expressions</li> <li>extracts the score's raw value via another set of RegEx</li> <li>normalize the score's value via a normalising function</li> </ul>"},{"location":"pipelines/ner/scores/overview/#available-scores","title":"Available scores","text":"Component Description <code>eds.charlson</code> A Charlson score extractor <code>eds.emergency_ccmu</code> A CCMU score extractor <code>eds.emergency_gemsa</code> A GEMSA score extractor <code>eds.emergency_priority</code> A priority score extractor <code>eds.sofa</code> A SOFA score extractor <code>eds.tnm</code> A TNM score extractor"},{"location":"pipelines/ner/scores/overview/#implementing-your-own-score","title":"Implementing your own score","text":"<p>Using the <code>eds.score</code> pipeline, you only have to change its configuration in order to implement a simple score extraction algorithm. As an example, let us see the configuration used for the <code>eds.charlson</code> pipe The configuration consists of 4 items:</p> <ul> <li><code>score_name</code>: The name of the score</li> <li><code>regex</code>: A list of regular expression to detect the score's mention</li> <li><code>value_extract</code>: A regular expression to extract the score's value in the context of the score's mention</li> <li><code>score_normalization</code>: A function name used to normalise the score's raw value</li> </ul> <p>Note</p> <p>Functions passed as parameters to components need to be registered as follow</p> <pre><code>import spacy\n\n\n@spacy.registry.misc(\"score_normalization.charlson\")\ndef my_normalization_score(raw_score: str):\n    # Implement some filtering here\n    # Return None if you want the score to be discarded\n    return normalized_score\n</code></pre> <p>The values used for the <code>eds.charlson</code> pipe are the following:</p> <pre><code>import spacy\n\n\n@spacy.registry.misc(\"score_normalization.charlson\")\ndef score_normalization(extracted_score):\n\"\"\"\n    Charlson score normalization.\n    If available, returns the integer value of the Charlson score.\n    \"\"\"\n    score_range = list(range(0, 30))\n    if (extracted_score is not None) and (int(extracted_score) in score_range):\n        return int(extracted_score)\n\n\ncharlson_config = dict(\n    score_name=\"charlson\",\n    regex=[r\"charlson\"],\n    value_extract=r\"charlson.*[\\n\\W]*(\\d+)\",\n    score_normalization=\"score_normalization.charlson\",\n)\n</code></pre>"},{"location":"pipelines/ner/scores/sofa/","title":"SOFA","text":"<p>The <code>eds.sofa</code> component extracts Sequential Organ Failure Assessment (SOFA) scores, used to track a person's status during the stay in an intensive care unit to determine the extent of a person's organ function or rate failure.</p>"},{"location":"pipelines/ner/scores/sofa/#edsnlp.pipelines.ner.scores.sofa.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sofa\")\n\ntext = \"\"\"\nSOFA (\u00e0 24H) : 12.\nOMS:\n\"\"\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (SOFA (\u00e0 24H) : 12,)\n</code></pre>"},{"location":"pipelines/ner/scores/sofa/#edsnlp.pipelines.ner.scores.sofa.factory.create_component--extensions","title":"Extensions","text":"<p>Each extraction exposes 3 extensions:</p> <pre><code>ent = doc.ents[0]\n\nent._.score_name\n# Out: 'sofa'\n\nent._.score_value\n# Out: 12\n\nent._.score_method\n# Out: '24H'\n</code></pre> <p>Score method can here be \"24H\", \"Maximum\", \"A l'admission\" or \"Non pr\u00e9cis\u00e9e\"</p>"},{"location":"pipelines/ner/scores/sofa/#edsnlp.pipelines.ner.scores.sofa.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the SOFA score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('CUSTOM_NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex to extract the score value</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex, and should return - None if no score could be extracted - The desired score value else</p> <p> TYPE: <code>Callable[[Union[str, None]], Any]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Flags to pass to the regex</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'sofa'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'sofa': True}</code> </p>"},{"location":"pipelines/qualifiers/family/","title":"Family Context","text":"<p>The <code>eds.family</code> component uses a simple rule-based algorithm to detect spans that describe a family member (or family history) of the patient rather than the patient themself.</p>"},{"location":"pipelines/qualifiers/family/#edsnlp.pipelines.qualifiers.family.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks the family context of the extracted entities. It is complete, and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", osteoporose=\"ost\u00e9oporose\")),\n)\nnlp.add_pipe(\"eds.family\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Il a des ant\u00e9c\u00e9dents familiaux d'ost\u00e9oporose\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, ost\u00e9oporose)\n\ndoc.ents[0]._.family\n# Out: False\n\ndoc.ents[1]._.family\n# Out: True\n</code></pre>"},{"location":"pipelines/qualifiers/family/#edsnlp.pipelines.qualifiers.family.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.family</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>family</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token relates to a family member.</li> <li>The <code>family_</code> property is a human-readable string, computed from the <code>family</code>    attribute. It implements a simple getter function that outputs <code>PATIENT</code> or    <code>FAMILY</code>, depending on the value of <code>family</code>.</li> </ol>"},{"location":"pipelines/qualifiers/family/#edsnlp.pipelines.qualifiers.family.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.family</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>family</code> <p>List of terms indicating family reference.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of syntagms termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_sections</code> <p>Whether to use annotated sections (namely <code>ant\u00e9c\u00e9dents familiaux</code>).</p> <p> TYPE: <code>bool, by default `False`</code> DEFAULT: <code>True</code> </p>"},{"location":"pipelines/qualifiers/family/#edsnlp.pipelines.qualifiers.family.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.family</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/qualifiers/history/","title":"Medical History","text":"<p>The <code>eds.history</code> pipeline uses a simple rule-based algorithm to detect spans that describe medical history rather than the diagnostic of a given visit.</p> <p>The mere definition of a medical history is not straightforward. Hence, this component only tags entities that are explicitly described as part of the medical history, e.g., preceded by a synonym of \"medical history\".</p> <p>This component may also use the output of:</p> <ul> <li>the <code>eds.sections</code> component. In that case, the entire <code>ant\u00e9c\u00e9dent</code> section is tagged as a medical history.</li> </ul> <p>Sections</p> <p>Be careful, the <code>eds.sections</code> component may oversize the <code>ant\u00e9c\u00e9dents</code> section. Indeed, it detects section titles and tags the entire text between a title and the next as a section. Hence, should a section title goes undetected after the <code>ant\u00e9c\u00e9dents</code> title, some parts of the document will erroneously be tagged as a medical history.</p> <p>To curb that possibility, using the output of the <code>eds.sections</code> component is deactivated by default.</p> <ul> <li>the <code>eds.dates</code> component. In that case, it will take the   dates into account to tag extracted entities as a medical history or not.</li> </ul> <p>Dates</p> <p>To take the most of the <code>eds.dates</code> component, you may add the <code>note_datetime</code> context (cf. Adding context). It allows the component to compute the duration of absolute dates (e.g., le 28 ao\u00fbt 2022/August 28, 2022). The <code>birth_datetime</code> context allows the component to exclude the birthdate from the extracted dates.</p>"},{"location":"pipelines/qualifiers/history/#edsnlp.pipelines.qualifiers.history.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are history or not. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\nnlp.add_pipe(\"eds.dates\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", malaise=\"malaises\")),\n)\nnlp.add_pipe(\n    \"eds.history\",\n    config=dict(\n        use_sections=True,\n        use_dates=True,\n    ),\n)\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Il a des ant\u00e9c\u00e9dents de malaises.\"\n    \"ANT\u00c9C\u00c9DENTS : \"\n    \"- le patient a d\u00e9j\u00e0 eu des malaises. \"\n    \"- le patient a eu une douleur \u00e0 la jambe il y a 10 jours\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, malaises, malaises, douleur)\n\ndoc.ents[0]._.history\n# Out: False\n\ndoc.ents[1]._.history\n# Out: True\n\ndoc.ents[2]._.history  # (1)\n# Out: True\n\ndoc.ents[3]._.history  # (2)\n# Out: False\n</code></pre> <ol> <li>The entity is in the section <code>ant\u00e9c\u00e9dent</code>.</li> <li>The entity is in the section <code>ant\u00e9c\u00e9dent</code>, however the extracted <code>relative_date</code> refers to an event that took place within 14 days.</li> </ol>"},{"location":"pipelines/qualifiers/history/#edsnlp.pipelines.qualifiers.history.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.history</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>history</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is a medical history.</li> <li>The <code>history_</code> property is a human-readable string, computed from the <code>history</code>    attribute. It implements a simple getter function that outputs <code>CURRENT</code> or    <code>ATCD</code>, depending on the value of <code>history</code>.</li> </ol>"},{"location":"pipelines/qualifiers/history/#edsnlp.pipelines.qualifiers.history.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.history</code> </p> <code>history</code> <p>List of terms indicating medical history reference.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of syntagms termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>use_sections</code> <p>Whether to use section pipeline to detect medical history section.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_dates</code> <p>Whether to use dates pipeline to detect if the event occurs  a long time before the document date.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>history_limit</code> <p>The number of days after which the event is considered as history.</p> <p> TYPE: <code>Union[int, timedelta]</code> DEFAULT: <code>14</code> </p> <code>exclude_birthdate</code> <p>Whether to exclude the birthdate from history dates.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>closest_dates_only</code> <p>Whether to include the closest dates only.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/qualifiers/history/#edsnlp.pipelines.qualifiers.history.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.history</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/qualifiers/hypothesis/","title":"Hypothesis","text":"<p>The <code>eds.hypothesis</code> pipeline uses a simple rule-based algorithm to detect spans that are speculations rather than certain statements.</p> <p>The component looks for five kinds of expressions in the text :</p> <ul> <li>preceding hypothesis, ie cues that precede a hypothetical expression</li> <li>following hypothesis, ie cues that follow a hypothetical expression</li> <li>pseudo hypothesis : contain a hypothesis cue, but are not hypothesis   (eg \"pas de doute\"/\"no doubt\")</li> <li>hypothetical verbs : verbs indicating hypothesis (eg \"douter\")</li> <li>classic verbs conjugated to the conditional, thus indicating hypothesis</li> </ul> <ol><li><p><p>Dalloux C., Claveau V. and Grabar N., 2017. D\u00e9tection de la n\u00e9gation : corpus fran\u00e7ais et apprentissage supervis\u00e9.</p></p></li><li><p><p>Grabar N., Claveau V. and Dalloux C., 2018. CAS: French Corpus with Clinical Cases.</p></p></li></ol>"},{"location":"pipelines/qualifiers/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are part of a speculation. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", fracture=\"fracture\")),\n)\nnlp.add_pipe(\"eds.hypothesis\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Possible fracture du radius.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, fracture)\n\ndoc.ents[0]._.hypothesis\n# Out: False\n\ndoc.ents[1]._.hypothesis\n# Out: True\n</code></pre>"},{"location":"pipelines/qualifiers/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.hypothesis</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>hypothesis</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is a speculation.</li> <li>The <code>hypothesis_</code> property is a human-readable string, computed from the    <code>hypothesis</code> attribute. It implements a simple getter function that outputs    <code>HYP</code> or <code>CERT</code>, depending on the value of <code>hypothesis</code>.</li> </ol>"},{"location":"pipelines/qualifiers/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--performance","title":"Performance","text":"<p>The component's performance is measured on three datasets :</p> <ul> <li>The ESSAI (Dalloux et al., 2017) and CAS (Grabar et al., 2018) datasets were developed   at the CNRS. The two are concatenated.</li> <li>The NegParHyp corpus was specifically developed at APHP's CDW to test the   component on actual clinical notes, using pseudonymised notes from the APHP's CDW.</li> </ul> Dataset Hypothesis F1 CAS/ESSAI 49% NegParHyp 52% <p>NegParHyp corpus</p> <p>The NegParHyp corpus was built by matching a subset of the MeSH terminology with around 300 documents from AP-HP's clinical data warehouse. Matched entities were then labelled for negation, speculation and family context.</p>"},{"location":"pipelines/qualifiers/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.hypothesis</code> </p> <code>attr</code> <p>spaCy's attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>pseudo</code> <p>List of pseudo hypothesis cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of preceding hypothesis cues</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of following hypothesis cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs_hyp</code> <p>List of hypothetical verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs_eds</code> <p>List of mainstream verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr'</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/qualifiers/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.hypothesis</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/qualifiers/negation/","title":"Negation","text":"<p>The <code>eds.negation</code> component uses a simple rule-based algorithm to detect negated spans. It was designed at AP-HP's EDS, following the insights of the NegEx algorithm by Chapman et al., 2001.</p> <p>The component looks for five kinds of expressions in the text :</p> <ul> <li>preceding negations, i.e., cues that precede a negated expression</li> <li>following negations, i.e., cues that follow a negated expression</li> <li>pseudo negations : contain a negation cue, but are not negations   (eg \"pas de doute\"/\"no doubt\")</li> <li>negation verbs, i.e., verbs that indicate a negation</li> <li>terminations, i.e., words that delimit propositions.   The negation spans from the preceding cue to the termination.</li> </ul> <ol><li><p><p>Chapman W.W., Bridewell W., Hanbury P., Cooper G.F. and Buchanan B.G., 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics. 34, pp.301--310. 10.1006/jbin.2001.1029</p></p></li><li><p><p>Dalloux C., Claveau V. and Grabar N., 2017. D\u00e9tection de la n\u00e9gation : corpus fran\u00e7ais et apprentissage supervis\u00e9.</p></p></li><li><p><p>Grabar N., Claveau V. and Dalloux C., 2018. CAS: French Corpus with Clinical Cases.</p></p></li></ol>"},{"location":"pipelines/qualifiers/negation/#edsnlp.pipelines.qualifiers.negation.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks the polarity of the extracted entities. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(patient=\"patient\", fracture=\"fracture\")),\n)\nnlp.add_pipe(\"eds.negation\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Le scanner ne d\u00e9tecte aucune fracture.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (patient, fracture)\n\ndoc.ents[0]._.negation  # (1)\n# Out: False\n\ndoc.ents[1]._.negation\n# Out: True\n</code></pre> <ol> <li>The result of the component is kept in the <code>negation</code> custom extension.</li> </ol>"},{"location":"pipelines/qualifiers/negation/#edsnlp.pipelines.qualifiers.negation.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.negation</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>negation</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is negated.</li> <li>The <code>negation_</code> property is a human-readable string, computed from the <code>negation</code>    attribute. It implements a simple getter function that outputs <code>AFF</code> or <code>NEG</code>,    depending on the value of <code>negation</code>.</li> </ol>"},{"location":"pipelines/qualifiers/negation/#edsnlp.pipelines.qualifiers.negation.factory.create_component--performance","title":"Performance","text":"<p>The component's performance is measured on three datasets :</p> <ul> <li>The ESSAI (Dalloux et al., 2017) and CAS (Grabar et al., 2018) datasets were developed   at the CNRS. The two are concatenated.</li> <li>The NegParHyp corpus was specifically developed at AP-HP to test the component   on actual clinical notes, using pseudonymised notes from the AP-HP.</li> </ul> Dataset Negation F1 CAS/ESSAI 71% NegParHyp 88% <p>NegParHyp corpus</p> <p>The NegParHyp corpus was built by matching a subset of the MeSH terminology with around 300 documents from AP-HP's clinical data warehouse. Matched entities were then labelled for negation, speculation and family context.</p>"},{"location":"pipelines/qualifiers/negation/#edsnlp.pipelines.qualifiers.negation.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.negation</code> </p> <code>attr</code> <p>spaCy's attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>pseudo</code> <p>List of pseudo negation cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of preceding negation cues</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of following negation cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs</code> <p>List of negation verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/qualifiers/negation/#edsnlp.pipelines.qualifiers.negation.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.negation</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/qualifiers/overview/","title":"Qualifier Overview","text":"<p>In EDS-NLP, we call qualifiers the suite of components designed to qualify a pre-extracted entity for a linguistic modality.</p>"},{"location":"pipelines/qualifiers/overview/#available-components","title":"Available components","text":"Pipeline Description <code>eds.negation</code> Rule-based negation detection <code>eds.family</code> Rule-based family context detection <code>eds.hypothesis</code> Rule-based speculation detection <code>eds.reported_speech</code> Rule-based reported speech detection <code>eds.history</code> Rule-based medical history detection"},{"location":"pipelines/qualifiers/overview/#rationale","title":"Rationale","text":"<p>In a typical medical NLP pipeline, a group of clinicians would define a list of synonyms for a given concept of interest (say, for example, diabetes), and look for that terminology in a corpus of documents.</p> <p>Now, consider the following example:</p> FrenchEnglish <pre><code>Le patient n'est pas diab\u00e9tique.\nLe patient est peut-\u00eatre diab\u00e9tique.\nLe p\u00e8re du patient est diab\u00e9tique.\n</code></pre> <pre><code>The patient is not diabetic.\nThe patient could be diabetic.\nThe patient's father is diabetic.\n</code></pre> <p>There is an obvious problem: none of these examples should lead us to include this particular patient into the cohort.</p> <p>Warning</p> <p>We show an English example just to explain the issue. EDS-NLP remains a French-language medical NLP library.</p> <p>To curb this issue, EDS-NLP proposes rule-based pipelines that qualify entities to help the user make an informed decision about which patient should be included in a real-world data cohort.</p>"},{"location":"pipelines/qualifiers/overview/#edsnlp.pipelines.base.SpanGetterArg","title":"Which spans are qualified ?","text":"<p>A component get entities from a document by looking up <code>doc.ents</code> or <code>doc.spans[group]</code>. This behavior is set by the <code>span_getter</code> argument in components that support it.</p> <p>Valid values for the <code>span_getter</code> argument of a component can be :</p> <ul> <li>a (doc) -&gt; spans callable</li> <li>a span group name</li> <li>a list of span group names</li> <li>a dict of group name to True or list of labels</li> </ul> <p>The group name <code>\"ents\"</code> is a special case, and will get the matches from <code>doc.ents</code></p>"},{"location":"pipelines/qualifiers/overview/#edsnlp.pipelines.base.SpanGetterArg--examples","title":"Examples","text":"<ul> <li><code>span_getter=[\"ents\", \"ckd\"]</code> will get the matches from both <code>doc.ents</code> and <code>doc.spans[\"ckd\"]</code>. It is equivalent to <code>{\"ents\": True, \"ckd\": True}</code>.</li> <li><code>span_getter={\"ents\": [\"foo\", \"bar\"]}</code> will get the matches with label \"foo\" and \"bar\" from <code>doc.ents</code>.</li> <li><code>span_getter=\"ents\"</code> will get all matches from <code>doc.ents</code>.</li> <li><code>span_getter=\"ckd\"</code> will get all matches from <code>doc.spans[\"ckd\"]</code>.</li> </ul>"},{"location":"pipelines/qualifiers/overview/#under-the-hood","title":"Under the hood","text":"<p>Our qualifier pipelines all follow the same basic pattern:</p> <ol> <li> <p>The pipeline extracts cues. We define three (possibly overlapping) kinds :</p> <ul> <li><code>preceding</code>, ie cues that precede modulated entities ;</li> <li><code>following</code>, ie cues that follow modulated entities ;</li> <li>in some cases, <code>verbs</code>, ie verbs that convey a modulation (treated as preceding cues).</li> </ul> </li> <li> <p>The pipeline splits the text between sentences and propositions, using annotations from a sentencizer pipeline and <code>termination</code> patterns, which define syntagma/proposition terminations.</p> </li> <li> <p>For each pre-extracted entity, the pipeline checks whether there is a cue between the start of the syntagma and the start of the entity, or a following cue between the end of the entity and the end of the proposition.</p> </li> </ol> <p>Albeit simple, this algorithm can achieve very good performance depending on the modality. For instance, our <code>eds.negation</code> pipeline reaches 88% F1-score on our dataset.</p> <p>Dealing with pseudo-cues</p> <p>The pipeline can also detect pseudo-cues, ie phrases that contain cues but that are not cues themselves. For instance: <code>sans doute</code>/<code>without doubt</code> contains <code>sans/without</code>, but does not convey negation.</p> <p>Detecting pseudo-cues lets the pipeline filter out any cue that overlaps with a pseudo-cue.</p> <p>Sentence boundaries are required</p> <p>The rule-based algorithm detects cues, and propagate their modulation on the rest of the syntagma. For that reason, a qualifier pipeline needs a sentencizer component to be defined, and will fail otherwise.</p> <p>You may use EDS-NLP's:</p> <pre><code>nlp.add_pipe(\"eds.sentences\")\n</code></pre>"},{"location":"pipelines/qualifiers/overview/#persisting-the-results","title":"Persisting the results","text":"<p>Our qualifier pipelines write their results to a custom spaCy extension, defined on both <code>Span</code> and <code>Token</code> objects. We follow the convention of naming said attribute after the pipeline itself, eg <code>Span._.negation</code> for the<code>eds.negation</code> pipeline.</p> <p>We also provide a string representation of the result, computed on the fly by declaring a getter that reads the boolean result of the pipeline. Following spaCy convention, we give this attribute the same name, followed by a <code>_</code>.</p>"},{"location":"pipelines/qualifiers/reported-speech/","title":"Reported Speech","text":"<p>The <code>eds.reported_speech</code> component uses a simple rule-based algorithm to detect spans that relate to reported speech (eg when the doctor quotes the patient). It was designed at AP-HP's EDS.</p>"},{"location":"pipelines/qualifiers/reported-speech/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are part of a reported speech. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(patient=\"patient\", alcool=\"alcoolis\u00e9\")),\n)\nnlp.add_pipe(\"eds.reported_speech\")\n\ntext = (\n    \"Le patient est admis aux urgences ce soir pour une douleur au bras. \"\n    \"Il nie \u00eatre alcoolis\u00e9.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (patient, alcoolis\u00e9)\n\ndoc.ents[0]._.reported_speech\n# Out: False\n\ndoc.ents[1]._.reported_speech\n# Out: True\n</code></pre>"},{"location":"pipelines/qualifiers/reported-speech/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.reported_speech</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>reported_speech</code> attribute is a boolean, set to <code>True</code> if the component    predicts that the span/token is reported.</li> <li>The <code>reported_speech_</code> property is a human-readable string, computed from the    <code>reported_speech</code> attribute. It implements a simple getter function that outputs    <code>DIRECT</code> or <code>REPORTED</code>, depending on the value of <code>reported_speech</code>.</li> </ol>"},{"location":"pipelines/qualifiers/reported-speech/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.reported_speech</code> </p> <code>quotation</code> <p>String gathering all quotation cues.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>verbs</code> <p>List of reported speech verbs.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of terms following a reported speech.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of terms preceding a reported speech.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"pipelines/qualifiers/reported-speech/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.reported_speech</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"pipelines/trainable/","title":"Trainable components overview","text":"<p>In addition to its rule-based pipeline components, EDS-NLP offers new trainable pipelines to fit and run machine learning models for classic biomedical information extraction tasks.</p>"},{"location":"pipelines/trainable/#available-components","title":"Available components :","text":"Name Description <code>eds.nested_ner</code> Recognize overlapping or nested entities (replaces spaCy's <code>ner</code> component) <p>Writing custom models</p> <p>spaCy models can be written with Thinc (spaCy's deep learning library), Tensorflow or Pytorch. As Pytorch is predominant in the NLP research field, we recommend writing models with the latter to facilitate interactions with the NLP community. To this end, we have written some Pytorch wrapping utilities like wrap_pytorch_model to allow loss and predictions to be computed directly in the Pytorch module.</p>"},{"location":"pipelines/trainable/#utils","title":"Utils","text":""},{"location":"pipelines/trainable/#training","title":"Training","text":"<p>In addition to the spaCy <code>train</code> CLI, EDS-NLP offers a <code>train</code> function that can be called in Python directly with an existing spaCy pipeline.</p> <p>Experimental</p> <p>This training API is an experimental feature of edsnlp and could change at any time.</p>"},{"location":"pipelines/trainable/#usage","title":"Usage","text":"<p>Let us define and train a full pipeline :</p> <pre><code>from pathlib import Path\n\nimport spacy\n\nfrom edsnlp.connectors.brat import BratConnector\nfrom edsnlp.utils.training import train, make_spacy_corpus_config\n\ntmp_path = Path(\"/tmp/test-train\")\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"nested_ner\")  # (1)\n\n# Train the model, with additional training configuration\nnlp = train(\n    nlp,\n    output_path=tmp_path / \"model\",\n    config=dict(\n        **make_spacy_corpus_config(\n            train_data=\"/path/to/the/training/set/brat/files\",\n            dev_data=\"/path/to/the/dev/set/brat/files\",\n            nlp=nlp,\n            data_format=\"brat\",\n        ),\n        training=dict(\n            max_steps=4000,\n        ),\n    ),\n)\n\n# Finally, we can run the pipeline on a new document\ndoc = nlp(\"Arret du folfox si inefficace\")\ndoc.spans[\"drug\"]\n# Out: [folfox]\n\ndoc.spans[\"criteria\"]\n# Out: [si folfox inefficace]\n\n# And export new predictions as Brat annotations\npredicted_docs = BratConnector(\"/path/to/the/new/files\", run_pipe=True).brat2docs(nlp)\nBratConnector(\"/path/to/predictions\").docs2brat(predicted_docs)\n</code></pre> <ol> <li>you can configure the component using the <code>add_pipe(..., config=...)</code> parameter</li> </ol> <ol></ol>"},{"location":"pipelines/trainable/ner/","title":"Nested Named Entity Recognition","text":"<p>The default spaCy Named Entity Recognizer (NER) pipeline only allows flat entity recognition, meaning that overlapping and nested entities cannot be extracted.</p> <p>The other spaCy component <code>SpanCategorizer</code> only supports assigning to a specific span group and both components are not well suited for extracting entities with ill-defined boundaries (this can occur if your training data contains difficult and long entities).</p> <p>We propose the new <code>eds.ner</code> component to extract almost any named entity:</p> <ul> <li>flat entities like spaCy's <code>EntityRecognizer</code> overlapping entities</li> <li>overlapping entities of different labels (much like spaCy's <code>SpanCategorizer</code>)</li> <li>entities will ill-defined boundaries</li> </ul> <p>However, the model cannot currently extract entities that are nested inside larger entities of the same label.</p> <p>The pipeline assigns both <code>doc.ents</code> (in which overlapping entities are filtered out) and <code>doc.spans</code>.</p>"},{"location":"pipelines/trainable/ner/#architecture","title":"Architecture","text":"<p>The model performs token classification using the BIOUL (Begin, Inside, Outside, Unary, Last) tagging scheme. To extract overlapping entities, each label has its own tag sequence, so the model predicts <code>n_labels</code> sequences of O, I, B, L, U tags. The architecture is displayed in the figure below.</p> <p>To enforce the tagging scheme, (ex: I cannot follow O but only B, ...), we use a stack of CRF (Conditional Random Fields) layers, one per label during both training and prediction.</p> <p> </p> Nested NER architecture"},{"location":"pipelines/trainable/ner/#usage","title":"Usage","text":"<p>Let us define the pipeline and train it:</p> <pre><code>from pathlib import Path\n\nimport spacy\n\nfrom edsnlp.connectors.brat import BratConnector\nfrom edsnlp.utils.training import train, make_spacy_corpus_config\n\ntmp_path = Path(\"/tmp/test-nested-ner\")\n\nnlp = spacy.blank(\"eds\")\n# \u2193 below is the nested ner pipeline \u2193\n# you can configure it using the `add_pipe(..., config=...)` parameter\nnlp.add_pipe(\"nested_ner\")\n\n# Train the model, with additional training configuration\nnlp = train(\n    nlp,\n    output_path=tmp_path / \"model\",\n    config=dict(\n        **make_spacy_corpus_config(\n            train_data=\"/path/to/the/training/set/brat/files\",\n            dev_data=\"/path/to/the/dev/set/brat/files\",\n            nlp=nlp,\n            data_format=\"brat\",\n        ),\n        training=dict(\n            max_steps=4000,\n        ),\n    ),\n)\n\n# Finally, we can run the pipeline on a new document\ndoc = nlp(\"Arret du folfox si inefficace\")\ndoc.spans[\"drug\"]\n# Out: [folfox]\n\ndoc.spans[\"criteria\"]\n# Out: [si folfox inefficace]\n\n# And export new predictions as Brat annotations\npredicted_docs = BratConnector(\"/path/to/the/new/files\", run_pipe=True).brat2docs(nlp)\nBratConnector(\"/path/to/predictions\").docs2brat(predicted_docs)\n</code></pre>"},{"location":"pipelines/trainable/ner/#configuration","title":"Configuration","text":"<p>The pipeline component can be configured using the following parameters :</p> <p>The default model <code>eds.nested_ner_model.v1</code> can be configured using the following parameters :</p>"},{"location":"pipelines/trainable/ner/#edsnlp.pipelines.trainable.nested_ner.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>model</code> <p>The model to extract the spans</p> <p> TYPE: <code>Model</code> </p> <code>ent_labels</code> <p>list of labels to filter entities for in <code>doc.ents</code></p> <p> DEFAULT: <code>None</code> </p> <code>spans_labels</code> <p>Mapping from span group names to list of labels to look for entities and assign the predicted entities</p> <p> DEFAULT: <code>None</code> </p>"},{"location":"pipelines/trainable/ner/#edsnlp.pipelines.trainable.nested_ner.factory.create_component--parameters","title":"Parameters","text":""},{"location":"pipelines/trainable/ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.create_model--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>tok2vec</code> <p>The tok2vec embedding model used to generate the word embeddings</p> <p> TYPE: <code>Model[List[Doc], List[Floats2d]]</code> </p> <code>mode</code> <p>How the CRF loss is computed</p> <ul> <li><code>joint</code>: Loss accounts for CRF transitions</li> <li><code>independent</code>: Loss does not account for CRF transitions (softmax loss)</li> <li><code>marginal</code>: Tag scores are smoothly updated with CRF transitions, and softmax loss is applied</li> </ul> <p> TYPE: <code>CRFMode</code> </p> <code>n_labels</code> <p>Number of labels. This will be automatically set later during initialization</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p>"},{"location":"pipelines/trainable/ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.create_model--parameters","title":"Parameters","text":""},{"location":"pipelines/trainable/ner/#authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.nested_ner</code> pipeline was developed by AP-HP's Data Science team.</p> <p>The deep learning model was adapted from Wajsb\u00fcrtWajsb\\\"urt, 2021</p> <p>\\bibliography</p> <ol><li><p><p>Wajsb\\\"urt P., 2021. Extraction and normalization of simple and structured entities in medical documents.</p></p></li></ol>"},{"location":"pipelines/trainable/span-qualifier/","title":"Span qualification","text":"<p>We propose the new <code>span_qualifier</code> component to qualify (i.e. assign attributes on) any span with machine learning. In this context, the span qualification task consists in assigning values (boolean, strings or any complex object) to attributes/extensions of spans such as:</p> <ul> <li><code>span.label_</code>,</li> <li><code>span._.negation</code>,</li> <li><code>span._.date.mode</code></li> <li>etc.</li> </ul>"},{"location":"pipelines/trainable/span-qualifier/#architecture","title":"Architecture","text":"<p>The underlying <code>eds.span_multilabel_classifier.v1</code> model performs span classification by:</p> <ol> <li>Pooling the words embedding (<code>mean</code>, <code>max</code> or <code>sum</code>) into a single embedding per span</li> <li>Computing logits for each possible binding (i.e. qualifier-value assignment)</li> <li> <p>Splitting these bindings into independent groups such as</p> <ul> <li><code>event_type=start</code> and <code>event_type=stop</code></li> <li><code>negated=False</code> and <code>negated=True</code></li> </ul> </li> <li> <p>Learning or predicting a combination amongst legal combination of these bindings. For instance in the second group, we can't have both <code>negated=True</code> and <code>negated=False</code> so the combinations are <code>[(1, 0), (0, 1)]</code></p> </li> <li>Assigning bindings on spans depending on the predicted results</li> </ol>"},{"location":"pipelines/trainable/span-qualifier/#under-the-hood","title":"Under the hood","text":""},{"location":"pipelines/trainable/span-qualifier/#initialization","title":"Initialization","text":"<p>During the initialization of the pipeline, the <code>span_qualifier</code> component will gather all spans that match <code>on_ents</code> and <code>on_span_groups</code> patterns (or <code>candidate_getter</code> function). It will then list all possible values for each <code>qualifier</code> of the <code>qualifiers</code> list and store every possible (qualifier, value) pair (i.e. binding).</p> <p>For instance, a custom qualifier <code>negation</code> with possible values <code>True</code> and <code>False</code> will result in the following bindings <code>[(\"_.negation\", True), (\"_.negation\", False)]</code>, while a custom qualifier <code>event_type</code> with possible values <code>start</code>, <code>stop</code>, and <code>start-stop</code> will result in the following bindings <code>[(\"_.event_type\", \"start\"), (\"_.event_type\", \"stop\"), (\"_.event_type\", \"start-stop\")]</code>.</p>"},{"location":"pipelines/trainable/span-qualifier/#training","title":"Training","text":"<p>During training, the <code>span_qualifier</code> component will gather spans on the documents in a mini-batch and evaluate each binding on each span to build a supervision matrix. This matrix will be feed it to the underlying model (most likely a <code>eds.span_multilabel_classifier.v1</code>). The model will compute logits for each entry of the matrix and compute a cross-entropy loss for each group of bindings sharing the same qualifier. The loss will not be computed for entries that violate the <code>label_constraints</code> parameter (for instance, the <code>event_type</code> qualifier can only be assigned to spans with the <code>event</code> label).</p>"},{"location":"pipelines/trainable/span-qualifier/#prediction","title":"Prediction","text":"<p>During prediction, the <code>span_qualifier</code> component will gather spans on a given document and evaluate each binding on each span using the underlying model. Using the same binding exclusion and label constraint mechanisms as during training, scores will be computed for each binding and the best legal combination of bindings will be selected. Finally, the selected bindings will be assigned to the spans.</p>"},{"location":"pipelines/trainable/span-qualifier/#usage","title":"Usage","text":"<p>Let us define the pipeline and train it. We provide utils to train the model using an API, but you can use a spaCy's config file as well.</p> API-based (Light)Configuration-based (Light)Configuration-based (BERT) <pre><code>from pathlib import Path\n\nimport spacy\n\nfrom edsnlp.connectors.brat import BratConnector\nfrom edsnlp.utils.training import train, make_spacy_corpus_config\nfrom edsnlp.pipelines.trainable.span_qualifier import SPAN_QUALIFIER_DEFAULTS\n\ntmp_path = Path(\"/tmp/test-span-qualifier\")\n\nnlp = spacy.blank(\"eds\")\n# \u2193 below is the span qualifier pipeline \u2193\n# you can configure it using the `add_pipe(..., config=...)` parameter\nnlp.add_pipe(\n    \"span_qualifier\",\n    config={\n        **SPAN_QUALIFIER_DEFAULTS,\n        # Two qualifiers: binary `_.negation` and multi-class `_.event_type`\n        \"qualifiers\": (\"_.negation\", \"_.event_type\"),\n        # Only predict on entities, not on span groups\n        \"from_ents\": True,\n        \"from_span_groups\": False,\n        \"label_constraints\": {\n            # Only allow `_.event_type` qualifier on events\n            \"_.event_type\": (\"event\",),\n        },\n        \"model\": {\n            **SPAN_QUALIFIER_DEFAULTS[\"model\"],\n            \"pooler_mode\": \"mean\",\n            \"classifier_mode\": \"dot\",\n        },\n    },\n)\n\n# Train the model, with additional training configuration\nnlp = train(\n    nlp,\n    output_path=tmp_path / \"model\",\n    config=dict(\n        **make_spacy_corpus_config(\n            train_data=\"/path/to/the/training/set/brat/files\",\n            dev_data=\"/path/to/the/dev/set/brat/files\",\n            nlp=nlp,\n            data_format=\"brat\",\n        ),\n        training=dict(\n            max_steps=100,\n        ),\n    ),\n)\n\n# Finally, we can run the pipeline on a new document\ndoc = nlp.make_doc(\"Arret du ttt si folfox inefficace\")\ndoc.ents = [\n    # event = \"Arret\"\n    spacy.tokens.Span(doc, 0, 1, \"event\"),\n    # criteria = \"si\"\n    spacy.tokens.Span(doc, 3, 4, \"criteria\"),\n    # drug = \"folfox\"\n    spacy.tokens.Span(doc, 4, 5, \"drug\"),\n]\ndoc = nlp(doc)\n\n[ent._.negation for ent in doc.ents]\n# Out: [True, False, False]\n\n[ent._.event_type for ent in doc.ents]\n# Out: [\"start\", None, None]\n\n# And export new predictions as Brat annotations\npredicted_docs = BratConnector(\"/path/to/the/new/files\", run_pipe=True).brat2docs(nlp)\nBratConnector(\"/path/to/predictions\").docs2brat(predicted_docs)\n</code></pre> config.cfg<pre><code>[paths]\ntrain = null\ndev = null\nvectors = null\ninit_tok2vec = null\nraw = null\n\n[system]\nseed = 0\ngpu_allocator = null\n\n[nlp]\nlang = \"eds\"\npipeline = [\"span_qualifier\"]\n\n[components]\n\n[components.span_qualifier]\nfactory = \"span_qualifier\"\nlabel_constraints = null\nfrom_ents = false\nfrom_span_groups = true\nqualifiers = [\"label_\"]\nscorer = {\"@scorers\":\"eds.span_qualifier_scorer.v1\"}\n\n[components.span_qualifier.model]\n@architectures = \"eds.span_multi_classifier.v1\"\nprojection_mode = \"dot\"\npooler_mode = \"max\"\nn_labels = null\n\n[components.span_qualifier.model.tok2vec]\n@architectures = \"spacy.Tok2Vec.v1\"\n\n[components.span_qualifier.model.tok2vec.embed]\n@architectures = \"spacy.MultiHashEmbed.v1\"\nwidth = 96\nrows = [5000,2000,1000,1000]\nattrs = [\"ORTH\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\ninclude_static_vectors = false\n\n[components.span_qualifier.model.tok2vec.encode]\n@architectures = \"spacy.MaxoutWindowEncoder.v1\"\nwidth = 96\nwindow_size = 1\nmaxout_pieces = 3\ndepth = 4\n\n[corpora]\n\n[corpora.train]\n@readers = \"test-span-classification-corpus\"\npath = ${path.train}\nmax_length = 0\ngold_preproc = false\nlimit = 0\naugmenter = null\n\n[corpora.dev]\n@readers = \"test-span-classification-corpus\"\npath = ${path.dev}\nmax_length = 0\ngold_preproc = false\nlimit = 0\naugmenter = null\n\n[training]\nseed = ${system.seed}\ngpu_allocator = ${system.gpu_allocator}\ndropout = 0.1\naccumulate_gradient = 1\npatience = 10000\nmax_epochs = 0\nmax_steps = 10\neval_frequency = 5\nfrozen_components = []\nannotating_components = []\ndev_corpus = \"corpora.dev\"\ntrain_corpus = \"corpora.train\"\nbefore_to_disk = null\nbefore_update = null\n\n[training.batcher]\n@batchers = \"spacy.batch_by_words.v1\"\ndiscard_oversize = false\ntolerance = 0.2\nget_length = null\n\n[training.batcher.size]\n@schedules = \"compounding.v1\"\nstart = 100\nstop = 1000\ncompound = 1.001\nt = 0.0\n\n[training.logger]\n@loggers = \"spacy.ConsoleLogger.v1\"\nprogress_bar = false\n\n[training.optimizer]\n@optimizers = \"Adam.v1\"\nbeta1 = 0.9\nbeta2 = 0.999\nL2_is_weight_decay = true\nL2 = 0.01\ngrad_clip = 1.0\nuse_averages = false\neps = 0.00000001\nlearn_rate = 0.001\n\n[training.score_weights]\naccuracy = 1.0\n\n[pretraining]\n\n[initialize]\nvectors = ${paths.vectors}\ninit_tok2vec = ${paths.init_tok2vec}\nvocab_data = null\nlookups = null\nbefore_init = null\nafter_init = null\n\n[initialize.components]\n\n[initialize.tokenizer]\n</code></pre> <p>To train it, run the following command :</p> <pre><code>spacy train config.cfg --output training/ --paths.train your_corpus/train.spacy --paths.dev your_corpus/dev.spacy\n</code></pre> <p>To use it, load the model and process a text :</p> <pre><code>import spacy\n\nnlp = spacy.load(\"training/model-best\")\ndoc = nlp.make_doc(\"Arret du ttt si folfox inefficace\")\ndoc.ents = [\n    # event = \"Arret\"\n    spacy.tokens.Span(doc, 0, 1, \"event\"),\n    # criteria = \"si\"\n    spacy.tokens.Span(doc, 3, 4, \"criteria\"),\n    # drug = \"folfox\"\n    spacy.tokens.Span(doc, 4, 5, \"drug\"),\n]\ndoc = nlp(doc)\n\n[ent._.negation for ent in doc.ents]\n# Out: [True, False, False]\n\n[ent._.event_type for ent in doc.ents]\n# Out: [\"start\", None, None]\n</code></pre> config.cfg<pre><code>[paths]\nbert = \"camembert-base\"\ntrain = null\ndev = null\nvectors = null\ninit_tok2vec = null\nraw = null\n\n[system]\nseed = 0\ngpu_allocator = \"pytorch\"\n\n[nlp]\nlang = \"eds\"\npipeline = [\"span_qualifier\"]\n\n[components]\n\n[components.span_qualifier]\nfactory = \"span_qualifier\"\nlabel_constraints = null\nfrom_ents = false\nfrom_span_groups = true\nqualifiers = [\"label_\"]\nscorer = {\"@scorers\":\"eds.span_qualifier_scorer.v1\"}\n\n[components.span_qualifier.model]\n@architectures = \"eds.span_multi_classifier.v1\"\nprojection_mode = \"dot\"\npooler_mode = \"max\"\nn_labels = null\n\n# (1) We use a transformer instead below here\n[components.span_qualifier.model.tok2vec]\n@architectures = \"spacy-transformers.Tok2VecTransformer.v3\"\nname = ${path.bert}\ntokenizer_config = {\"use_fast\": false}\ntransformer_config = {}\ngrad_factor = 1.0\nmixed_precision = true\ngrad_scaler_config = {\"init_scale\": 32768}\n\n[corpora]\n\n[corpora.train]\n@readers = \"test-span-classification-corpus\"\npath = ${path.train}\nmax_length = 0\ngold_preproc = false\nlimit = 0\naugmenter = null\n\n[corpora.dev]\n@readers = \"test-span-classification-corpus\"\npath = ${path.dev}\nmax_length = 0\ngold_preproc = false\nlimit = 0\naugmenter = null\n\n[training]\nseed = ${system.seed}\ngpu_allocator = ${system.gpu_allocator}\ndropout = 0.1\naccumulate_gradient = 1\npatience = 10000\nmax_epochs = 0\nmax_steps = 10\neval_frequency = 5\nfrozen_components = []\nannotating_components = []\ndev_corpus = \"corpora.dev\"\ntrain_corpus = \"corpora.train\"\nbefore_to_disk = null\nbefore_update = null\n\n[training.batcher]\n@batchers = \"spacy.batch_by_words.v1\"\ndiscard_oversize = false\ntolerance = 0.2\nget_length = null\n\n[training.batcher.size]\n@schedules = \"compounding.v1\"\nstart = 100\nstop = 1000\ncompound = 1.001\nt = 0.0\n\n[training.logger]\n@loggers = \"spacy.ConsoleLogger.v1\"\nprogress_bar = false\n\n[training.optimizer]\n@optimizers = \"Adam.v1\"\nbeta1 = 0.9\nbeta2 = 0.999\nL2_is_weight_decay = true\nL2 = 0.01\ngrad_clip = 1.0\nuse_averages = false\neps = 0.00000001\nlearn_rate = 0.001\n\n[training.score_weights]\naccuracy = 1.0\n\n[pretraining]\n\n[initialize]\nvectors = ${paths.vectors}\ninit_tok2vec = ${paths.init_tok2vec}\nvocab_data = null\nlookups = null\nbefore_init = null\nafter_init = null\n\n[initialize.components]\n\n[initialize.tokenizer]\n</code></pre> <p>To train it, run the following command :</p> <pre><code>spacy train config.cfg --output training/ --paths.train your_corpus/train.spacy --paths.dev your_corpus/dev.spacy\n</code></pre> <p>To use it, load the model and process a text :</p> <pre><code>import spacy\n\nnlp = spacy.load(\"training/model-best\")\ndoc = nlp.make_doc(\"Arret du ttt si folfox inefficace\")\ndoc.ents = [\n    # event = \"Arret\"\n    spacy.tokens.Span(doc, 0, 1, \"event\"),\n    # criteria = \"si\"\n    spacy.tokens.Span(doc, 3, 4, \"criteria\"),\n    # drug = \"folfox\"\n    spacy.tokens.Span(doc, 4, 5, \"drug\"),\n]\ndoc = nlp(doc)\n\n[ent._.negation for ent in doc.ents]\n# Out: [True, False, False]\n\n[ent._.event_type for ent in doc.ents]\n# Out: [\"start\", None, None]\n</code></pre>"},{"location":"pipelines/trainable/span-qualifier/#configuration","title":"Configuration","text":"<p>The <code>span_qualifier</code> pipeline component can be configured using the following parameters :</p> <p>The default model <code>eds.span_multi_classifier.v1</code> can be configured using the following parameters :</p>"},{"location":"pipelines/trainable/span-qualifier/#edsnlp.pipelines.trainable.span_qualifier.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>model</code> <p>The model to extract the spans</p> <p> TYPE: <code>Model</code> </p> <code>on_ents</code> <p>Whether to look into <code>doc.ents</code> for spans to classify. If a list of strings is provided, only the span of the given labels will be considered. If None and <code>on_span_groups</code> is False, labels mentioned in <code>label_constraints</code> will be used, and all ents will be used if <code>label_constraints</code> is None.</p> <p> TYPE: <code>Optional[Union[bool, Sequence[str]]]</code> DEFAULT: <code>None</code> </p> <code>on_span_groups</code> <p>Whether to look into <code>doc.spans</code> for spans to classify:</p> <ul> <li>If True, all span groups will be considered</li> <li>If False, no span group will be considered</li> <li>If a list of str is provided, only these span groups will be kept</li> <li>If a mapping is provided, the keys are the span group names and the values   are either a list of allowed labels in the group or True to keep them all</li> </ul> <p> TYPE: <code>Union[bool, Sequence[str], Mapping[str, Union[bool, Sequence[str]]]]</code> DEFAULT: <code>False</code> </p> <code>qualifiers</code> <p>The qualifiers to predict or train on. If None, keys from the <code>label_constraints</code> will be used</p> <p> TYPE: <code>Optional[Sequence[str]]</code> DEFAULT: <code>None</code> </p> <code>label_constraints</code> <p>Constraints to select qualifiers for each span depending on their labels. Keys of the dict are the qualifiers and values are the labels for which the qualifier is allowed. If None, all qualifiers will be used for all spans</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> <code>candidate_getter</code> <p>Optional method to call to extract the candidate spans and the qualifiers to predict or train on. If None, a candidate getter will be created from the other parameters: <code>on_ents</code>, <code>on_span_groups</code>, <code>qualifiers</code> and <code>label_constraints</code>.</p> <p> TYPE: <code>Optional[Callable[[Doc], Tuple[Spans, Optional[Spans], SpanGroups, List[List[str]]]]]</code> DEFAULT: <code>None</code> </p>"},{"location":"pipelines/trainable/span-qualifier/#authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.span_qualifier</code> pipeline was developed by AP-HP's Data Science team.</p> <p>\\bibliography</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>We provide step-by-step guides to get you started. We cover the following use-cases:</p> <ul> <li>Matching a terminology: you're looking for a concept within a corpus of texts.</li> <li>Qualifying entities: you want to make sure that the concept you've extracted are not invalidated by linguistic modulation.</li> <li>Detecting dates, which could serve as the basis for an event ordering algorithm.</li> <li>Processing multiple texts: to improve the inference speed of your pipeline !</li> <li>Detecting Hospitalisation Reason: you want to look spans that mention the reason of hospitalisation or tag entities as the reason.</li> <li>Detecting false endlines: classify each endline and add the attribute <code>excluded</code> to the these tokens.</li> </ul>"},{"location":"tutorials/#rationale","title":"Rationale","text":"<p>In a typical medical NLP pipeline, a group of clinicians would define a list of synonyms for a given concept of interest (say, for example, diabetes), and look for that terminology in a corpus of documents.</p> <p>Now, consider the following example:</p> FrenchEnglish <pre><code>Le patient n'est pas diab\u00e9tique.\nLe patient est peut-\u00eatre diab\u00e9tique.\nLe p\u00e8re du patient est diab\u00e9tique.\n</code></pre> <pre><code>The patient is not diabetic.\nThe patient could be diabetic.\nThe patient's father is diabetic.\n</code></pre> <p>There is an obvious problem: none of these examples should lead us to include this particular patient into the cohort.</p> <p>Warning</p> <p>We show an English example just to explain the issue. EDS-NLP remains a French-language medical NLP library.</p> <p>To curb this issue, EDS-NLP proposes rule-based pipelines that qualify entities to help the user make an informed decision about which patient should be included in a real-world data cohort.</p> <p>To sum up, a typical medical NLP project consists in:</p> <ol> <li>Editing a terminology</li> <li>\"Matching\" this terminology on a corpus, ie extract phrases that belong to that terminology</li> <li>\"Qualifying\" entities to avoid false positives</li> </ol> <p>Once the pipeline is ready, we need to deploy it efficiently.</p> <ol></ol>"},{"location":"tutorials/aggregating-results/","title":"Aggregating results","text":""},{"location":"tutorials/aggregating-results/#rationale","title":"Rationale","text":"<p>In some cases, you are not interested in individual extractions, but rather in document-level aggregated variables. For instance, you may be interested to know if a patient is diabetic without caring abou the actual mentions of diabetes. Here, we propose a simple and generic rule which work by:</p> <ul> <li>Extracting entities via methods of your choice</li> <li>Qualifiy those entities and discard appropriate entities</li> <li>Set a threshold on the minimal number of entities that should be present in the document to aggregate them.</li> </ul>"},{"location":"tutorials/aggregating-results/#an-example-for-the-disorders-pipelines","title":"An example for the disorders pipelines","text":"<p>Below is a simple implementation of this aggregation rule (this can be adapted for other comorbidity components and other qualification methods):</p> <pre><code>MIN_NUMBER_ENTITIES = 2  # (1)!\n\nif not Doc.has_extension(\"aggregated\"):\n    Doc.set_extension(\"aggregated\", default={})  # (2)!\n\nspans = doc.spans[\"diabetes\"]  # (3)!\nkept_spans = [\n    (span, span._.status, span._.detailed_status)\n    for span in spans\n    if not any([span._.negation, span._.hypothesis, span._.family])\n]  # (4)!\n\nif len(kept_spans) &lt; MIN_NUMBER_ENTITIES:  # (5)!\n    status = \"ABSENT\"\n\nelse:\n    status = max(kept_spans, key=itemgetter(1))[2]  # (6)!\n\ndoc._.aggregated[\"diabetes\"] = status\n</code></pre> <ol> <li>We want at least 2 correct entities</li> <li>Storing the status in the <code>doc._.aggregated</code> dictionary</li> <li>Getting status for the <code>diabetes</code> component</li> <li>Disregarding entities which are either negated, hypothetical, or not about the patient himself</li> <li>Setting the status to 0 if less than 2 relevant entities are left:</li> <li>Getting the maximum severity status</li> </ol> <ol></ol>"},{"location":"tutorials/detecting-dates/","title":"Detecting dates","text":"<p>We now know how to match a terminology and qualify detected entities, which covers most use cases for a typical medical NLP project. In this tutorial, we'll see how to use EDS-NLP to detect and normalise date mentions using <code>eds.dates</code>.</p> <p>This can have many applications, for dating medical events in particular. The <code>eds.consultation_dates</code> component, for instance, combines the date detection capabilities with a few simple patterns to detect the date of the consultation, when mentioned in clinical reports.</p>"},{"location":"tutorials/detecting-dates/#dates-in-clinical-notes","title":"Dates in clinical notes","text":"<p>Consider the following example:</p> FrenchEnglish <pre><code>Le patient est admis le 21 janvier pour une douleur dans le cou.\nIl se plaint d'une douleur chronique qui a d\u00e9but\u00e9 il y a trois ans.\n</code></pre> <pre><code>The patient is admitted on January 21st for a neck pain.\nHe complains about chronique pain that started three years ago.\n</code></pre> <p>Clinical notes contain many different types of dates. To name a few examples:</p> Type Description Examples Absolute Explicit date <code>2022-03-03</code> Partial Date missing the day, month or year <code>le 3 janvier/on January 3rd</code>, <code>en 2021/in 2021</code> Relative Relative dates <code>hier/yesterday</code>, <code>le mois dernier/last month</code> Duration Durations <code>pendant trois mois/for three months</code> <p>Warning</p> <p>We show an English example just to explain the issue. EDS-NLP remains a French-language medical NLP library.</p>"},{"location":"tutorials/detecting-dates/#extracting-dates","title":"Extracting dates","text":"<p>The followings snippet adds the <code>eds.date</code> component to the pipeline:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.dates\")  # (1)\n\ntext = (\n    \"Le patient est admis le 21 janvier pour une douleur dans le cou.\\n\"\n    \"Il se plaint d'une douleur chronique qui a d\u00e9but\u00e9 il y a trois ans.\"\n)\n\n# Detecting dates becomes trivial\ndoc = nlp(text)\n\n# Likewise, accessing detected dates is hassle-free\ndates = doc.spans[\"dates\"]  # (2)\n</code></pre> <ol> <li>The date detection component is declared with <code>eds.dates</code></li> <li>Dates are saved in the <code>doc.spans[\"dates\"]</code> key</li> </ol> <p>After this, accessing dates and there normalisation becomes trivial:</p> <pre><code># \u2191 Omitted code above \u2191\n\ndates  # (1)\n# Out: [21 janvier, il y a trois ans]\n</code></pre> <ol> <li><code>dates</code> is a list of spaCy <code>Span</code> objects.</li> </ol>"},{"location":"tutorials/detecting-dates/#normalisation","title":"Normalisation","text":"<p>We can review each date and get its normalisation:</p> <code>date.text</code> <code>date._.date</code> <code>21 janvier</code> <code>{\"day\": 21, \"month\": 1}</code> <code>il y a trois ans</code> <code>{\"direction\": \"past\", \"year\": 3}</code> <p>Dates detected by the pipeline component are parsed into a dictionary-like object. It includes every information that is actually contained in the text.</p> <p>To get a more usable representation, you may call the <code>to_datetime()</code> method. If there's enough information, the date will be represented in a <code>datetime.datetime</code> or <code>datetime.timedelta</code> object. If some information is missing, It will return <code>None</code>. Alternatively for this case, you can optionally set to <code>True</code> the parameter <code>infer_from_context</code> and you may also give a value for <code>note_datetime</code>.</p> <p>Date normalisation</p> <p>Since dates can be missing some information (eg <code>en ao\u00fbt</code>), we refrain from outputting a <code>datetime</code> object in that case. Doing so would amount to guessing, and we made the choice of letting you decide how you want to handle missing dates.</p>"},{"location":"tutorials/detecting-dates/#what-next","title":"What next?","text":"<p>The <code>eds.dates</code> pipeline component's role is merely to detect and normalise dates. It is the user's responsibility to use this information in a downstream application.</p> <p>For instance, you could use this pipeline to date medical entities. Let's do that.</p>"},{"location":"tutorials/detecting-dates/#a-medical-event-tagger","title":"A medical event tagger","text":"<p>Our pipeline will detect entities and events separately, and we will post-process the output <code>Doc</code> object to determine whether a given entity can be linked to a date.</p> <pre><code>import spacy\nfrom datetime import datetime\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.dates\")\n\nconfig = dict(\n    regex=dict(admission=[\"admissions?\", \"admise?\", \"prise? en charge\"]),\n    attr=\"LOWER\",\n)\nnlp.add_pipe(\"eds.matcher\", config=config)\n\ntext = (\n    \"Le patient est admis le 12 avril pour une douleur \"\n    \"survenue il y a trois jours. \"\n    \"Il avait \u00e9t\u00e9 pris en charge l'ann\u00e9e derni\u00e8re. \"\n    \"Il a \u00e9t\u00e9 diagnostiqu\u00e9 en mai 1995.\"\n)\n\ndoc = nlp(text)\n</code></pre> <p>At this point, the document is ready to be post-processed: its <code>ents</code> and <code>spans[\"dates\"]</code> are populated:</p> <pre><code># \u2191 Omitted code above \u2191\n\ndoc.ents\n# Out: (admis, pris en charge)\n\ndoc.spans[\"dates\"]\n# Out: [12 avril, il y a trois jours, l'ann\u00e9e derni\u00e8re, mai 1995]\n\nnote_datetime = datetime(year=1999, month=8, day=27)\n\nfor i, date in enumerate(doc.spans[\"dates\"]):\n    print(\n        i,\n        \" - \",\n        date,\n        \" - \",\n        date._.date.to_datetime(\n            note_datetime=note_datetime, infer_from_context=False, tz=None\n        ),\n    )\n    # Out: 0  -  12 avril  -  None\n    # Out: 1  -  il y a trois jours  -  1999-08-24 00:00:00\n    # Out: 2  -  l'ann\u00e9e derni\u00e8re  -  1998-08-27 00:00:00\n    # Out: 3  -  mai 1995  -  None\n\n\nfor i, date in enumerate(doc.spans[\"dates\"]):\n    print(\n        i,\n        \" - \",\n        date,\n        \" - \",\n        date._.date.to_datetime(\n            note_datetime=note_datetime,\n            infer_from_context=True,\n            tz=None,\n            default_day=15,\n        ),\n    )\n    # Out: 0  -  12 avril  -  1999-04-12T00:00:00\n    # Out: 1  -  il y a trois jours  -  1999-08-24 00:00:00\n    # Out: 2  -  l'ann\u00e9e derni\u00e8re  -  1998-08-27 00:00:00\n    # Out: 3  -  mai 1995  -  1995-05-15T00:00:00\n</code></pre> <p>As a first heuristic, let's consider that an entity can be linked to a date if the two are in the same sentence. In the case where multiple dates are present, we'll select the closest one.</p> utils.py<pre><code>from spacy.tokens import Span\nfrom typing import List, Optional\n\n\ndef candidate_dates(ent: Span) -&gt; List[Span]:\n\"\"\"Return every dates in the same sentence as the entity\"\"\"\n    return [date for date in ent.doc.spans[\"dates\"] if date.sent == ent.sent]\n\n\ndef get_event_date(ent: Span) -&gt; Optional[Span]:\n\"\"\"Link an entity to the closest date in the sentence, if any\"\"\"\n\n    dates = candidate_dates(ent)  # (1)\n\n    if not dates:\n        return\n\n    dates = sorted(\n        dates,\n        key=lambda d: min(abs(d.start - ent.end), abs(ent.start - d.end)),\n    )\n\n    return dates[0]  # (2)\n</code></pre> <ol> <li>Get all dates present in the same sentence.</li> <li>Sort the dates, and keep the first item.</li> </ol> <p>We can apply this simple function:</p> <pre><code>import spacy\nfrom utils import get_event_date\nfrom datetime import datetime\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.dates\")\n\nconfig = dict(\n    regex=dict(admission=[\"admissions?\", \"admise?\", \"prise? en charge\"]),\n    attr=\"LOWER\",\n)\nnlp.add_pipe(\"eds.matcher\", config=config)\n\ntext = (\n    \"Le patient est admis le 12 avril pour une douleur \"\n    \"survenue il y a trois jours. \"\n    \"Il avait \u00e9t\u00e9 pris en charge l'ann\u00e9e derni\u00e8re.\"\n)\n\ndoc = nlp(text)\nnow = datetime.now()\n\nfor ent in doc.ents:\n    if ent.label_ != \"admission\":\n        continue\n    date = get_event_date(ent)\n    print(f\"{ent.text:&lt;20}{date.text:&lt;20}{date._.date.to_datetime(now).strftime('%d/%m/%Y'):&lt;15}{date._.date.to_duration(now)}\")\n# Out: admis               12 avril            12/04/2023     21 weeks 4 days 6 hours 3 minutes 26 seconds\n# Out: pris en charge      l'ann\u00e9e derni\u00e8re    10/09/2022     -1 year\n</code></pre> <p>Which will output:</p> <code>ent</code> <code>get_event_date(ent)</code> <code>get_event_date(ent)._.date.to_datetime()</code> admis 12 avril <code>2020-04-12T00:00:00+02:00</code> pris en charge l'ann\u00e9e derni\u00e8re <code>-1 year</code> <ol></ol>"},{"location":"tutorials/endlines/","title":"Detecting end-of-lines","text":"<p>A common problem in medical corpus is that the character <code>\\n</code> does not necessarily correspond to a real new line as in other domains.</p> <p>For example, it is common to find texts like:</p> <pre><code>Il doit prendre\nle medicament indiqu\u00e9 3 fois par jour. Revoir m\u00e9decin\ndans 1 mois.\n</code></pre> <p>Inserted new line characters</p> <p>This issue is especially impactful for clinical notes that have been extracted from PDF documents. In that case, the new line character could be deliberately inserted by the doctor, or more likely added to respect the layout during the edition of the PDF.</p> <p>The aim of this tutorial is to train a unsupervised model to detect this false endlines and to use it for inference. The implemented model is based on the work of Zweigenbaum et alZweigenbaum et al., 2016.</p>"},{"location":"tutorials/endlines/#training-the-model","title":"Training the model","text":"<p>Let's train the model using an example corpus of three documents:</p> <pre><code>import spacy\nfrom edsnlp.pipelines.core.endlines.model import EndLinesModel\n\nnlp = spacy.blank(\"eds\")\n\ntext1 = \"\"\"Le patient est arriv\u00e9 hier soir.\nIl est accompagn\u00e9 par son fils\n\nANTECEDENTS\nIl a fait une TS en 2010;\nFumeur, il est arr\u00eat\u00e9 il a 5 mois\nChirurgie de coeur en 2011\nCONCLUSION\nIl doit prendre\nle medicament indiqu\u00e9 3 fois par jour. Revoir m\u00e9decin\ndans 1 mois.\nDIAGNOSTIC :\n\nAntecedents Familiaux:\n- 1. P\u00e8re avec diab\u00e8te\n\"\"\"\n\ntext2 = \"\"\"J'aime le \\nfromage...\\n\"\"\"\ntext3 = (\n    \"/n\"\n    \"Intervention(s) - acte(s) r\u00e9alis\u00e9(s) :/n\"\n    \"Parathyro\u00efdectomie \u00e9lective le [DATE]\"\n)\n\ntexts = [\n    text1,\n    text2,\n    text3,\n]\n\ncorpus = nlp.pipe(texts)\n\n# Fit the model\nendlines = EndLinesModel(nlp=nlp)  # (1)\ndf = endlines.fit_and_predict(corpus)  # (2)\n\n# Save model\nPATH = \"/tmp/path_to_model\"\nendlines.save(PATH)\n</code></pre> <ol> <li>Initialize the <code>EndLinesModel</code>    object and then fit (and predict) in the training corpus.</li> <li>The corpus should be an iterable of spacy documents.</li> </ol>"},{"location":"tutorials/endlines/#use-a-trained-model-for-inference","title":"Use a trained model for inference","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nPATH = \"/path_to_model\"\nnlp.add_pipe(\"eds.endlines\", config=dict(model_path=PATH))  # (1)\nnlp.add_pipe(\"eds.sentences\")  # (1)\n\ndocs = list(nlp.pipe([text1, text2, text3]))\n\ndoc = docs[1]\ndoc\n# Out: J'aime le\n# Out: fromage...\n\nlist(doc.sents)[0]\n# Out: J'aime le\n# Out: fromage...\n</code></pre> <ol> <li>You should specify the path to the trained model here.</li> <li>All fake new line are excluded by setting their <code>tag</code> to 'EXCLUDED' and all true new lines' <code>tag</code> are set to 'ENDLINE'.</li> </ol>"},{"location":"tutorials/endlines/#declared-extensions","title":"Declared extensions","text":"<p>It lets downstream matchers skip excluded tokens (see normalisation) for more detail.</p> <p>\\bibliography</p> <ol><li><p><p>Zweigenbaum P., Grouin C. and Lavergne T., 2016. Une cat\\'egorisation de fins de lignes non-supervis\\'ee (End-of-line classification with no supervision).</p></p></li></ol>"},{"location":"tutorials/matching-a-terminology/","title":"Matching a terminology","text":"<p>Matching a terminology is perhaps the most basic application of a medical NLP pipeline.</p> <p>In this tutorial, we will cover :</p> <ul> <li>Matching a terminology using spaCy's matchers, as well as RegExps</li> <li>Matching on a specific attribute</li> </ul> <p>You should consider reading the matcher's specific documentation for a description.</p> <p>Comparison to spaCy's matcher</p> <p>spaCy's <code>Matcher</code> and <code>PhraseMatcher</code> use a very efficient algorithm that compare a hashed representation token by token. They are not components by themselves, but can underpin rule-based pipelines.</p> <p>EDS-NLP's <code>RegexMatcher</code> lets the user match entire expressions using regular expressions. To achieve this, the matcher has to get to the text representation, match on it, and get back to spaCy's abstraction.</p> <p>The <code>EDSPhraseMatcher</code> lets EDS-NLP reuse spaCy's efficient algorithm, while adding the ability to skip pollution tokens (see the normalisation documentation for detail)</p>"},{"location":"tutorials/matching-a-terminology/#a-simple-use-case-finding-covid19","title":"A simple use case : finding COVID19","text":"<p>Let's try to find mentions of COVID19 and references to patients within a clinical note.</p> <pre><code>import spacy\n\ntext = (\n    \"Motif de prise en charge : probable pneumopathie a COVID19, \"\n    \"sans difficult\u00e9s respiratoires\\n\"\n    \"Le p\u00e8re du patient est asthmatique.\"\n)\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],\n    respiratoire=[\"asthmatique\", \"respiratoire\"],\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.matcher\", config=dict(terms=terms))\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (asthmatique,)\n</code></pre> <p>Let's unpack what happened:</p> <ol> <li>We defined a dictionary of terms to look for, in the form <code>{'label': list of terms}</code>.</li> <li>We declared a spaCy pipeline, and add the <code>eds.matcher</code> component.</li> <li>We applied the pipeline to the texts...</li> <li>... and explored the extracted entities.</li> </ol> <p>This example showcases a limitation of our term dictionary : the phrases <code>COVID19</code> and <code>difficult\u00e9s respiratoires</code> were not detected by the pipeline.</p> <p>To increase recall, we could just add every possible variation :</p> <pre><code>terms = dict(\n-    covid=[\"coronavirus\", \"covid19\"],\n+    covid=[\"coronavirus\", \"covid19\", \"COVID19\"],\n-    respiratoire=[\"asthmatique\", \"respiratoire\"],\n+    respiratoire=[\"asthmatique\", \"respiratoire\", \"respiratoires\"],\n)\n</code></pre> <p>But what if we come across <code>Coronavirus</code>? Surely we can do better!</p>"},{"location":"tutorials/matching-a-terminology/#matching-on-normalised-text","title":"Matching on normalised text","text":"<p>We can modify the matcher's configuration to match on other attributes instead of the verbatim input. You can refer to spaCy's list of available token attributes.</p> <p>Let's focus on two:</p> <ol> <li>The <code>LOWER</code> attribute, which lets you match on a lowercased version of the text.</li> <li>The <code>NORM</code> attribute, which adds some basic normalisation (eg <code>\u0153</code> to <code>oe</code>). EDS-NLP provides a <code>eds.normalizer</code> component that extends the level of cleaning on the <code>NORM</code> attribute.</li> </ol>"},{"location":"tutorials/matching-a-terminology/#the-lower-attribute","title":"The <code>LOWER</code> attribute","text":"<p>Matching on the lowercased version is extremely easy:</p> <pre><code>import spacy\n\ntext = (\n    \"Motif de prise en charge : probable pneumopathie a COVID19, \"\n    \"sans difficult\u00e9s respiratoires\\n\"\n    \"Le p\u00e8re du patient est asthmatique.\"\n)\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],\n    respiratoire=[\"asthmatique\", \"respiratoire\", \"respiratoires\"],\n)\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=terms,\n        attr=\"LOWER\",  # (1)\n    ),\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (COVID19, respiratoires, asthmatique)\n</code></pre> <ol> <li>The matcher's <code>attr</code> parameter defines the attribute that the matcher will use. It is set to <code>\"TEXT\"</code> by default (ie verbatim text).</li> </ol> <p>This code is complete, and should run as is.</p>"},{"location":"tutorials/matching-a-terminology/#using-the-normalisation-component","title":"Using the normalisation component","text":"<p>EDS-NLP provides its own normalisation component, which modifies the <code>NORM</code> attribute in place. It handles:</p> <ul> <li>removal of accentuated characters;</li> <li>normalisation of quotes and apostrophes;</li> <li>lowercasing, which enabled by default in spaCy \u2013 EDS-NLP lets you disable it;</li> <li>removal of pollution.</li> </ul> <p>Pollution in clinical texts</p> <p>EDS-NLP is meant to be deployed on clinical reports extracted from hospitals information systems. As such, it is often riddled with extraction issues or administrative artifacts that \"pollute\" the report.</p> <p>As a core principle, EDS-NLP never modifies the input text, and <code>nlp(text).text == text</code> is always true. However, we can tag some tokens as pollution elements, and avoid using them for matching the terminology.</p> <p>You can activate it like any other component.</p> <pre><code>import spacy\n\ntext = (\n\"Motif de prise en charge : probable pneumopathie a ===== COVID19, \"  # (1)\n\"sans difficult\u00e9s respiratoires\\n\"\n    \"Le p\u00e8re du patient est asthmatique.\"\n)\n\nterms = dict(\ncovid=[\"coronavirus\", \"covid19\", \"pneumopathie \u00e0 covid19\"],  # (2)\nrespiratoire=[\"asthmatique\", \"respiratoire\", \"respiratoires\"],\n)\n\nnlp = spacy.blank(\"eds\")\n\n# Add the normalisation component\nnlp.add_pipe(\"eds.normalizer\")  # (3)\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=terms,\nattr=\"NORM\",  # (4)\nignore_excluded=True,  # (5)\n),\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (pneumopathie a ===== COVID19, respiratoires, asthmatique)\n</code></pre> <ol> <li>We've modified the example to include a simple pollution.</li> <li>We've added <code>pneumopathie \u00e0 covid19</code> to the list of synonyms detected by the pipeline.    Note that in the synonym we provide, we kept the accentuated <code>\u00e0</code>, whereas the example    displays an unaccentuated <code>a</code>.</li> <li>The component can be configured. See the specific documentation for detail.</li> <li>The normalisation lives in the <code>NORM</code> attribute</li> <li>We can tell the matcher to ignore excluded tokens (tokens tagged as pollution by the normalisation component).    This is not an obligation.</li> </ol> <p>Using the normalisation component, you can match on a normalised version of the text, as well as skip pollution tokens during the matching process.</p> <p>Using term matching with the normalisation</p> <p>If you use the term matcher with the normalisation, bear in mind that the examples go through the pipeline. That's how the matcher was able to recover <code>pneumopathie a ===== COVID19</code> despite the fact that we used an accentuated <code>\u00e0</code> in the terminology.</p> <p>The term matcher matches the input text to the provided terminology, using the selected attribute in both cases. The <code>NORM</code> attribute that corresponds to <code>\u00e0</code> and <code>a</code> is the same: <code>a</code>.</p>"},{"location":"tutorials/matching-a-terminology/#preliminary-conclusion","title":"Preliminary conclusion","text":"<p>We have matched all mentions! However, we had to spell out the singular and plural form of <code>respiratoire</code>... And what if we wanted to detect <code>covid 19</code>, or <code>covid-19</code> ? Of course, we could write out every imaginable possibility, but this will quickly become tedious.</p>"},{"location":"tutorials/matching-a-terminology/#using-regular-expressions","title":"Using regular expressions","text":"<p>Let us redefine the pipeline once again, this time using regular expressions:</p> <pre><code>import spacy\n\ntext = (\n    \"Motif de prise en charge : probable pneumopathie a COVID19, \"\n    \"sans difficult\u00e9s respiratoires\\n\"\n    \"Le p\u00e8re du patient est asthmatique.\"\n)\n\nregex = dict(\n    covid=r\"(coronavirus|covid[-\\s]?19)\",\n    respiratoire=r\"respiratoires?\",\n)\nterms = dict(respiratoire=\"asthmatique\")\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        regex=regex,  # (1)\n        terms=terms,  # (2)\n        attr=\"LOWER\",  # (3)\n    ),\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (COVID19, respiratoires, asthmatique)\n</code></pre> <ol> <li>We can now match using regular expressions.</li> <li>We can mix and match patterns! Here we keep looking for patients using spaCy's term matching.</li> <li>RegExp matching is not limited to the verbatim text! You can choose to use one of spaCy's native attribute, ignore excluded tokens, etc.</li> </ol> <p>This code is complete, and should run as is.</p> <p>Using regular expressions can help define richer patterns using more compact queries.</p>"},{"location":"tutorials/matching-a-terminology/#visualising-matched-entities","title":"Visualising matched entities","text":"<p>EDS-NLP is part of the spaCy ecosystem, which means we can benefit from spaCy helper functions. For instance, spaCy's visualiser displacy can let us visualise the matched entities:</p> <pre><code># \u2191 Omitted code above \u2191\n\nfrom spacy import displacy\n\ncolors = {\n    \"covid\": \"orange\",\n    \"respiratoire\": \"steelblue\",\n}\noptions = {\n    \"colors\": colors,\n}\n\ndisplacy.render(doc, style=\"ent\", options=options)\n</code></pre> <p>If you run this within a notebook, you should get:</p> Motif de prise en charge : probable pneumopathie a              COVID19         covid      , sans difficult\u00e9s              respiratoires         respiratoire Le p\u00e8re du patient est              asthmatique         respiratoire      ."},{"location":"tutorials/multiple-texts/","title":"Processing multiple texts","text":"<p>In the previous tutorials, we've seen how to apply a spaCy NLP pipeline to a single text. Once the pipeline is tested and ready to be applied on an entire corpus, we'll want to deploy it efficiently.</p> <p>In this tutorial, we'll cover a few best practices and some caveats to avoid. Then, we'll explore methods that EDS-NLP provides to use a spaCy pipeline directly on a pandas or Spark DataFrame. These can drastically increase throughput.</p> <p>Consider this simple pipeline:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"fr\")\n\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\n\nconfig = dict(\n    terms=dict(patient=[\"patient\", \"malade\"]),\n    attr=\"NORM\",\n)\nnlp.add_pipe(\"eds.matcher\", config=config)\n\n# Add qualifiers\nnlp.add_pipe(\"eds.negation\")\nnlp.add_pipe(\"eds.hypothesis\")\nnlp.add_pipe(\"eds.family\")\n\n# Add date detection\nnlp.add_pipe(\"eds.dates\")\n</code></pre> <p>Let's deploy it on a large number of documents.</p>"},{"location":"tutorials/multiple-texts/#what-about-a-for-loop","title":"What about a <code>for</code> loop?","text":"<p>Suppose we have a corpus of text:</p> <pre><code>text = (\n    \"Patient admis le 25 septembre 2021 pour suspicion de Covid.\\n\"\n    \"Pas de cas de coronavirus dans ce service.\\n\"\n    \"Le p\u00e8re du patient est atteint du covid.\"\n)\n\ncorpus = [text] * 10000  # (1)\n</code></pre> <ol> <li>This is admittedly ugly. But you get the idea, we have a corpus of 10 000 documents we want to process...</li> </ol> <p>You could just apply the pipeline document by document.</p> A naive approach<pre><code># \u2191 Omitted code above \u2191\n\ndocs = [nlp(text) for text in corpus]\n</code></pre> <p>It turns out spaCy has a powerful parallelisation engine for an efficient processing of multiple texts. So the first step for writing more efficient spaCy code is to use <code>nlp.pipe</code> when processing multiple texts:</p> <pre><code>- docs = [nlp(text) for text in corpus]\n+ docs = list(nlp.pipe(corpus))\n</code></pre> <p>The <code>nlp.pipe</code> method takes an iterable as input, and outputs a generator of <code>Doc</code> object. Under the hood, texts are processed in batches, which is often much more efficient.</p> <p>Batch processing and EDS-NLP</p> <p>For now, EDS-NLP does not natively parallelise its components, so the gain from using <code>nlp.pipe</code> will not be that significant.</p> <p>Nevertheless, it's good practice to avoid using <code>for</code> loops when possible. Moreover, you will benefit from the batched tokenisation step.</p> <p>The way EDS-NLP is used may depend on how many documents you are working with. Once working with tens of thousands of them, parallelising the processing can be really efficient (up to 20x faster), but will require a (tiny) bit more work. Here are shown 4 ways to analyse texts depending on your needs</p> <p>A wrapper is available to simply switch between those use cases.</p>"},{"location":"tutorials/multiple-texts/#processing-a-pandas-dataframe","title":"Processing a pandas DataFrame","text":"<p>Processing text within a pandas DataFrame is a very common use case. In many applications, you'll select a corpus of documents over a distributed cluster, load it in memory and process all texts.</p> <p>The OMOP CDM</p> <p>In every tutorial that mentions distributing EDS-NLP over a corpus of documents, we will expect the data to be organised using a flavour of the OMOP Common Data Model.</p> <p>The OMOP CDM defines two tables of interest to us:</p> <ul> <li>the <code>note</code> table contains the clinical notes</li> <li>the <code>note_nlp</code> table holds the results of   a NLP pipeline applied to the <code>note</code> table.</li> </ul> <p>To make sure we can follow along, we propose three recipes for getting the DataFrame: using a dummy dataset like before, loading a CSV or by loading a Spark DataFrame into memory.</p> Dummy exampleLoading data from a CSVLoading data from a Spark DataFrame <pre><code>import pandas as pd\n\ntext = (\n    \"Patient admis le 25 septembre 2021 pour suspicion de Covid.\\n\"\n    \"Pas de cas de coronavirus dans ce service.\\n\"\n    \"Le p\u00e8re du patient est atteint du covid.\"\n)\n\ncorpus = [text] * 1000\n\ndata = pd.DataFrame(dict(note_text=corpus))\ndata[\"note_id\"] = range(len(data))\n</code></pre> <pre><code>import pandas as pd\n\ndata = pd.read_csv(\"note.csv\")\n</code></pre> <pre><code>from pyspark.sql.session import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\ndf = spark.sql(\"SELECT * FROM note\")\ndf = df.select(\"note_id\", \"note_text\")\n\ndata = df.limit(1000).toPandas()  # (1)\n</code></pre> <ol> <li>We limit the size of the DataFrame to make sure we do not overwhelm our machine.</li> </ol> <p>We'll see in what follows how we can efficiently deploy our pipeline on the <code>data</code> object.</p>"},{"location":"tutorials/multiple-texts/#by-hand","title":"\"By hand\"","text":"<p>We can deploy the pipeline using <code>nlp.pipe</code> directly, but we'll need some work to format the results in a usable way. Let's see how this might go, before using EDS-NLP's helper function to avoid the boilerplate code.</p> <pre><code>from spacy.tokens import Doc\nfrom typing import Any, Dict, List\n\n\ndef get_entities(doc: Doc) -&gt; List[Dict[str, Any]]:\n\"\"\"Return a list of dict representation for the entities\"\"\"\n\n    entities = []\n\n    for ent in doc.ents:\n        d = dict(\n            start=ent.start_char,\n            end=ent.end_char,\n            label=ent.label_,\n            lexical_variant=ent.text,\n            negation=ent._.negation,\n            hypothesis=ent._.hypothesis,\n            family=ent._.family,\n            key=\"ents\",\n        )\n        entities.append(d)\n\n    for date in doc.spans.get(\"dates\", []):\n        d = dict(\n            start=date.start_char,\n            end=date.end_char,\n            label=date._.date,\n            lexical_variant=date.text,\n            key=\"dates\",\n        )\n        entities.append(d)\n\n    return entities\n</code></pre> <pre><code># \u2191 Omitted code above \u2191\nimport pandas as pd\n\ndata[\"doc\"] = list(nlp.pipe(data.note_text))  # (1)\ndata[\"entities\"] = data.doc.apply(get_entities)  # (2)\n\n# \"Explode\" the dataframe\ndata = data[[\"note_id\", \"entities\"]].explode(\"entities\")\ndata = data.dropna()\n\ndata = data.reset_index(drop=True)\n\ndata = data[[\"note_id\"]].join(pd.json_normalize(data.entities))\n</code></pre> <ol> <li>We use spaCy's efficient <code>nlp.pipe</code> method</li> <li>This part is far from optimal, since it uses apply... But the computationally heavy part is in the previous line,    since <code>get_entities</code> merely reads pre-computed values from the document.</li> </ol> <p>The result on the first note:</p> note_id start end label lexical_variant negation hypothesis family key 0 0 7 patient Patient 0 0 0 ents 0 114 121 patient patient 0 0 1 ents 0 17 34 2021-09-25 25 septembre 2021 nan nan nan dates"},{"location":"tutorials/multiple-texts/#using-eds-nlps-helper-functions","title":"Using EDS-NLP's helper functions","text":"<p>Let's see how we can efficiently deploy our pipeline using EDS-NLP's utility methods.</p> <p>They share the same arguments:</p> Argument Description Default <code>note</code> A DataFrame, with two required columns, <code>note_id</code> and <code>note_text</code> Required <code>nlp</code> The pipeline object Required <code>context</code> A list of column names to add context to the generate <code>Doc</code> <code>[]</code> <code>additional_spans</code> Keys in <code>doc.spans</code> to include besides <code>doc.ents</code> <code>[]</code> <code>extensions</code> Custom extensions to use <code>[]</code> <code>results_extractor</code> An arbitrary callback function that turns a <code>Doc</code> into a list of dictionaries <code>None</code> (use extensions) <p>Adding context</p> <p>You might want to store some context information contained in the <code>note</code> DataFrame as an extension in the generated <code>Doc</code> object.</p> <p>For instance, you may use the <code>eds.dates</code> pipeline in coordination with the <code>note_datetime</code> field to normalise a relative date (eg <code>Le patient est venu il y a trois jours/The patient came three days ago</code>).</p> <p>In this case, you can use the <code>context</code> parameter and provide a list of column names you want to add:</p> <pre><code>note_nlp = single_pipe(\n    data,\n    nlp,\n    context=[\"note_datetime\"],\n    additional_spans=[\"dates\"],\n    extensions=[\"date.day\", \"date.month\", \"date.year\"],\n)\n</code></pre> <p>In this example, the <code>note_datetime</code> field becomes available as <code>doc._.note_datetime</code>.</p> <p>Depending on your pipeline, you may want to extract other extensions. To do so, simply provide those extension names (without the leading underscore) to the <code>extensions</code> argument. This should cover most use-cases.</p> <p>In case you need more fine-grained control over how you want to process the results of your pipeline, you can provide an arbitrary <code>results_extractor</code> function. Said function is expected to take a spaCy <code>Doc</code> object as input, and return a list of dictionaries that will be used to construct the <code>note_nlp</code> table. For instance, the <code>get_entities</code> function defined earlier could be distributed directly:</p> <pre><code># \u2191 Omitted code above \u2191\nfrom edsnlp.processing.simple import pipe as single_pipe\nfrom processing import get_entities\n\nnote_nlp = single_pipe(\n    data,\n    nlp,\n    results_extractor=get_entities,\n)\n</code></pre> <p>A few caveats on using an arbitrary function</p> <p>Should you use multiprocessing, your arbitrary function needs to be serialisable as a pickle object in order to be distributed. That implies a few limitations on the way your function can be defined.</p> <p>Namely, your function needs to be discoverable (see the pickle documentation on the subject). When deploying it should be defined such a way that can be accessed by the worker processes.</p> <p>For that reason, arbitrary functions can only be distributed via Spark/Koalas if their source code is advertised to the Spark workers. To that end, you should define your custom function in a pip-installed Python package.</p>"},{"location":"tutorials/multiple-texts/#single-process","title":"Single process","text":"<p>EDS-NLP provides a <code>single_pipe</code> helper function that avoids the hassle we just went through in the previous section. Using it is trivial:</p> <pre><code># \u2191 Omitted code above \u2191\nfrom edsnlp.processing.simple import pipe as single_pipe\n\nnote_nlp = single_pipe(\n    data,\n    nlp,\n    additional_spans=[\"dates\"],\n    extensions=[\"date.day\", \"date.month\", \"date.year\"],\n)\n</code></pre> <p>In just two Python statements, we get the exact same result as before!</p>"},{"location":"tutorials/multiple-texts/#multiple-processes","title":"Multiple processes","text":"<p>Depending on the size of your corpus, and if you have CPU cores to spare, you may want to distribute the computation. Again, EDS-NLP makes it extremely easy for you, through the <code>parallel_pipe</code> helper:</p> <pre><code># \u2191 Omitted code above \u2191\nfrom edsnlp.processing.parallel import pipe as parallel_pipe\n\nnote_nlp = parallel_pipe(\n    data,\n    nlp,\n    additional_spans=[\"dates\"],\n    extensions=[\"date.day\", \"date.month\", \"date.year\"],\n    n_jobs=-2,  # (1)\n)\n</code></pre> <ol> <li>The <code>n_jobs</code> parameter controls the number of workers that you deploy in parallel. Negative inputs means \"all cores minus <code>abs(n_jobs + 1)</code>\"</li> </ol> <p>Using a large number of workers and memory use</p> <p>In spaCy, even a rule-based pipeline is a memory intensive object. Be wary of using too many workers, lest you get a memory error.</p> <p>Depending on your machine, you should get a significant speed boost (we got 20x acceleration on a shared cluster using 62 cores).</p>"},{"location":"tutorials/multiple-texts/#deploying-eds-nlp-on-sparkkoalas","title":"Deploying EDS-NLP on Spark/Koalas","text":"<p>Should you need to deploy spaCy on a distributed DataFrame such as a Spark or a Koalas DataFrame, EDS-NLP has you covered. The procedure for those two types of DataFrame is virtually the same. Under the hood, EDS-NLP automatically deals with the necessary conversions.</p> <p>Suppose you have a Spark DataFrame:</p> Using a dummy exampleLoading a pre-existing tableUsing a Koalas DataFrame <pre><code>from pyspark.sql.session import SparkSession\nfrom pyspark.sql import types as T\n\nspark = SparkSession.builder.getOrCreate()\n\nschema = T.StructType(\n    [\n        T.StructField(\"note_id\", T.IntegerType()),\n        T.StructField(\"note_text\", T.StringType()),\n    ]\n)\n\ntext = (\n    \"Patient admis le 25 septembre 2021 pour suspicion de Covid.\\n\"\n    \"Pas de cas de coronavirus dans ce service.\\n\"\n    \"Le p\u00e8re du patient est atteint du covid.\"\n)\n\ndata = [(i, text) for i in range(1000)]\n\ndf = spark.createDataFrame(data=data, schema=schema)\n</code></pre> <pre><code>from pyspark.sql.session import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\ndf = spark.sql(\"SELECT * FROM note\")\ndf = df.select(\"note_id\", \"note_text\")\n</code></pre> <pre><code>from pyspark.sql.session import SparkSession\nimport databricks.koalas\n\nspark = SparkSession.builder.getOrCreate()\n\ndf = spark.sql(\"SELECT note_id, note_text FROM note\").to_koalas()\n</code></pre>"},{"location":"tutorials/multiple-texts/#declaring-types","title":"Declaring types","text":"<p>There is a minor twist, though: Spark (or Koalas) needs to know in advance the type of each extension you want to save. Thus, if you need additional extensions to be saved, you'll have to provide a dictionary to the <code>extensions</code> argument instead of a list of strings. This dictionary will have the name of the extension as keys and its PySpark type as value.</p> <p>Accepted types are the ones present in <code>pyspark.sql.types</code>.</p> <p>EDS-NLP provides a helper function, <code>pyspark_type_finder</code>, is available to get the correct type for most Python objects. You just need to provide an example of the type you wish to collect:</p> <pre><code>int_type = pyspark_type_finder(1)\n\n# Out: IntegerType()\n</code></pre> <p>Be careful when providing the example</p> <p>Do not blindly provide the first entity matched by your pipeline: it might be ill-suited. For instance, the <code>Span._.date</code> makes sense for a date span, but will be <code>None</code> if you use an entity...</p>"},{"location":"tutorials/multiple-texts/#deploying-the-pipeline","title":"Deploying the pipeline","text":"<p>Once again, using the helper is trivial:</p> SparkKoalas <pre><code># \u2191 Omitted code above \u2191\nfrom edsnlp.processing.distributed import pipe as distributed_pipe\n\nnote_nlp = distributed_pipe(\n    df,\n    nlp,\n    additional_spans=[\"dates\"],\n    extensions={\"date.year\": int_type, \"date.month\": int_type, \"date.day\": int_type},\n)\n\n# Check that the pipeline was correctly distributed:\nnote_nlp.show(5)\n</code></pre> <pre><code># \u2191 Omitted code above \u2191\nfrom edsnlp.processing.distributed import pipe as distributed_pipe\n\nnote_nlp = distributed_pipe(\n    df,\n    nlp,\n    additional_spans=[\"dates\"],\n    extensions={\"date.year\": int_type, \"date.month\": int_type, \"date.day\": int_type},\n)\n\n# Check that the pipeline was correctly distributed:\nnote_nlp.head()\n</code></pre> <p>Using Spark or Koalas, you can deploy EDS-NLP pipelines on tens of millions of documents with ease!</p>"},{"location":"tutorials/multiple-texts/#one-function-to-rule-them-all","title":"One function to rule them all","text":"<p>EDS-NLP provides a wrapper to simplify deployment even further:</p> <pre><code># \u2191 Omitted code above \u2191\nfrom edsnlp.processing import pipe\n\n### Small pandas DataFrame\nnote_nlp = pipe(\n    note=df.limit(1000).toPandas(),\n    nlp=nlp,\n    n_jobs=1,\n    additional_spans=[\"dates\"],\n    extensions=[\"date.day\", \"date.month\", \"date.year\"],\n)\n\n### Larger pandas DataFrame\nnote_nlp = pipe(\n    note=df.limit(10000).toPandas(),\n    nlp=nlp,\n    n_jobs=-2,\n    additional_spans=[\"dates\"],\n    extensions=[\"date.day\", \"date.month\", \"date.year\"],\n)\n\n### Huge Spark or Koalas DataFrame\nnote_nlp = pipe(\n    note=df,\n    nlp=nlp,\n    how=\"spark\",\n    additional_spans=[\"dates\"],\n    extensions={\"date.year\": int_type, \"date.month\": int_type, \"date.day\": int_type},\n)\n</code></pre>"},{"location":"tutorials/qualifying-entities/","title":"Qualifying entities","text":"<p>In the previous tutorial, we saw how to match a terminology on a text. Using the <code>doc.ents</code> attribute, we can check whether a document mentions a concept of interest to build a cohort or describe patients.</p>"},{"location":"tutorials/qualifying-entities/#the-issue","title":"The issue","text":"<p>However, consider the classical example where we look for the <code>diabetes</code> concept:</p> FrenchEnglish <pre><code>Le patient n'est pas diab\u00e9tique.\nLe patient est peut-\u00eatre diab\u00e9tique.\nLe p\u00e8re du patient est diab\u00e9tique.\n</code></pre> <pre><code>The patient is not diabetic.\nThe patient could be diabetic.\nThe patient's father is diabetic.\n</code></pre> <p>None of these expressions should be used to build a cohort: the detected entity is either negated, speculative, or does not concern the patient themself. That's why we need to qualify the matched entities.</p> <p>Warning</p> <p>We show an English example just to explain the issue. EDS-NLP remains a French-language medical NLP library.</p>"},{"location":"tutorials/qualifying-entities/#the-solution","title":"The solution","text":"<p>We can use EDS-NLP's qualifier pipelines to achieve that. Let's add specific components to our pipeline to detect these three modalities.</p>"},{"location":"tutorials/qualifying-entities/#adding-qualifiers","title":"Adding qualifiers","text":"<p>Adding qualifier pipelines is straightforward:</p> <pre><code>import spacy\n\ntext = (\n    \"Motif de prise en charge : probable pneumopathie \u00e0 COVID19, \"\n    \"sans difficult\u00e9s respiratoires\\n\"\n    \"Le p\u00e8re du patient est asthmatique.\"\n)\n\nregex = dict(\n    covid=r\"(coronavirus|covid[-\\s]?19)\",\n    respiratoire=r\"respiratoires?\",\n)\nterms = dict(respiratoire=\"asthmatique\")\n\nnlp = spacy.blank(\"fr\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        regex=regex,\n        terms=terms,\n        attr=\"LOWER\",\n    ),\n)\n\nnlp.add_pipe(\"eds.sentences\")  # (1)\nnlp.add_pipe(\"eds.negation\")  # Negation component\nnlp.add_pipe(\"eds.hypothesis\")  # Speculation pipeline\nnlp.add_pipe(\"eds.family\")  # Family context detection\n</code></pre> <ol> <li>Qualifiers pipelines need sentence boundaries to be set (see the specific documentation for detail).</li> </ol> <p>This code is complete, and should run as is.</p>"},{"location":"tutorials/qualifying-entities/#reading-the-results","title":"Reading the results","text":"<p>Let's output the results as a pandas DataFrame for better readability:</p> <pre><code>import spacy\nimport pandas as pd\ntext = (\n    \"Motif de prise en charge : probable pneumopathie \u00e0 COVID19, \"\n    \"sans difficult\u00e9s respiratoires\\n\"\n    \"Le p\u00e8re du patient est asthmatique.\"\n)\n\nregex = dict(\n    covid=r\"(coronavirus|covid[-\\s]?19)\",\n    respiratoire=r\"respiratoires?\",\n)\nterms = dict(respiratoire=\"asthmatique\")\n\nnlp = spacy.blank(\"fr\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        regex=regex,\n        terms=terms,\n        attr=\"LOWER\",\n    ),\n)\n\nnlp.add_pipe(\"eds.sentences\")\n\nnlp.add_pipe(\"eds.negation\")  # Negation component\nnlp.add_pipe(\"eds.hypothesis\")  # Speculation pipeline\nnlp.add_pipe(\"eds.family\")  # Family context detection\n\ndoc = nlp(text)\n\n# Extraction as a pandas DataFrame\nentities = []\nfor ent in doc.ents:\nd = dict(\nlexical_variant=ent.text,\nlabel=ent.label_,\nnegation=ent._.negation,\nhypothesis=ent._.hypothesis,\nfamily=ent._.family,\n)\nentities.append(d)\ndf = pd.DataFrame.from_records(entities)\n</code></pre> <p>This code is complete, and should run as is.</p> <p>We get the following result:</p> lexical_variant label negation hypothesis family COVID19 covid False True False respiratoires respiratoire True False False asthmatique respiratoire False False True"},{"location":"tutorials/qualifying-entities/#conclusion","title":"Conclusion","text":"<p>The qualifier pipelines limits the number of false positives by detecting linguistic modulations such as negations or speculations. Go to the full documentation for a complete presentation of the different pipelines, their configuration options and validation performance.</p> <p>Recall the qualifier pipeline proposed by EDS-NLP:</p> Pipeline Description <code>eds.negation</code> Rule-based negation detection <code>eds.family</code> Rule-based family context detection <code>eds.hypothesis</code> Rule-based speculation detection <code>eds.reported_speech</code> Rule-based reported speech detection <code>eds.history</code> Rule-based history detection"},{"location":"tutorials/quick-examples/","title":"Display single text outputs","text":"<p>If you are</p> <ul> <li>Developping a new pipeline</li> <li>Testing various inputs on an existing pipeline</li> <li>...</li> </ul> <p>you might want to quickly apply a pipeline and display the output <code>doc</code> in a comprehensible way.</p> <p>```{ .python .no-check } from edsnlp.viz import QuickExample</p> <p>E = QuickExample(nlp)  # (1) <pre><code>1. This is the `Language` instance that should be defined beforehands\n\nNext, simply call `E` with any string:\n\n ```{ .python .no-check }\ntxt = \"Le patient pr\u00e9sente une anomalie.\"\nE(txt)\n</code></pre></p> <pre>                              Le patient pr\u00e9sente une anomalie                               \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Entity   \u2503 Source   \u2503 eds.hypoth\u2026 \u2503 eds.negation \u2503 eds.family \u2503 eds.history \u2503 eds.report\u2026 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 patient  \u2502 patient  \u2502 False       \u2502 False        \u2502 False      \u2502 False       \u2502 False       \u2502\n\u2502 anomalie \u2502 anomalie \u2502 False       \u2502 False        \u2502 False      \u2502 False       \u2502 False       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>By default, each <code>Qualifiers</code> in <code>nlp</code> adds a corresponding column to the output. Additionnal informations can be displayed by using the <code>extensions</code> parameter. For instance, if entities have a custom <code>ent._.custom_ext</code> extensions, it can be displayed by providing the extension when instantiating <code>QuickExample</code>:</p> <p>```{ .python .no-check } E = QuickExample(nlp, extensions=[\"_.custom_ext\"]) <pre><code>Finally, if you prefer to output a DataFrame instead of displaying a table, set the `as_dataframe` parameter to True:\n\n ```{ .python .no-check }\nE = QuickExample(nlp)\nE(txt, as_dataframe=True)\n</code></pre></p>"},{"location":"tutorials/reason/","title":"Detecting Reason of Hospitalisation","text":"<p>In this tutorial we will use the pipeline <code>eds.reason</code> to :</p> <ul> <li>Identify spans that corresponds to the reason of hospitalisation</li> <li>Check if there are named entities overlapping with my span of 'reason of hospitalisation'</li> <li>Check for all named entities if they are tagged <code>is_reason</code></li> </ul> <pre><code>import spacy\n\ntext = \"\"\"COMPTE RENDU D'HOSPITALISATION du 11/07/2018 au 12/07/2018\nMOTIF D'HOSPITALISATION\nMonsieur Dupont Jean Michel, de sexe masculin, \u00e2g\u00e9e de 39 ans, n\u00e9e le 23/11/1978,\na \u00e9t\u00e9 hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nANT\u00c9C\u00c9DENTS\nAnt\u00e9c\u00e9dents m\u00e9dicaux :\nPremier \u00e9pisode d'asthme en mai 2018.\"\"\"\n\nnlp = spacy.blank(\"fr\")\n\n# Extraction d'entit\u00e9s nomm\u00e9es\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=dict(\n            respiratoire=[\n                \"asthmatique\",\n                \"asthme\",\n                \"toux\",\n            ]\n        )\n    ),\n)\n\n\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\nnlp.add_pipe(\"eds.reason\", config=dict(use_sections=True))\n\ndoc = nlp(text)\n</code></pre> <p>The pipeline <code>reason</code> will add a key of spans called <code>reasons</code>. We check the first item in this list.</p> <pre><code># \u2191 Omitted code above \u2191\n\nreason = doc.spans[\"reasons\"][0]\nreason\n# Out: hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n</code></pre> <p>Naturally, all spans included the <code>reasons</code> key have the attribute <code>reason._.is_reason == True</code>.</p> <pre><code># \u2191 Omitted code above \u2191\n\nreason._.is_reason\n# Out: True\n</code></pre> <pre><code># \u2191 Omitted code above \u2191\n\nentities = reason._.ents_reason  # (1)\nfor e in entities:\n    print(\n        \"Entity:\",\n        e.text,\n        \"-- Label:\",\n        e.label_,\n        \"-- is_reason:\",\n        e._.is_reason,\n    )\n# Out: Entity: asthme -- Label: respiratoire -- is_reason: True\n</code></pre> <ol> <li>We check if the span include named entities, their labels and the attribute is_reason</li> </ol> <p>We can verify that named entities that do not overlap with the spans of reason, have their attribute <code>reason._.is_reason == False</code>:</p> <pre><code>for e in doc.ents:\n    print(e.start, e, e._.is_reason)\n# Out: 42 asthme True\n# Out: 54 asthme False\n</code></pre> <ol></ol>"},{"location":"tutorials/spacy101/","title":"spaCy 101","text":"<p>EDS-NLP is a spaCy library. To use it, you will need to familiarise yourself with some key spaCy concepts.</p> <p>Skip if you're familiar with spaCy</p> <p>This page is intended as a crash course for the very basic spaCy concepts that are needed to use EDS-NLP. If you've already used spaCy, you should probably skip to the next page.</p> <p>In a nutshell, spaCy offers three things:</p> <ul> <li>a convenient abstraction with a language-dependent, rule-based, deterministic and non-destructive tokenizer</li> <li>a rich set of rule-based and trainable components</li> <li>a configuration and training system</li> </ul> <p>We will focus on the first item.</p> <p>Be sure to check out spaCy's crash course page for more information on the possibilities offered by the library.</p>"},{"location":"tutorials/spacy101/#resources","title":"Resources","text":"<p>The spaCy documentation is one of the great strengths of the library. In particular, you should check out the \"Advanced NLP with spaCy\" course, which provides a more in-depth presentation.</p>"},{"location":"tutorials/spacy101/#spacy-in-action","title":"spaCy in action","text":"<p>Consider the following minimal example:</p> <pre><code>import spacy  # (1)\n\n# Initialise a spaCy pipeline\nnlp = spacy.blank(\"fr\")  # (2)\n\ntext = \"Michel est un penseur lat\u00e9ral.\"  # (3)\n\n# Apply the pipeline\ndoc = nlp(text)  # (4)\n\ndoc.text\n# Out: 'Michel est un penseur lat\u00e9ral.'\n</code></pre> <ol> <li>Import spaCy...</li> <li>Load a pipeline. In spaCy, the <code>nlp</code> object handles the entire processing.</li> <li>Define a text you want to process.</li> <li>Apply the pipeline and get a spaCy <code>Doc</code> object.</li> </ol> <p>We just created a spaCy pipeline and applied it to a sample text. It's that simple.</p> <p>Note that we use spaCy's \"blank\" NLP pipeline here. It actually carries a lot of information, and defines spaCy's language-dependent, rule-based tokenizer.</p> <p>Non-destructive processing</p> <p>In EDS-NLP, just like spaCy, non-destructiveness is a core principle. Your detected entities will always be linked to the original text.</p> <p>In other words, <code>nlp(text).text == text</code> is always true.</p>"},{"location":"tutorials/spacy101/#the-doc-abstraction","title":"The <code>Doc</code> abstraction","text":"<p>The <code>doc</code> object carries the result of the entire processing. It's the most important abstraction in spaCy, and holds a token-based representation of the text along with the results of every pipeline components. It also keeps track of the input text in a non-destructive manner, meaning that <code>doc.text == text</code> is always true.</p> <pre><code># \u2191 Omitted code above \u2191\n\n# Text processing in spaCy is non-destructive\ndoc.text == text  # (1)\n\n# You can access a specific token\ntoken = doc[2]  # (2)\n\n# And create a Span using slices\nspan = doc[:3]  # (3)\n\n# Entities are tracked in the ents attribute\ndoc.ents  # (4)\n# Out: ()\n</code></pre> <ol> <li>This feature is a core principle in spaCy. It will always be true in EDS-NLP.</li> <li><code>token</code> is a <code>Token</code> object referencing the third token</li> <li><code>span</code> is a <code>Span</code> object referencing the first three tokens.</li> <li>We have not declared any entity recognizer in our pipeline, hence this attribute is empty.</li> </ol>"},{"location":"tutorials/spacy101/#adding-pipeline-components","title":"Adding pipeline components","text":"<p>You can add pipeline components with the <code>nlp.add_pipe</code> method. Let's add two simple components to our pipeline.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"fr\")\n\nnlp.add_pipe(\"eds.sentences\")  # (1)\nnlp.add_pipe(\"eds.dates\")  # (2)\ntext = \"Le 5 mai 2005, Jimoth\u00e9 a \u00e9t\u00e9 invit\u00e9 \u00e0 une f\u00eate organis\u00e9e par Michel.\"\n\ndoc = nlp(text)\n</code></pre> <ol> <li>Like the name suggests, this pipeline is declared by EDS-NLP.    <code>eds.sentences</code> is a rule-based sentence boundary prediction.    See its documentation for detail.</li> <li>Like the name suggests, this pipeline is declared by EDS-NLP.    <code>eds.dates</code> is a date extraction and normalisation component.    See its documentation for detail.</li> </ol> <p>The <code>doc</code> object just became more interesting!</p> <pre><code># \u2191 Omitted code above \u2191\n\n# We can split the document into sentences\nlist(doc.sents)  # (1)\n# Out: [Le 5 mai 2005, Jimoth\u00e9 a \u00e9t\u00e9 invit\u00e9 \u00e0 une f\u00eate organis\u00e9e par Michel.]\n\n# And look for dates\ndoc.spans[\"dates\"]  # (2)\n# Out: [5 mai 2005]\n\nspan = doc.spans[\"dates\"][0]  # (3)\nspan._.date.to_datetime()  # (4)\n# Out: DateTime(2005, 5, 5, 0, 0, 0, tzinfo=Timezone('Europe/Paris'))\n</code></pre> <ol> <li>In this example, there is only one sentence...</li> <li>The <code>eds.dates</code> adds a key to the <code>doc.spans</code> attribute</li> <li><code>span</code> is a spaCy <code>Span</code> object.</li> <li>In spaCy, you can declare custom extensions that live in the <code>_</code> attribute.    Here, the <code>eds.dates</code> pipeline uses a <code>Span._.date</code> extension to persist the normalised date.    We use the <code>to_datetime()</code> method to get an object that is usable by Python.</li> </ol>"},{"location":"tutorials/spacy101/#conclusion","title":"Conclusion","text":"<p>This page is just a glimpse of a few possibilities offered by spaCy. To get a sense of what spaCy can help you achieve, we strongly recommend you visit their documentation and take the time to follow the spaCy course.</p> <p>Moreover, be sure to check out spaCy's own crash course, which is an excellent read. It goes into more detail on what's possible with the library.</p>"},{"location":"utilities/","title":"Utilities","text":"<p>EDS-NLP provides a few utilities to deploy pipelines, process RegExps, etc.</p>"},{"location":"utilities/evaluation/","title":"Pipeline evaluation","text":""},{"location":"utilities/matchers/","title":"Matchers","text":"<p>We implemented three pattern matchers that are fit to clinical documents:</p> <ul> <li>the <code>EDSPhraseMatcher</code></li> <li>the <code>RegexMatcher</code></li> <li>the <code>SimstringMatcher</code></li> </ul> <p>However, note that for most use-cases, you should instead use the <code>eds.matcher</code> pipeline that wraps these classes to annotate documents.</p>"},{"location":"utilities/matchers/#edsphrasematcher","title":"EDSPhraseMatcher","text":"<p>The EDSPhraseMatcher lets you efficiently match large terminology lists, by comparing tokenx against a given attribute. This matcher differs from the <code>spacy.PhraseMatcher</code> in that it allows to skip pollution tokens. To make it efficient, we have reimplemented the matching algorithm in Cython, like the original <code>spacy.PhraseMatcher</code>.</p> <p>You can use it as described in the code below.</p> <pre><code>import spacy\nfrom edsnlp.matchers.phrase import EDSPhraseMatcher\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\ndoc = nlp(\"On ne rel\u00e8ve pas de signe du Corona =============== virus.\")\n\nmatcher = EDSPhraseMatcher(nlp.vocab, attr=\"NORM\")\nmatcher.build_patterns(\n    nlp,\n    {\n        \"covid\": [\"corona virus\", \"coronavirus\", \"covid\"],\n        \"diabete\": [\"diabete\", \"diabetique\"],\n    },\n)\n\nlist(matcher(doc, as_spans=True))[0].text\n# Out: Corona =============== virus\n</code></pre>"},{"location":"utilities/matchers/#regexmatcher","title":"RegexMatcher","text":"<p>The <code>RegexMatcher</code> performs full-text regex matching. It is especially useful to handle spelling variations like <code>mammo-?graphies?</code>. Like the <code>EDSPhraseMatcher</code>, this class allows to skip pollution tokens. Note that this class is significantly slower than the <code>EDSPhraseMatcher</code>: if you can, try enumerating lexical variations of the target phrases and feed them to the <code>PhraseMatcher</code> instead.</p> <p>You can use it as described in the code below.</p> <pre><code>import spacy\nfrom edsnlp.matchers.regex import RegexMatcher\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\ndoc = nlp(\"On ne rel\u00e8ve pas de signe du Corona =============== virus.\")\n\nmatcher = RegexMatcher(attr=\"NORM\", ignore_excluded=True)\nmatcher.build_patterns(\n    {\n        \"covid\": [\"corona[ ]*virus\", \"covid\"],\n        \"diabete\": [\"diabete\", \"diabetique\"],\n    },\n)\n\nlist(matcher(doc, as_spans=True))[0].text\n# Out: Corona =============== virus\n</code></pre>"},{"location":"utilities/matchers/#simstringmatcher","title":"SimstringMatcher","text":"<p>The <code>SimstringMatcher</code> performs fuzzy term matching by comparing spans of text with a similarity metric. It is especially useful to handle spelling variations like <code>paracetomol</code> (instead of <code>paracetamol</code>).</p> <p>The <code>simstring</code> algorithm compares two strings by enumerating their char trigrams and measuring the overlap between the two sets. In the previous example: - <code>paracetomol</code> becomes <code>##p #pa par ara rac ace cet eto tom omo mol ol# l##</code> - <code>paracetamol</code> becomes <code>##p #pa par ara rac ace cet eta tam amo mol ol# l##</code> and the Dice (or F1) similarity between the two sets is 0.75.</p> <p>Like the <code>EDSPhraseMatcher</code>, this class allows to skip pollution tokens. Just like the <code>RegexMatcher</code>, this class is significantly slower than the <code>EDSPhraseMatcher</code>: if you can, try enumerating lexical variations of the target phrases and feed them to the <code>PhraseMatcher</code> instead.</p> <p>You can use it as described in the code below.</p> <pre><code>import spacy\nfrom edsnlp.matchers.simstring import SimstringMatcher\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\ndoc = nlp(\n    \"On ne rel\u00e8ve pas de signe du corona-virus. Historique d'un hepatocellulaire carcinome.\"\n)\n\nmatcher = SimstringMatcher(\n    nlp.vocab,\n    attr=\"NORM\",\n    ignore_excluded=True,\n    measure=\"dice\",\n    threshold=0.75,\n    windows=5,\n)\nmatcher.build_patterns(\n    nlp,\n    {\n        \"covid\": [\"coronavirus\", \"covid\"],\n        \"carcinome\": [\"carcinome hepatocellulaire\"],\n    },\n)\n\nlist(matcher(doc, as_spans=True))[0].text\n# Out: corona-virus\n\nlist(matcher(doc, as_spans=True))[1].text\n# Out: hepatocellulaire carcinome\n</code></pre>"},{"location":"utilities/regex/","title":"Work with RegExp","text":""},{"location":"utilities/connectors/","title":"Overview of connectors","text":"<p>EDS-NLP provides a series of connectors apt to convert back and forth from different formats into spaCy representation.</p> <p>We provide the following connectors:</p> <ul> <li>BRAT</li> <li>OMOP</li> </ul>"},{"location":"utilities/connectors/brat/","title":"BRAT Connector","text":"<p>BRAT is currently the only supported in-text annotation editor at EDS. BRAT annotations are in the standoff format. Consider the following document:</p> <pre><code>Le patient est admis pour une pneumopathie au coronavirus.\nOn lui prescrit du parac\u00e9tamol.\n</code></pre> <p>It could be annotated as follows :</p> <pre><code>T1  Patient 4 11    patient\nT2  Disease 31 58   pneumopathie au coronavirus\nT3  Drug 79 90  parac\u00e9tamol\n</code></pre> <p>The point of the BRAT connector is to go from the standoff annotation format to an annotated spaCy document :</p> <pre><code>import spacy\nfrom edsnlp.connectors.brat import BratConnector\n\n# Instantiate the connector\nbrat = BratConnector(\"path/to/brat\")\n\n# Instantiate the spacy pipeline\nnlp = spacy.blank(\"eds\")\n\n# Convert all BRAT files to a list of documents\ndocs = brat.brat2docs(nlp)\ndoc = docs[0]\n\ndoc.ents\n# Out: [patient, pneumopathie au coronavirus, parac\u00e9tamol]\n\ndoc.ents[0].label_\n# Out: Patient\n</code></pre> <p>The connector can also go the other way around, enabling pre-annotations and an ersatz of active learning.</p>"},{"location":"utilities/connectors/labeltool/","title":"LabelTool Connector","text":"<p>LabelTool is an in-house module enabling rapid annotation of pre-extracted entities.</p> <p>We provide a ready-to-use function that converts a list of annotated spaCy documents into a <code>pandas</code> DataFrame that is readable to LabelTool.</p> <pre><code>import spacy\n\nfrom edsnlp.connectors.labeltool import docs2labeltool\n\ncorpus = [\n    \"Ceci est un document m\u00e9dical.\",\n    \"Le patient n'est pas malade.\",\n]\n\n# Instantiate the spacy pipeline\nnlp = spacy.blank(\"fr\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.matcher\", config=dict(terms=dict(medical=\"m\u00e9dical\", malade=\"malade\")))\nnlp.add_pipe(\"eds.negation\")\n\n# Convert all BRAT files to a list of documents\ndocs = nlp.pipe(corpus)\n\ndf = docs2labeltool(docs, extensions=[\"negation\"])\n</code></pre> <p>The results:</p> note_id note_text start end label lexical_variant negation 0 Ceci est un document m\u00e9dical. 21 28 medical m\u00e9dical False 1 Le patient n'est pas malade. 21 27 malade malade True"},{"location":"utilities/connectors/omop/","title":"OMOP Connector","text":"<p>We provide a connector between OMOP-formatted dataframes and spaCy documents.</p>"},{"location":"utilities/connectors/omop/#omop-style-dataframes","title":"OMOP-style dataframes","text":"<p>Consider a corpus of just one document:</p> <pre><code>Le patient est admis pour une pneumopathie au coronavirus.\nOn lui prescrit du parac\u00e9tamol.\n</code></pre> <p>And its OMOP-style representation, separated in two tables <code>note</code> and <code>note_nlp</code> (here with selected columns) :</p> <p><code>note</code>:</p> note_id note_text note_datetime 0 Le patient est admis pour une pneumopathie... 2021-10-23 <p><code>note_nlp</code>:</p> note_nlp_id note_id start_char end_char note_nlp_source_value lexical_variant 0 0 46 57 disease coronavirus 1 0 77 88 drug parac\u00e9tamol"},{"location":"utilities/connectors/omop/#using-the-connector","title":"Using the connector","text":"<p>The following snippet expects the tables <code>note</code> and <code>note_nlp</code> to be already defined (eg through PySpark's <code>toPandas()</code> method).</p> <pre><code>import spacy\nfrom edsnlp.connectors.omop import OmopConnector\n\n# Instantiate a spacy pipeline\nnlp = spacy.blank(\"eds\")\n\n# Instantiate the connector\nconnector = OmopConnector(nlp)\n\n# Convert OMOP tables (note and note_nlp) to a list of documents\ndocs = connector.omop2docs(note, note_nlp)\ndoc = docs[0]\n\ndoc.ents\n# Out: [coronavirus, parac\u00e9tamol]\n\ndoc.ents[0].label_\n# Out: 'disease'\n\ndoc.text == note.loc[0].note_text\n# Out: True\n</code></pre> <p>The object <code>docs</code> now contains a list of documents that reflects the information contained in the OMOP-formatted dataframes.</p>"},{"location":"utilities/processing/","title":"Overview of processing","text":""},{"location":"utilities/processing/multi/","title":"Multiprocessing","text":""},{"location":"utilities/processing/single/","title":"Single processing","text":""},{"location":"utilities/processing/spark/","title":"Deploying on Spark","text":"<p>We provide a simple connector to distribute a pipeline on a Spark cluster. We expose a Spark UDF (user-defined function) factory that handles the nitty gritty of distributing a pipeline over a cluster of Spark-enabled machines.</p>"},{"location":"utilities/processing/spark/#distributing-a-pipeline","title":"Distributing a pipeline","text":"<p>Because of the way Spark distributes Python objects, we need to re-declare custom extensions on the executors. To make this step as smooth as possible, EDS-NLP provides a <code>BaseComponent</code> class that implements a <code>set_extensions</code> method. When the pipeline is distributed, every component that extend <code>BaseComponent</code> rerun their <code>set_extensions</code> method.</p> <p>Since spaCy <code>Doc</code> objects cannot easily be serialised, the UDF we provide returns a list of detected entities along with selected qualifiers.</p>"},{"location":"utilities/processing/spark/#example","title":"Example","text":"<p>See the dedicated tutorial for a step-by-step presentation.</p>"},{"location":"utilities/processing/spark/#authors-and-citation","title":"Authors and citation","text":"<p>The Spark connector was developed by AP-HP's Data Science team.</p>"},{"location":"utilities/tests/","title":"Tests Utilities","text":"<p>We provide a few testing utilities that simplify the process of:</p> <ul> <li>creating testing examples for NLP pipelines;</li> <li>testing documentation code blocs.</li> </ul>"},{"location":"utilities/tests/blocs/","title":"Testing Code Blocs","text":"<p>We created a utility that scans through markdown files, extracts code blocs and executes them to check that everything is indeed functional.</p> <p>There is more! Whenever the utility comes across an example (denoted by <code># Out:</code>, see example below), an <code>assert</code> statement is dynamically added to the snippet to check that the output matches.</p> <p>For instance:</p> <pre><code>a = 1\n\na\n# Out: 1\n</code></pre> <p>Is transformed into:</p> <pre><code>a = 1\n\nv = a\nassert repr(v) == \"1\"\n</code></pre> <p>We can disable code checking for a specific code bloc by adding <code>&lt;!-- no-check --&gt;</code> above it:</p> <pre><code>```{ .python .no-check }\ntest = undeclared_function(42)\n```\n</code></pre> <p>See the dedicated reference for more information</p>"},{"location":"utilities/tests/examples/","title":"Creating Examples","text":"<p>Testing a NER/qualifier pipeline can be a hassle. We created a utility to simplify that process.</p> <p>Using the <code>parse_example</code> method, you can define a full example in a human-readable way:</p> <pre><code>from edsnlp.utils.examples import parse_example\n\nexample = \"Absence d'&lt;ent negated=true&gt;image osseuse d'allure \u00e9volutive&lt;/ent&gt;.\"\n\ntext, entities = parse_example(example)\n\ntext\n# Out: \"Absence d'image osseuse d'allure \u00e9volutive.\"\n\nentities\n# Out: [Entity(start_char=10, end_char=42, modifiers=[Modifier(key='negated', value=True)])]\n</code></pre> <p>Entities are defined using the <code>&lt;ent&gt;</code> tag. You can encode complexe information by adding keys into the tag (see example above). The <code>parse_example</code> method strips the text of the tags, and outputs a list of <code>Entity</code> objects that contain:</p> <ul> <li>the character indices of the entity ;</li> <li>custom user-defined \"modifiers\".</li> </ul> <p>See the dedicated reference page for more information.</p>"},{"location":"reference/edsnlp/","title":"<code>edsnlp</code>","text":"<p>EDS-NLP</p>"},{"location":"reference/edsnlp/conjugator/","title":"<code>edsnlp.conjugator</code>","text":""},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.conjugate_verb","title":"<code>conjugate_verb</code>","text":"<p>Conjugates the verb using an instance of mlconjug3, and formats the results in a pandas <code>DataFrame</code>.</p>"},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.conjugate_verb--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verb</code> <p>Verb to conjugate.</p> <p> TYPE: <code>str</code> </p> <code>conjugator</code> <p>mlconjug3 instance for conjugating.</p> <p> TYPE: <code>Conjugator</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>Normalized dataframe containing all conjugated forms for the verb.</p>"},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.conjugate","title":"<code>conjugate</code>","text":"<p>Conjugate a list of verbs.</p>"},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.conjugate--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verbs</code> <p>List of verbs to conjugate</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> <code>language</code> <p>Language to conjugate. Defaults to French (<code>fr</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fr'</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>Dataframe containing the conjugations for the provided verbs. Columns: <code>verb</code>, <code>mode</code>, <code>tense</code>, <code>person</code>, <code>term</code></p>"},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.get_conjugated_verbs","title":"<code>get_conjugated_verbs</code>","text":"<p>Get a list of conjugated verbs.</p>"},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.get_conjugated_verbs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verbs</code> <p>List of verbs to conjugate.</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> <code>matches</code> <p>List of dictionary describing the mode/tense/persons to keep.</p> <p> TYPE: <code>Union[List[Dict[str, str]], Dict[str, str]]</code> </p> <code>language</code> <p>[description], by default \"fr\" (French)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fr'</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of terms to look for.</p>"},{"location":"reference/edsnlp/conjugator/#edsnlp.conjugator.get_conjugated_verbs--examples","title":"Examples","text":"<p>get_conjugated_verbs(         \"aimer\",         dict(mode=\"Indicatif\", tense=\"Pr\u00e9sent\", person=\"1p\"),     ) ['aimons']</p>"},{"location":"reference/edsnlp/connectors/","title":"<code>edsnlp.connectors</code>","text":""},{"location":"reference/edsnlp/connectors/brat/","title":"<code>edsnlp.connectors.brat</code>","text":""},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector","title":"<code>BratConnector</code>","text":"<p>           Bases: <code>object</code></p> <p>Two-way connector with BRAT. Supports entities only.</p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>directory</code> <p>Directory containing the BRAT files.</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>n_jobs</code> <p>Number of jobs for multiprocessing, by default 1</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>attributes</code> <p>Mapping from BRAT attributes to spaCy Span extensions. Extensions / attributes that are not in the mapping are not imported or exported If left to None, the mapping is filled with all BRAT attributes.</p> <p> TYPE: <code>Optional[Union[Sequence[str], Mapping[str, str]]]</code> DEFAULT: <code>None</code> </p> <code>span_groups</code> <p>Additional span groups to look for entities in spaCy documents when exporting. Missing label (resp. span group) names are not imported (resp. exported) If left to None, the sequence is filled with all BRAT entity labels.</p> <p> TYPE: <code>Optional[Sequence[str]]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.load_brat","title":"<code>load_brat</code>","text":"<p>Transforms a BRAT folder to a list of spaCy documents.</p> RETURNS DESCRIPTION <code>List[Dict]</code> <p>List of spaCy documents, with annotations in the <code>ents</code> attribute.</p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.brat2docs","title":"<code>brat2docs</code>","text":"<p>Transforms a BRAT folder to a list of spaCy documents.</p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.brat2docs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>A spaCy pipeline.</p> <p> TYPE: <code>Language</code> </p> <code>run_pipe</code> <p>Should the full spaCy pipeline be run on the documents, or just the tokenization (defaults to False ie only tokenization)</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>docs</code> <p>List of spaCy documents, with annotations in the <code>ents</code> attribute.</p> <p> TYPE: <code>List[Doc]</code> </p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.doc2brat","title":"<code>doc2brat</code>","text":"<p>Writes a spaCy document to file in the BRAT directory.</p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.doc2brat--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object. The spans in <code>ents</code> will populate the <code>note_id.ann</code> file.</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.docs2brat","title":"<code>docs2brat</code>","text":"<p>Writes a list of spaCy documents to file.</p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.docs2brat--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p>List of spaCy documents.</p> <p> TYPE: <code>List[Doc]</code> </p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.BratConnector.get_brat","title":"<code>get_brat</code>","text":"<p>Reads texts and annotations, and returns two DataFrame objects. For backward compatibility</p> RETURNS DESCRIPTION <code>texts</code> <p>A DataFrame containing two fields, <code>note_id</code> and <code>note_text</code></p> <p> TYPE: <code>DataFrame</code> </p> <code>annotations</code> <p>A DataFrame containing the annotations.</p> <p> TYPE: <code>DataFrame</code> </p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.load_from_brat","title":"<code>load_from_brat</code>","text":"<p>Load a brat file</p> <p>Adapted from https://github.com/percevalw/nlstruct/blob/master/nlstruct/datasets/brat.py</p>"},{"location":"reference/edsnlp/connectors/brat/#edsnlp.connectors.brat.load_from_brat--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>path</code> <p>Path or glob path of the brat text file (.txt, not .ann)</p> <p> TYPE: <code>str</code> </p> <code>merge_spaced_fragments</code> <p>Merge fragments of a entity that was splitted by brat because it overlapped an end of line</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Iterator[Dict]</code>"},{"location":"reference/edsnlp/connectors/labeltool/","title":"<code>edsnlp.connectors.labeltool</code>","text":""},{"location":"reference/edsnlp/connectors/labeltool/#edsnlp.connectors.labeltool.docs2labeltool","title":"<code>docs2labeltool</code>","text":"<p>Returns a labeltool-ready dataframe from a list of annotated document.</p>"},{"location":"reference/edsnlp/connectors/labeltool/#edsnlp.connectors.labeltool.docs2labeltool--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p>List of annotated spacy docs.</p> <p> TYPE: <code>List[Doc]</code> </p> <code>extensions</code> <p>List of extensions to use by labeltool.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>df</code> <p>DataFrame tailored for labeltool.</p> <p> TYPE: <code>DataFrame</code> </p>"},{"location":"reference/edsnlp/connectors/omop/","title":"<code>edsnlp.connectors.omop</code>","text":""},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector","title":"<code>OmopConnector</code>","text":"<p>           Bases: <code>object</code></p> <p>[summary]</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy language object.</p> <p> TYPE: <code>Language</code> </p> <code>start_char</code> <p>Name of the column containing the start character index of the entity, by default \"start_char\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'start_char'</code> </p> <code>end_char</code> <p>Name of the column containing the end character index of the entity, by default \"end_char\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'end_char'</code> </p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.preprocess","title":"<code>preprocess</code>","text":"<p>Preprocess the input OMOP tables: modification of the column names.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.preprocess--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>OMOP <code>note_nlp</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>note</code> <p>OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>OMOP <code>note_nlp</code> table.</p> <p> TYPE: <code>DataFrame</code> </p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.postprocess","title":"<code>postprocess</code>","text":"<p>Postprocess the input OMOP tables: modification of the column names.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.postprocess--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>OMOP <code>note_nlp</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>note</code> <p>OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>OMOP <code>note_nlp</code> table.</p> <p> TYPE: <code>DataFrame</code> </p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.omop2docs","title":"<code>omop2docs</code>","text":"<p>Transforms OMOP tables to a list of spaCy documents.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.omop2docs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>OMOP <code>note_nlp</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>extensions</code> <p>Extensions to keep, by default None</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Doc]</code> <p>List of spaCy documents.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.docs2omop","title":"<code>docs2omop</code>","text":"<p>Transforms a list of spaCy documents to a pair of OMOP tables.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.OmopConnector.docs2omop--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p>List of spaCy documents.</p> <p> TYPE: <code>List[Doc]</code> </p> <code>extensions</code> <p>Extensions to keep, by default None</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>note</code> <p>OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>OMOP <code>note_nlp</code> table.</p> <p> TYPE: <code>DataFrame</code> </p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.omop2docs","title":"<code>omop2docs</code>","text":"<p>Transforms an OMOP-formatted pair of dataframes into a list of documents.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.omop2docs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>The OMOP <code>note</code> table.</p> <p> TYPE: <code>DataFrame</code> </p> <code>note_nlp</code> <p>The OMOP <code>note_nlp</code> table</p> <p> TYPE: <code>DataFrame</code> </p> <code>nlp</code> <p>spaCy language object.</p> <p> TYPE: <code>Language</code> </p> <code>extensions</code> <p>Extensions to keep, by default None</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Doc] :</code> <p>List of spaCy documents</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.docs2omop","title":"<code>docs2omop</code>","text":"<p>Transforms a list of spaCy docs to a pair of OMOP tables.</p>"},{"location":"reference/edsnlp/connectors/omop/#edsnlp.connectors.omop.docs2omop--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p>List of documents to transform.</p> <p> TYPE: <code>List[Doc]</code> </p> <code>extensions</code> <p>Extensions to keep, by default None</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tuple[DataFrame, DataFrame]</code> <p>Pair of OMOP tables (<code>note</code> and <code>note_nlp</code>)</p>"},{"location":"reference/edsnlp/extensions/","title":"<code>edsnlp.extensions</code>","text":""},{"location":"reference/edsnlp/language/","title":"<code>edsnlp.language</code>","text":""},{"location":"reference/edsnlp/language/#edsnlp.language.EDSDefaults","title":"<code>EDSDefaults</code>","text":"<p>           Bases: <code>FrenchDefaults</code></p> <p>Defaults for the EDSLanguage class Mostly identical to the FrenchDefaults, but without tokenization info</p>"},{"location":"reference/edsnlp/language/#edsnlp.language.EDSLanguage","title":"<code>EDSLanguage</code>","text":"<p>           Bases: <code>French</code></p> <p>French clinical language. It is shipped with the <code>EDSTokenizer</code> tokenizer that better handles tokenization for French clinical documents</p>"},{"location":"reference/edsnlp/language/#edsnlp.language.EDSTokenizer","title":"<code>EDSTokenizer</code>","text":"<p>           Bases: <code>DummyTokenizer</code></p> <pre><code>    Tokenizer class for French clinical documents.\n    It better handles tokenization around:\n    - numbers: \"ACR5\" -&gt; [\"ACR\", \"5\"] instead of [\"ACR5\"]\n    - newlines: \"\n</code></pre> <p>\" -&gt; [\" \", \" \", \" \"] instead of [\"</p> <p>\"]         and should be around 5-6 times faster than its standard French counterpart.         Parameters         ----------         vocab: Vocab             The spacy vocabulary</p>"},{"location":"reference/edsnlp/language/#edsnlp.language.EDSTokenizer.__call__","title":"<code>__call__</code>","text":"<p>Tokenizes the text using the EDSTokenizer</p>"},{"location":"reference/edsnlp/language/#edsnlp.language.EDSTokenizer.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>text</code> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Doc</code>"},{"location":"reference/edsnlp/language/#edsnlp.language.create_eds_tokenizer","title":"<code>create_eds_tokenizer</code>","text":"<p>Creates a factory that returns new EDSTokenizer instances</p> RETURNS DESCRIPTION <code>EDSTokenizer</code>"},{"location":"reference/edsnlp/matchers/","title":"<code>edsnlp.matchers</code>","text":""},{"location":"reference/edsnlp/matchers/regex/","title":"<code>edsnlp.matchers.regex</code>","text":""},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher","title":"<code>RegexMatcher</code>","text":"<p>           Bases: <code>object</code></p> <p>Simple RegExp matcher.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>alignment_mode</code> <p>How spans should be aligned with tokens. Possible values are <code>strict</code> (character indices must be aligned with token boundaries), \"contract\" (span of all tokens completely within the character span), \"expand\" (span of all tokens at least partially covered by the character span). Defaults to <code>expand</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'expand'</code> </p> <code>attr</code> <p>Default attribute to match on, by default \"TEXT\". Can be overiden in the <code>add</code> method.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'TEXT'</code> </p> <code>flags</code> <p>Additional flags provided to the <code>re</code> module. Can be overiden in the <code>add</code> method.</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>ignore_excluded</code> <p>Whether to skip exclusions</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p>You won't be able to match on newlines if this is enabled and the \"spaces\"/\"newline\" option of <code>eds.normalizer</code> is enabled (by default).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>span_from_group</code> <p>If set to <code>False</code>, will create spans basede on the regex's full match. If set to <code>True</code>, will use the first matching capturing group as a span (and fall back to using the full match if no capturing group is matching)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.build_patterns","title":"<code>build_patterns</code>","text":"<p>Build patterns and adds them for matching. Helper function for pipelines using this matcher.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.build_patterns--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>regex</code> <p>Dictionary of label/terms, or label/dictionary of terms/attribute.</p> <p> TYPE: <code>Patterns</code> </p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.add","title":"<code>add</code>","text":"<p>Add a pattern to the registry.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.add--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>key</code> <p>Key of the new/updated pattern.</p> <p> TYPE: <code>str</code> </p> <code>patterns</code> <p>List of patterns to add.</p> <p> TYPE: <code>List[str]</code> </p> <code>attr</code> <p>Attribute to use for matching. By default, uses the <code>default_attr</code> attribute</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>None</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p>You won't be able to match on newlines if this is enabled and the \"spaces\"/\"newline\" option of <code>eds.normalizer</code> is enabled (by default).</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>None</code> </p> <p>alignment_mode : Optional[str]     Overwrite alignment mode.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.remove","title":"<code>remove</code>","text":"<p>Remove a pattern for the registry.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.remove--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>key</code> <p>key of the pattern to remove.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the key is not present in the registered patterns.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.match","title":"<code>match</code>","text":"<p>Iterates on the matches.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.match--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>spaCy Doc or Span object to match on.</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> YIELDS DESCRIPTION <code>span</code> <p>A match.</p> <p> TYPE:: <code>Tuple[Span, Match]</code> </p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.match_with_groupdict_as_spans","title":"<code>match_with_groupdict_as_spans</code>","text":"<p>Iterates on the matches.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.match_with_groupdict_as_spans--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>spaCy Doc or Span object to match on.</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> YIELDS DESCRIPTION <code>span</code> <p>A match.</p> <p> TYPE:: <code>Tuple[Span, Dict[str, Span]]</code> </p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.__call__","title":"<code>__call__</code>","text":"<p>Performs matching. Yields matches.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.RegexMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>spaCy Doc or Span object.</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> <code>as_spans</code> <p>Returns matches as spans.</p> <p> DEFAULT: <code>False</code> </p> YIELDS DESCRIPTION <code>span</code> <p>A match.</p> <p> TYPE:: <code>Union[Span, Tuple[Span, Dict[str, Any]]]</code> </p> <code>groupdict</code> <p>Additional information coming from the named patterns in the regular expression.</p> <p> TYPE:: <code>Union[Span, Tuple[Span, Dict[str, Any]]]</code> </p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.spans_generator","title":"<code>spans_generator</code>","text":"<p>Iterates over every group, and then yields the full match</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.spans_generator--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>match</code> <p>A match object</p> <p> TYPE: <code>Match</code> </p> YIELDS DESCRIPTION <code>Tuple[int, int]</code> <p>A tuple containing the start and end of the group or match</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.span_from_match","title":"<code>span_from_match</code>","text":"<p>Return the span (as a (start, end) tuple) of the first matching group. If <code>span_from_group=True</code>, returns the full match instead.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.span_from_match--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>match</code> <p>The Match object</p> <p> TYPE: <code>Match</code> </p> <code>span_from_group</code> <p>Whether to work on groups or on the full match</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>Tuple[int, int]</code> <p>A tuple containing the start and end of the group or match</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.create_span","title":"<code>create_span</code>","text":"<p>spaCy only allows strict alignment mode for char_span on Spans. This method circumvents this.</p>"},{"location":"reference/edsnlp/matchers/regex/#edsnlp.matchers.regex.create_span--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p><code>Doc</code> or <code>Span</code>.</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> <code>start_char</code> <p>Character index within the Doc-like object.</p> <p> TYPE: <code>int</code> </p> <code>end_char</code> <p>Character index of the end, within the Doc-like object.</p> <p> TYPE: <code>int</code> </p> <code>key</code> <p>The key used to match.</p> <p> TYPE: <code>str</code> </p> <code>alignment_mode</code> <p>The alignment mode.</p> <p> TYPE: <code>str</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>span</code> <p>A span matched on the Doc-like object.</p> <p> TYPE: <code>Span</code> </p>"},{"location":"reference/edsnlp/matchers/simstring/","title":"<code>edsnlp.matchers.simstring</code>","text":""},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.SimstringWriter","title":"<code>SimstringWriter</code>","text":"<p>A context class to write a simstring database</p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.SimstringWriter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>path</code> <p>Path to database</p> <p> TYPE: <code>Union[str, Path]</code> </p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.SimstringMatcher","title":"<code>SimstringMatcher</code>","text":"<p>PhraseMatcher that allows to skip excluded tokens. Heavily inspired by https://github.com/Georgetown-IR-Lab/QuickUMLS</p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.SimstringMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>vocab</code> <p>spaCy vocabulary to match on.</p> <p> TYPE: <code>Vocab</code> </p> <code>path</code> <p>Path where we will store the precomputed patterns</p> <p> TYPE: <code>Optional[Union[Path, str]]</code> DEFAULT: <code>None</code> </p> <code>measure</code> <p>Name of the similarity measure. One of [jaccard, dice, overlap, cosine]</p> <p> TYPE: <code>SimilarityMeasure</code> DEFAULT: <code>dice</code> </p> <code>windows</code> <p>Maximum number of words in a candidate span</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>threshold</code> <p>Minimum similarity value to match a concept's synonym</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.75</code> </p> <code>ignore_excluded</code> <p>Whether to exclude tokens that have an EXCLUDED tag, by default False</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to exclude tokens that have a \"SPACE\" tag, by default False</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>Default attribute to match on, by default \"TEXT\". Can be overridden in the <code>add</code> method. To match on a custom attribute, prepend the attribute name with <code>_</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.SimstringMatcher.build_patterns","title":"<code>build_patterns</code>","text":"<p>Build patterns and adds them for matching.</p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.SimstringMatcher.build_patterns--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The instance of the spaCy language class.</p> <p> TYPE: <code>Language</code> </p> <code>terms</code> <p>Dictionary of label/terms, or label/dictionary of terms/attribute.</p> <p> TYPE: <code>Patterns</code> </p> <code>progress</code> <p>Whether to track progress when preprocessing terms</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.get_text_and_offsets","title":"<code>get_text_and_offsets</code>  <code>cached</code>","text":"<p>Align different representations of a <code>Doc</code> or <code>Span</code> object.</p>"},{"location":"reference/edsnlp/matchers/simstring/#edsnlp.matchers.simstring.get_text_and_offsets--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>spaCy <code>Doc</code> or <code>Span</code> object</p> <p> TYPE: <code>Doc</code> </p> <code>attr</code> <p>Attribute to use, by default <code>\"TEXT\"</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'TEXT'</code> </p> <code>ignore_excluded</code> <p>Whether to remove excluded tokens, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_space_tokens</code> <p>Whether to remove space tokens, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tuple[str, List[Tuple[int, int, int, int]]]</code> <p>The new clean text and offset tuples for each word giving the begin char indice of the word in the new text, the end char indice of its preceding word and the begin / end indices of the word in the original document</p>"},{"location":"reference/edsnlp/matchers/utils/","title":"<code>edsnlp.matchers.utils</code>","text":""},{"location":"reference/edsnlp/matchers/utils/offset/","title":"<code>edsnlp.matchers.utils.offset</code>","text":""},{"location":"reference/edsnlp/matchers/utils/offset/#edsnlp.matchers.utils.offset.alignment","title":"<code>alignment</code>  <code>cached</code>","text":"<p>Align different representations of a <code>Doc</code> or <code>Span</code> object.</p>"},{"location":"reference/edsnlp/matchers/utils/offset/#edsnlp.matchers.utils.offset.alignment--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy <code>Doc</code> or <code>Span</code> object</p> <p> TYPE: <code>Doc</code> </p> <code>attr</code> <p>Attribute to use, by default <code>\"TEXT\"</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'TEXT'</code> </p> <code>ignore_excluded</code> <p>Whether to remove excluded tokens, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_space_tokens</code> <p>Whether to remove space tokens, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tuple[List[int], List[int]]</code> <p>An alignment tuple: original and clean lists.</p>"},{"location":"reference/edsnlp/matchers/utils/offset/#edsnlp.matchers.utils.offset.offset","title":"<code>offset</code>","text":"<p>Compute offset between the original text and a given representation (defined by the couple <code>attr</code>, <code>ignore_excluded</code>).</p> <p>The alignment itself is computed with <code>alignment</code>.</p>"},{"location":"reference/edsnlp/matchers/utils/offset/#edsnlp.matchers.utils.offset.offset--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>The spaCy <code>Doc</code> object</p> <p> TYPE: <code>Doc</code> </p> <code>attr</code> <p>The attribute used by the <code>RegexMatcher</code> (eg <code>NORM</code>)</p> <p> TYPE: <code>str</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded tokens.</p> <p> TYPE: <code>bool</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore spaces tokens.</p> <p> TYPE: <code>bool</code> </p> <code>index</code> <p>The index in the pre-processed text.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The offset. To get the character index in the original document, just do: <code>original = index + offset(doc, attr, ignore_excluded, index)</code></p>"},{"location":"reference/edsnlp/matchers/utils/text/","title":"<code>edsnlp.matchers.utils.text</code>","text":""},{"location":"reference/edsnlp/matchers/utils/text/#edsnlp.matchers.utils.text.get_text","title":"<code>get_text</code>  <code>cached</code>","text":"<p>Get text using a custom attribute, possibly ignoring excluded tokens.</p>"},{"location":"reference/edsnlp/matchers/utils/text/#edsnlp.matchers.utils.text.get_text--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>Doc or Span to get text from.</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> <code>attr</code> <p>Attribute to use.</p> <p> TYPE: <code>str</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens, by default False</p> <p> TYPE: <code>bool</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Extracted text.</p>"},{"location":"reference/edsnlp/patch_spacy_dot_components/","title":"<code>edsnlp.patch_spacy_dot_components</code>","text":""},{"location":"reference/edsnlp/patch_spacy_dot_components/#edsnlp.patch_spacy_dot_components.factory","title":"<code>factory</code>  <code>classmethod</code>","text":"<p>Patched from spaCy to allow back dots in factory names (https://github.com/aphp/edsnlp/pull/152)</p> <p>Register a new pipeline component factory. Can be used as a decorator on a function or classmethod, or called as a function with the factory provided as the func keyword argument. To create a component and add it to the pipeline, you can use nlp.add_pipe(name).</p> <p>name (str): The name of the component factory. default_config (Dict[str, Any]): Default configuration, describing the     default values of the factory arguments. assigns (Iterable[str]): Doc/Token attributes assigned by this component,     e.g. \"token.ent_id\". Used for pipeline analysis. requires (Iterable[str]): Doc/Token attributes required by this component,     e.g. \"token.ent_id\". Used for pipeline analysis. retokenizes (bool): Whether the component changes the tokenization.     Used for pipeline analysis. default_score_weights (Dict[str, Optional[float]]): The scores to report during     training, and their default weight towards the final score used to     select the best model. Weights should sum to 1.0 per component and     will be combined and normalized for the whole pipeline. If None,     the score won't be shown in the logs or be weighted. func (Optional[Callable]): Factory function if not used as a decorator.</p> <p>DOCS: https://spacy.io/api/language#factory</p>"},{"location":"reference/edsnlp/pipelines/","title":"<code>edsnlp.pipelines</code>","text":""},{"location":"reference/edsnlp/pipelines/base/","title":"<code>edsnlp.pipelines.base</code>","text":""},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.BaseComponent","title":"<code>BaseComponent</code>","text":"<p>The <code>BaseComponent</code> adds a <code>set_extensions</code> method, called at the creation of the object.</p> <p>It helps decouple the initialisation of the pipeline from the creation of extensions, and is particularly usefull when distributing EDSNLP on a cluster, since the serialisation mechanism imposes that the extensions be reset.</p>"},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.BaseComponent.set_extensions","title":"<code>set_extensions</code>","text":"<p>Set <code>Doc</code>, <code>Span</code> and <code>Token</code> extensions.</p>"},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.BaseComponent.get_spans","title":"<code>get_spans</code>","text":"<p>Returns sorted spans of interest according to the possible value of <code>on_ents_only</code>. Includes <code>doc.ents</code> by default, and adds eventual SpanGroups.</p>"},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.SpanSetterArg","title":"<code>SpanSetterArg</code>","text":"<p>Valid values for the <code>span_setter</code> argument of a component can be :</p> <ul> <li>a (doc, matches) -&gt; None callable</li> <li>a span group name</li> <li>a list of span group names</li> <li>a dict of group name to True or list of labels</li> </ul> <p>The group name <code>\"ents\"</code> is a special case, and will add the matches to <code>doc.ents</code></p>"},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.SpanSetterArg--examples","title":"Examples","text":"<ul> <li><code>span_setter=[\"ents\", \"ckd\"]</code> will add the matches to both <code>doc.ents</code> and <code>doc.spans[\"ckd\"]</code>. It is equivalent to <code>{\"ents\": True, \"ckd\": True}</code>.</li> <li><code>span_setter={\"ents\": [\"foo\", \"bar\"]}</code> will add the matches with label \"foo\" and \"bar\" to <code>doc.ents</code>.</li> <li><code>span_setter=\"ents\"</code> will add all matches only to <code>doc.ents</code>.</li> <li><code>span_setter=\"ckd\"</code> will add all matches only to <code>doc.spans[\"ckd\"]</code>.</li> </ul>"},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.SpanGetterArg","title":"<code>SpanGetterArg</code>","text":"<p>Valid values for the <code>span_getter</code> argument of a component can be :</p> <ul> <li>a (doc) -&gt; spans callable</li> <li>a span group name</li> <li>a list of span group names</li> <li>a dict of group name to True or list of labels</li> </ul> <p>The group name <code>\"ents\"</code> is a special case, and will get the matches from <code>doc.ents</code></p>"},{"location":"reference/edsnlp/pipelines/base/#edsnlp.pipelines.base.SpanGetterArg--examples","title":"Examples","text":"<ul> <li><code>span_getter=[\"ents\", \"ckd\"]</code> will get the matches from both <code>doc.ents</code> and <code>doc.spans[\"ckd\"]</code>. It is equivalent to <code>{\"ents\": True, \"ckd\": True}</code>.</li> <li><code>span_getter={\"ents\": [\"foo\", \"bar\"]}</code> will get the matches with label \"foo\" and \"bar\" from <code>doc.ents</code>.</li> <li><code>span_getter=\"ents\"</code> will get all matches from <code>doc.ents</code>.</li> <li><code>span_getter=\"ckd\"</code> will get all matches from <code>doc.spans[\"ckd\"]</code>.</li> </ul>"},{"location":"reference/edsnlp/pipelines/core/","title":"<code>edsnlp.pipelines.core</code>","text":""},{"location":"reference/edsnlp/pipelines/core/context/","title":"<code>edsnlp.pipelines.core.context</code>","text":""},{"location":"reference/edsnlp/pipelines/core/context/context/","title":"<code>edsnlp.pipelines.core.context.context</code>","text":""},{"location":"reference/edsnlp/pipelines/core/context/context/#edsnlp.pipelines.core.context.context.ContextAdder","title":"<code>ContextAdder</code>","text":"<p>           Bases: <code>BaseComponent</code></p> <p>Provides a generic context adder component.</p>"},{"location":"reference/edsnlp/pipelines/core/context/context/#edsnlp.pipelines.core.context.context.ContextAdder--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>context</code> <p>The list of extensions to add to the <code>Doc</code></p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"reference/edsnlp/pipelines/core/context/factory/","title":"<code>edsnlp.pipelines.core.context.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/","title":"<code>edsnlp.pipelines.core.contextual_matcher</code>","text":""},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/","title":"<code>edsnlp.pipelines.core.contextual_matcher.contextual_matcher</code>","text":""},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher","title":"<code>ContextualMatcher</code>","text":"<p>           Bases: <code>BaseNERComponent</code></p> <p>Allows additional matching in the surrounding context of the main match group, for qualification/filtering.</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>patterns</code> <p>The configuration dictionary</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> </p> <code>assign_as_span</code> <p>Whether to store eventual extractions defined via the <code>assign</code> key as Spans or as string</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>alignment_mode</code> <p>Overwrite alignment mode.</p> <p> TYPE: <code>str</code> DEFAULT: <code>expand</code> </p> <code>regex_flags</code> <p>RegExp flags to use when matching, filtering and assigning (See here)</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>include_assigned</code> <p>Whether to include (eventual) assign matches to the final entity</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>label_name</code> <p>Deprecated, use <code>label</code> instead. The label to assign to the matched entities</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>The label to assign to the matched entities</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.filter_one","title":"<code>filter_one</code>","text":"<p>Filter extracted entity based on the \"exclusion filter\" mentioned in the configuration</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.filter_one--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>span</code> <p>Span to filter</p> <p> TYPE: <code>Span</code> </p> RETURNS DESCRIPTION <code>Optional[Span]</code> <p>None if the span was filtered, the span else</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.assign_one","title":"<code>assign_one</code>","text":"<p>Get additional information in the context of each entity. This function will populate two custom attributes:</p> <ul> <li><code>ent._.source</code></li> <li><code>ent._.assigned</code>, a dictionary with all retrieved information</li> </ul>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.assign_one--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>span</code> <p>Span to enrich</p> <p> TYPE: <code>Span</code> </p> RETURNS DESCRIPTION <code>Span</code> <p>Span with additional information</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.process","title":"<code>process</code>","text":"<p>Process the document, looking for named entities.</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>List[Span]</code> <p>List of detected spans.</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.__call__","title":"<code>__call__</code>","text":"<p>Adds spans to document.</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/contextual_matcher/#edsnlp.pipelines.core.contextual_matcher.contextual_matcher.ContextualMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for extracted terms.</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/factory/","title":"<code>edsnlp.pipelines.core.contextual_matcher.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/factory/#edsnlp.pipelines.core.contextual_matcher.factory.create_component","title":"<code>create_component = Language.factory('eds.contextual-matcher')(create_component)</code>  <code>module-attribute</code>","text":"<p>Allows additional matching in the surrounding context of the main match group, for qualification/filtering.</p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/factory/#edsnlp.pipelines.core.contextual_matcher.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>patterns</code> <p>The configuration dictionary</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> </p> <code>assign_as_span</code> <p>Whether to store eventual extractions defined via the <code>assign</code> key as Spans or as string</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>alignment_mode</code> <p>Overwrite alignment mode.</p> <p> TYPE: <code>str</code> DEFAULT: <code>expand</code> </p> <code>regex_flags</code> <p>RegExp flags to use when matching, filtering and assigning (See here)</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>include_assigned</code> <p>Whether to include (eventual) assign matches to the final entity</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>label_name</code> <p>Deprecated, use <code>label</code> instead. The label to assign to the matched entities</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>The label to assign to the matched entities</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/models/","title":"<code>edsnlp.pipelines.core.contextual_matcher.models</code>","text":""},{"location":"reference/edsnlp/pipelines/core/contextual_matcher/models/#edsnlp.pipelines.core.contextual_matcher.models.AssignDict","title":"<code>AssignDict</code>","text":"<p>           Bases: <code>dict</code></p> <p>Custom dictionary that overrides the setitem method depending on the reduce_mode</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/","title":"<code>edsnlp.pipelines.core.endlines</code>","text":""},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/","title":"<code>edsnlp.pipelines.core.endlines.endlines</code>","text":"<ol><li><p><p>Zweigenbaum P., Grouin C. and Lavergne T., 2016. Une cat\\'egorisation de fins de lignes non-supervis\\'ee (End-of-line classification with no supervision).</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher","title":"<code>EndLinesMatcher</code>","text":"<p>           Bases: <code>GenericMatcher</code></p> <p>The <code>eds.endlines</code> component classifies newline characters as actual end of lines or mere spaces. In the latter case, the token is removed from the normalised document.</p> <p>Behind the scenes, it uses a <code>endlinesmodel</code> instance, which is an unsupervised algorithm based on the work of Zweigenbaum et al., 2016.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher--training","title":"Training","text":"<pre><code>import spacy\nfrom edsnlp.pipelines.core.endlines.model import EndLinesModel\n\nnlp = spacy.blank(\"eds\")\n\ntexts = [\n\"\"\"\nLe patient est arriv\u00e9 hier soir.\nIl est accompagn\u00e9 par son fils\n\nANTECEDENTS\nIl a fait une TS en 2010\nFumeur, il est arret\u00e9 il a 5 mois\nChirurgie de coeur en 2011\nCONCLUSION\nIl doit prendre\nle medicament indiqu\u00e9 3 fois par jour. Revoir m\u00e9decin\ndans 1 mois.\nDIAGNOSTIC :\n\nAntecedents Familiaux:\n- 1. P\u00e8re avec diabete\n\"\"\",\n\"\"\"\nJ'aime le\nfromage...\n\"\"\",\n]\n\ndocs = list(nlp.pipe(texts))\n\n# Train and predict an EndLinesModel\nendlines = EndLinesModel(nlp=nlp)\n\ndf = endlines.fit_and_predict(docs)\ndf.head()\n\nPATH = \"/tmp/path_to_save\"\nendlines.save(PATH)\n</code></pre>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher--examples","title":"Examples","text":"<pre><code>import spacy\nfrom spacy.tokens import Span\nfrom spacy import displacy\n\nnlp = spacy.blank(\"eds\")\n\nPATH = \"/tmp/path_to_save\"\nnlp.add_pipe(\"eds.endlines\", config=dict(model_path=PATH))\n\ndocs = list(nlp.pipe(texts))\n\ndoc_exemple = docs[1]\n\ndoc_exemple.ents = tuple(\n    Span(doc_exemple, token.i, token.i + 1, \"excluded\")\n    for token in doc_exemple\n    if token.tag_ == \"EXCLUDED\"\n)\n\ndisplacy.render(doc_exemple, style=\"ent\", options={\"colors\": {\"space\": \"red\"}})\n</code></pre>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.endlines</code> pipeline declares one extension, on both <code>Span</code> and <code>Token</code> objects. The <code>end_line</code> attribute is a boolean, set to <code>True</code> if the pipeline predicts that the new line is an end line character. Otherwise, it is set to <code>False</code> if the new line is classified as a space.</p> <p>The pipeline also sets the <code>excluded</code> custom attribute on newlines that are classified as spaces. It lets downstream matchers skip excluded tokens (see normalisation) for more detail.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> DEFAULT: <code>eds.endlines</code> </p> <code>model_path</code> <p>Path to trained model. If None, it will use a default model</p> <p> TYPE: <code>Optional[Union[str, EndLinesModel]]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.endlines</code> pipeline was developed by AP-HP's Data Science team based on the work of Zweigenbaum et al., 2016.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher.__call__","title":"<code>__call__</code>","text":"<p>Predict for each new line if it's an end of line or a space.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/endlines/#edsnlp.pipelines.core.endlines.endlines.EndLinesMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p> TYPE: <code>spaCy Doc object, with each new line annotated</code> </p>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/","title":"<code>edsnlp.pipelines.core.endlines.factory</code>","text":"<ol><li><p><p>Zweigenbaum P., Grouin C. and Lavergne T., 2016. Une cat\\'egorisation de fins de lignes non-supervis\\'ee (End-of-line classification with no supervision).</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/#edsnlp.pipelines.core.endlines.factory.create_component","title":"<code>create_component = Language.factory('eds.endlines', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.endlines</code> component classifies newline characters as actual end of lines or mere spaces. In the latter case, the token is removed from the normalised document.</p> <p>Behind the scenes, it uses a <code>endlinesmodel</code> instance, which is an unsupervised algorithm based on the work of Zweigenbaum et al., 2016.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/#edsnlp.pipelines.core.endlines.factory.create_component--training","title":"Training","text":"<pre><code>import spacy\nfrom edsnlp.pipelines.core.endlines.model import EndLinesModel\n\nnlp = spacy.blank(\"eds\")\n\ntexts = [\n\"\"\"\nLe patient est arriv\u00e9 hier soir.\nIl est accompagn\u00e9 par son fils\n\nANTECEDENTS\nIl a fait une TS en 2010\nFumeur, il est arret\u00e9 il a 5 mois\nChirurgie de coeur en 2011\nCONCLUSION\nIl doit prendre\nle medicament indiqu\u00e9 3 fois par jour. Revoir m\u00e9decin\ndans 1 mois.\nDIAGNOSTIC :\n\nAntecedents Familiaux:\n- 1. P\u00e8re avec diabete\n\"\"\",\n\"\"\"\nJ'aime le\nfromage...\n\"\"\",\n]\n\ndocs = list(nlp.pipe(texts))\n\n# Train and predict an EndLinesModel\nendlines = EndLinesModel(nlp=nlp)\n\ndf = endlines.fit_and_predict(docs)\ndf.head()\n\nPATH = \"/tmp/path_to_save\"\nendlines.save(PATH)\n</code></pre>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/#edsnlp.pipelines.core.endlines.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\nfrom spacy.tokens import Span\nfrom spacy import displacy\n\nnlp = spacy.blank(\"eds\")\n\nPATH = \"/tmp/path_to_save\"\nnlp.add_pipe(\"eds.endlines\", config=dict(model_path=PATH))\n\ndocs = list(nlp.pipe(texts))\n\ndoc_exemple = docs[1]\n\ndoc_exemple.ents = tuple(\n    Span(doc_exemple, token.i, token.i + 1, \"excluded\")\n    for token in doc_exemple\n    if token.tag_ == \"EXCLUDED\"\n)\n\ndisplacy.render(doc_exemple, style=\"ent\", options={\"colors\": {\"space\": \"red\"}})\n</code></pre>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/#edsnlp.pipelines.core.endlines.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.endlines</code> pipeline declares one extension, on both <code>Span</code> and <code>Token</code> objects. The <code>end_line</code> attribute is a boolean, set to <code>True</code> if the pipeline predicts that the new line is an end line character. Otherwise, it is set to <code>False</code> if the new line is classified as a space.</p> <p>The pipeline also sets the <code>excluded</code> custom attribute on newlines that are classified as spaces. It lets downstream matchers skip excluded tokens (see normalisation) for more detail.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/#edsnlp.pipelines.core.endlines.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> DEFAULT: <code>eds.endlines</code> </p> <code>model_path</code> <p>Path to trained model. If None, it will use a default model</p> <p> TYPE: <code>Optional[Union[str, EndLinesModel]]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/core/endlines/factory/#edsnlp.pipelines.core.endlines.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.endlines</code> pipeline was developed by AP-HP's Data Science team based on the work of Zweigenbaum et al., 2016.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/functional/","title":"<code>edsnlp.pipelines.core.endlines.functional</code>","text":""},{"location":"reference/edsnlp/pipelines/core/endlines/functional/#edsnlp.pipelines.core.endlines.functional.build_path","title":"<code>build_path</code>","text":"<p>Function to build an absolut path.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/functional/#edsnlp.pipelines.core.endlines.functional.build_path--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>file</code> <code>relative_path</code> <p>relative path from the main file to the desired output</p> <p> </p> RETURNS DESCRIPTION <code>path</code> <p> TYPE: <code>absolute path</code> </p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/","title":"<code>edsnlp.pipelines.core.endlines.model</code>","text":""},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel","title":"<code>EndLinesModel</code>","text":"<p>Model to classify if an end line is a real one or it should be a space.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel.fit_and_predict","title":"<code>fit_and_predict</code>","text":"<p>Fit the model and predict for the training data</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel.fit_and_predict--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>corpus</code> <p>An iterable of Documents</p> <p> TYPE: <code>Iterable[Doc]</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>one line by end_line prediction</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel.predict","title":"<code>predict</code>","text":"<p>Use the model for inference</p> <p>The df should have the following columns: <code>[\"A1\",\"A2\",\"A3\",\"A4\",\"B1\",\"B2\",\"BLANK_LINE\"]</code></p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel.predict--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>df</code> <p>The df should have the following columns: <code>[\"A1\",\"A2\",\"A3\",\"A4\",\"B1\",\"B2\",\"BLANK_LINE\"]</code></p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>The result is added to the column <code>PREDICTED_END_LINE</code></p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel.save","title":"<code>save</code>","text":"<p>Save a pickle of the model. It could be read by the pipeline later.</p>"},{"location":"reference/edsnlp/pipelines/core/endlines/model/#edsnlp.pipelines.core.endlines.model.EndLinesModel.save--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>path</code> <p>path to file .pkl, by default <code>base_model.pkl</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'base_model.pkl'</code> </p>"},{"location":"reference/edsnlp/pipelines/core/matcher/","title":"<code>edsnlp.pipelines.core.matcher</code>","text":""},{"location":"reference/edsnlp/pipelines/core/matcher/factory/","title":"<code>edsnlp.pipelines.core.matcher.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/matcher/factory/#edsnlp.pipelines.core.matcher.factory.create_component","title":"<code>create_component = Language.factory('eds.matcher', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>EDS-NLP simplifies the matching process by exposing a <code>eds.matcher</code> component that can match on terms or regular expressions.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/factory/#edsnlp.pipelines.core.matcher.factory.create_component--examples","title":"Examples","text":"<p>Let us redefine the pipeline :</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],  # (1)\n    patient=\"patient\",  # (2)\n)\n\nregex = dict(\n    covid=r\"coronavirus|covid[-\\s]?19|sars[-\\s]cov[-\\s]2\",  # (3)\n)\n\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=terms,\n        regex=regex,\n        attr=\"LOWER\",\n        term_matcher=\"exact\",\n        term_matcher_config={},\n    ),\n)\n</code></pre> <ol> <li>Every key in the <code>terms</code> dictionary is mapped to a concept.</li> <li>The <code>eds.matcher</code> pipeline expects a list of expressions, or a single expression.</li> <li>We can also define regular expression patterns.</li> </ol> <p>This snippet is complete, and should run as is.</p> <p>Patterns, be they <code>terms</code> or <code>regex</code>, are defined as dictionaries where keys become  the label of the extracted entities. Dictionary values are either a single  expression or a list of expressions that match the concept.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/factory/#edsnlp.pipelines.core.matcher.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.matcher</code> </p> <code>terms</code> <p>A dictionary of terms.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A dictionary of regular expressions.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>The default attribute to use for matching. Can be overridden using the <code>terms</code> and <code>regex</code> configurations.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p>You won't be able to match on newlines if this is enabled and the \"spaces\"/\"newline\" option of <code>eds.normalizer</code> is enabled (by default).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>exact</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher class</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>span_setter</code> <p>How to set the spans in the doc.</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/core/matcher/factory/#edsnlp.pipelines.core.matcher.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.matcher</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/","title":"<code>edsnlp.pipelines.core.matcher.matcher</code>","text":""},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher","title":"<code>GenericMatcher</code>","text":"<p>           Bases: <code>BaseNERComponent</code></p> <p>EDS-NLP simplifies the matching process by exposing a <code>eds.matcher</code> component that can match on terms or regular expressions.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher--examples","title":"Examples","text":"<p>Let us redefine the pipeline :</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],  # (1)\n    patient=\"patient\",  # (2)\n)\n\nregex = dict(\n    covid=r\"coronavirus|covid[-\\s]?19|sars[-\\s]cov[-\\s]2\",  # (3)\n)\n\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=terms,\n        regex=regex,\n        attr=\"LOWER\",\n        term_matcher=\"exact\",\n        term_matcher_config={},\n    ),\n)\n</code></pre> <ol> <li>Every key in the <code>terms</code> dictionary is mapped to a concept.</li> <li>The <code>eds.matcher</code> pipeline expects a list of expressions, or a single expression.</li> <li>We can also define regular expression patterns.</li> </ol> <p>This snippet is complete, and should run as is.</p> <p>Patterns, be they <code>terms</code> or <code>regex</code>, are defined as dictionaries where keys become  the label of the extracted entities. Dictionary values are either a single  expression or a list of expressions that match the concept.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.matcher</code> </p> <code>terms</code> <p>A dictionary of terms.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A dictionary of regular expressions.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>The default attribute to use for matching. Can be overridden using the <code>terms</code> and <code>regex</code> configurations.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p>You won't be able to match on newlines if this is enabled and the \"spaces\"/\"newline\" option of <code>eds.normalizer</code> is enabled (by default).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>exact</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher class</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>span_setter</code> <p>How to set the spans in the doc.</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.matcher</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher.process","title":"<code>process</code>","text":"<p>Find matching spans in doc.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object.</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>spans</code> <p>List of Spans returned by the matchers.</p> <p> TYPE: <code>List[Span]</code> </p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher.__call__","title":"<code>__call__</code>","text":"<p>Adds spans to document.</p>"},{"location":"reference/edsnlp/pipelines/core/matcher/matcher/#edsnlp.pipelines.core.matcher.matcher.GenericMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for extracted terms.</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/","title":"<code>edsnlp.pipelines.core.normalizer</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/","title":"<code>edsnlp.pipelines.core.normalizer.accents</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/accents/","title":"<code>edsnlp.pipelines.core.normalizer.accents.accents</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/accents/#edsnlp.pipelines.core.normalizer.accents.accents.AccentsConverter","title":"<code>AccentsConverter</code>","text":"<p>           Bases: <code>object</code></p> <p>Normalises accents, using a same-length strategy.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/accents/#edsnlp.pipelines.core.normalizer.accents.accents.AccentsConverter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.spaces</code> </p> <code>accents</code> <p>List of accentuated characters and their transcription.</p> <p> TYPE: <code>List[Tuple[str, str]]</code> DEFAULT: <code>[('\u00e7', 'c'), ('\u00e0\u00e1\u00e2\u00e4', 'a'), ('\u00e8\u00e9\u00ea\u00eb', 'e'), ('\u00ec\u00ed...</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/accents/#edsnlp.pipelines.core.normalizer.accents.accents.AccentsConverter.__call__","title":"<code>__call__</code>","text":"<p>Remove accents from spacy <code>NORM</code> attribute.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/accents/#edsnlp.pipelines.core.normalizer.accents.accents.AccentsConverter.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>The spaCy <code>Doc</code> object.</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>Doc</code> <p>The document, with accents removed in <code>Token.norm_</code>.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/factory/","title":"<code>edsnlp.pipelines.core.normalizer.accents.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/factory/#edsnlp.pipelines.core.normalizer.accents.factory.create_component","title":"<code>create_component = Language.factory('eds.accents', assigns=['token.norm'])(create_component)</code>  <code>module-attribute</code>","text":"<p>Normalises accents, using a same-length strategy.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/factory/#edsnlp.pipelines.core.normalizer.accents.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.spaces</code> </p> <code>accents</code> <p>List of accentuated characters and their transcription.</p> <p> TYPE: <code>List[Tuple[str, str]]</code> DEFAULT: <code>[('\u00e7', 'c'), ('\u00e0\u00e1\u00e2\u00e4', 'a'), ('\u00e8\u00e9\u00ea\u00eb', 'e'), ('\u00ec\u00ed...</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/accents/patterns/","title":"<code>edsnlp.pipelines.core.normalizer.accents.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/factory/","title":"<code>edsnlp.pipelines.core.normalizer.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/factory/#edsnlp.pipelines.core.normalizer.factory.create_component","title":"<code>create_component</code>","text":"<p>Normalisation pipeline. Modifies the <code>NORM</code> attribute, acting on five dimensions :</p> <ul> <li><code>lowercase</code>: using the default <code>NORM</code></li> <li><code>accents</code>: deterministic and fixed-length normalisation of accents.</li> <li><code>quotes</code>: deterministic and fixed-length normalisation of quotation marks.</li> <li><code>spaces</code>: \"removal\" of spaces tokens (via the tag_ attribute).</li> <li><code>pollution</code>: \"removal\" of pollutions (via the tag_ attribute).</li> </ul>"},{"location":"reference/edsnlp/pipelines/core/normalizer/factory/#edsnlp.pipelines.core.normalizer.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.normalizer'</code> </p> <code>lowercase</code> <p>Whether to remove case.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>accents</code> <p><code>Accents</code> configuration object</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p> <code>quotes</code> <p><code>Quotes</code> configuration object</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p> <code>spaces</code> <p><code>Spaces</code> configuration object</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p> <code>pollution</code> <p>Optional <code>Pollution</code> configuration object.</p> <p> TYPE: <code>Union[bool, Dict[str, Any]]</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/normalizer/","title":"<code>edsnlp.pipelines.core.normalizer.normalizer</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/normalizer/#edsnlp.pipelines.core.normalizer.normalizer.Normalizer","title":"<code>Normalizer</code>","text":"<p>           Bases: <code>object</code></p> <p>Normalisation pipeline. Modifies the <code>NORM</code> attribute, acting on five dimensions :</p> <ul> <li><code>lowercase</code>: using the default <code>NORM</code></li> <li><code>accents</code>: deterministic and fixed-length normalisation of accents.</li> <li><code>quotes</code>: deterministic and fixed-length normalisation of quotation marks.</li> <li><code>spaces</code>: \"removal\" of spaces tokens (via the tag_ attribute).</li> <li><code>pollution</code>: \"removal\" of pollutions (via the tag_ attribute).</li> </ul>"},{"location":"reference/edsnlp/pipelines/core/normalizer/normalizer/#edsnlp.pipelines.core.normalizer.normalizer.Normalizer--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>'eds.normalizer'</code> </p> <code>lowercase</code> <p>Whether to remove case.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>accents</code> <p>Optional <code>Accents</code> object.</p> <p> TYPE: <code>Optional[Accents]</code> DEFAULT: <code>None</code> </p> <code>quotes</code> <p>Optional <code>Quotes</code> object.</p> <p> TYPE: <code>Optional[Quotes]</code> DEFAULT: <code>None</code> </p> <code>spaces</code> <p>Optional <code>Spaces</code> object.</p> <p> TYPE: <code>Optional[Spaces]</code> DEFAULT: <code>None</code> </p> <code>pollution</code> <p>Optional <code>Pollution</code> object.</p> <p> TYPE: <code>Optional[Pollution]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/normalizer/#edsnlp.pipelines.core.normalizer.normalizer.Normalizer.__call__","title":"<code>__call__</code>","text":"<p>Apply the normalisation pipeline, one component at a time.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/normalizer/#edsnlp.pipelines.core.normalizer.normalizer.Normalizer.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy <code>Doc</code> object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>Doc</code> <p>Doc object with <code>NORM</code> attribute modified</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/","title":"<code>edsnlp.pipelines.core.normalizer.pollution</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/factory/","title":"<code>edsnlp.pipelines.core.normalizer.pollution.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/factory/#edsnlp.pipelines.core.normalizer.pollution.factory.create_component","title":"<code>create_component = Language.factory('eds.pollution', assigns=['doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>Tags pollution tokens.</p> <p>Populates a number of spaCy extensions :</p> <ul> <li><code>Token._.pollution</code> : indicates whether the token is a pollution</li> <li><code>Doc._.clean</code> : lists non-pollution tokens</li> <li><code>Doc._.clean_</code> : original text with pollutions removed.</li> <li><code>Doc._.char_clean_span</code> : method to create a Span using character   indices extracted using the cleaned text.</li> </ul>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/factory/#edsnlp.pipelines.core.normalizer.pollution.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.pollution</code> </p> <code>pollution</code> <p>Dictionary containing regular expressions of pollution.</p> <p> TYPE: <code>Dict[str, Union[str, List[str]]]</code> DEFAULT: <code>{'information': True, 'bars': True, 'biology': ...</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/patterns/","title":"<code>edsnlp.pipelines.core.normalizer.pollution.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/","title":"<code>edsnlp.pipelines.core.normalizer.pollution.pollution</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger","title":"<code>PollutionTagger</code>","text":"<p>           Bases: <code>BaseComponent</code></p> <p>Tags pollution tokens.</p> <p>Populates a number of spaCy extensions :</p> <ul> <li><code>Token._.pollution</code> : indicates whether the token is a pollution</li> <li><code>Doc._.clean</code> : lists non-pollution tokens</li> <li><code>Doc._.clean_</code> : original text with pollutions removed.</li> <li><code>Doc._.char_clean_span</code> : method to create a Span using character   indices extracted using the cleaned text.</li> </ul>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.pollution</code> </p> <code>pollution</code> <p>Dictionary containing regular expressions of pollution.</p> <p> TYPE: <code>Dict[str, Union[str, List[str]]]</code> DEFAULT: <code>{'information': True, 'bars': True, 'biology': ...</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger.build_patterns","title":"<code>build_patterns</code>","text":"<p>Builds the patterns for phrase matching.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger.process","title":"<code>process</code>","text":"<p>Find pollutions in doc and clean candidate negations to remove pseudo negations</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>pollution</code> <p>list of pollution spans</p> <p> TYPE: <code>List[Span]</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger.__call__","title":"<code>__call__</code>","text":"<p>Tags pollutions.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/pollution/pollution/#edsnlp.pipelines.core.normalizer.pollution.pollution.PollutionTagger.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for pollutions.</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/","title":"<code>edsnlp.pipelines.core.normalizer.quotes</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/factory/","title":"<code>edsnlp.pipelines.core.normalizer.quotes.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/factory/#edsnlp.pipelines.core.normalizer.quotes.factory.create_component","title":"<code>create_component = Language.factory('eds.quotes', assigns=['token.norm'])(create_component)</code>  <code>module-attribute</code>","text":"<p>We normalise quotes, following this <code>source &lt;https://www.cl.cam.ac.uk/~mgk25/ucs/quotes.html&gt;</code>_.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/factory/#edsnlp.pipelines.core.normalizer.quotes.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.spaces</code> </p> <code>quotes</code> <p>List of quotation characters and their transcription.</p> <p> TYPE: <code>List[Tuple[str, str]]</code> DEFAULT: <code>[('\uff02\u3003\u05f2\u1cd3\u2033\u05f4\u2036\u02f6\u02ba\u201c\u201d\u02dd\u201f', '\"'), ('\uff40\u0384\uff07\u02c8\u02ca\u144a\u02cb\ua78c\u16cc\ud81b\udf52\ud81b\udf51\u2018\u2019\u05d9\u055a\u201b\u055d`\u1fef\u2032...</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/patterns/","title":"<code>edsnlp.pipelines.core.normalizer.quotes.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/quotes/","title":"<code>edsnlp.pipelines.core.normalizer.quotes.quotes</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/quotes/#edsnlp.pipelines.core.normalizer.quotes.quotes.QuotesConverter","title":"<code>QuotesConverter</code>","text":"<p>We normalise quotes, following this <code>source &lt;https://www.cl.cam.ac.uk/~mgk25/ucs/quotes.html&gt;</code>_.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/quotes/#edsnlp.pipelines.core.normalizer.quotes.quotes.QuotesConverter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.spaces</code> </p> <code>quotes</code> <p>List of quotation characters and their transcription.</p> <p> TYPE: <code>List[Tuple[str, str]]</code> DEFAULT: <code>[('\uff02\u3003\u05f2\u1cd3\u2033\u05f4\u2036\u02f6\u02ba\u201c\u201d\u02dd\u201f', '\"'), ('\uff40\u0384\uff07\u02c8\u02ca\u144a\u02cb\ua78c\u16cc\ud81b\udf52\ud81b\udf51\u2018\u2019\u05d9\u055a\u201b\u055d`\u1fef\u2032...</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/quotes/#edsnlp.pipelines.core.normalizer.quotes.quotes.QuotesConverter.__call__","title":"<code>__call__</code>","text":"<p>Normalises quotes.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/quotes/quotes/#edsnlp.pipelines.core.normalizer.quotes.quotes.QuotesConverter.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>Document to process.</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>Doc</code> <p>Same document, with quotes normalised.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/remove_lowercase/","title":"<code>edsnlp.pipelines.core.normalizer.remove_lowercase</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/remove_lowercase/factory/","title":"<code>edsnlp.pipelines.core.normalizer.remove_lowercase.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/remove_lowercase/factory/#edsnlp.pipelines.core.normalizer.remove_lowercase.factory.remove_lowercase","title":"<code>remove_lowercase</code>","text":"<p>Add case on the <code>NORM</code> custom attribute. Should always be applied first.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/remove_lowercase/factory/#edsnlp.pipelines.core.normalizer.remove_lowercase.factory.remove_lowercase--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>The spaCy <code>Doc</code> object.</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>Doc</code> <p>The document, with case put back in <code>NORM</code>.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/remove_lowercase/factory/#edsnlp.pipelines.core.normalizer.remove_lowercase.factory.create_component","title":"<code>create_component</code>","text":"<p>Add case on the <code>NORM</code> custom attribute. Should always be applied first.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/remove_lowercase/factory/#edsnlp.pipelines.core.normalizer.remove_lowercase.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>str</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/","title":"<code>edsnlp.pipelines.core.normalizer.spaces</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/factory/","title":"<code>edsnlp.pipelines.core.normalizer.spaces.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/factory/#edsnlp.pipelines.core.normalizer.spaces.factory.create_component","title":"<code>create_component = Language.factory('eds.spaces', assigns=['token.tag'])(create_component)</code>  <code>module-attribute</code>","text":"<p>We assign \"SPACE\" to <code>token.tag</code> to be used by optimized components such as the EDSPhraseMatcher</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/factory/#edsnlp.pipelines.core.normalizer.spaces.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.spaces</code> </p> <code>newline</code> <p>Whether to update the newline tokens too</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/spaces/","title":"<code>edsnlp.pipelines.core.normalizer.spaces.spaces</code>","text":""},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/spaces/#edsnlp.pipelines.core.normalizer.spaces.spaces.SpacesTagger","title":"<code>SpacesTagger</code>","text":"<p>We assign \"SPACE\" to <code>token.tag</code> to be used by optimized components such as the EDSPhraseMatcher</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/spaces/#edsnlp.pipelines.core.normalizer.spaces.spaces.SpacesTagger--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.spaces</code> </p> <code>newline</code> <p>Whether to update the newline tokens too</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/spaces/#edsnlp.pipelines.core.normalizer.spaces.spaces.SpacesTagger.__call__","title":"<code>__call__</code>","text":"<p>Apply the component to the doc.</p>"},{"location":"reference/edsnlp/pipelines/core/normalizer/spaces/spaces/#edsnlp.pipelines.core.normalizer.spaces.spaces.SpacesTagger.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/core/sentences/","title":"<code>edsnlp.pipelines.core.sentences</code>","text":""},{"location":"reference/edsnlp/pipelines/core/sentences/factory/","title":"<code>edsnlp.pipelines.core.sentences.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/sentences/factory/#edsnlp.pipelines.core.sentences.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.sentences</code> matcher provides an alternative to spaCy's default <code>sentencizer</code>, aiming to overcome some of its limitations.</p> <p>Indeed, the <code>sentencizer</code> merely looks at period characters to detect the end of a sentence, a strategy that often fails in a clinical note settings. Our <code>eds.sentences</code> component also classifies end-of-lines as sentence boundaries if the subsequent token begins with an uppercase character, leading to slightly better performances.</p> <p>Moreover, the <code>eds.sentences</code> component use the output of the <code>eds.normalizer</code> and <code>eds.endlines</code> output by default when these components are added to the pipeline.</p>"},{"location":"reference/edsnlp/pipelines/core/sentences/factory/#edsnlp.pipelines.core.sentences.factory.create_component--examples","title":"Examples","text":"EDS-NLPspaCy sentencizer <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n\ntext = \"\"\"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\nIl lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans.\"\n\"\"\"\n\ndoc = nlp(text)\n\nfor sentence in doc.sents:\n    print(\"&lt;s&gt;\", sentence, \"&lt;/s&gt;\")\n# Out: &lt;s&gt; Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\n# Out:  &lt;\\s&gt;\n# Out: &lt;s&gt; Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans. &lt;\\s&gt;\n</code></pre> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"sentencizer\")\n\ntext = \"\"\"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\"\nIl lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans.\n\"\"\"\n\ndoc = nlp(text)\n\nfor sentence in doc.sents:\n    print(\"&lt;s&gt;\", sentence, \"&lt;/s&gt;\")\n# Out: &lt;s&gt; Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac\n# Out: Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a deux ans. &lt;\\s&gt;\n</code></pre> <p>Notice how EDS-NLP's implementation is more robust to ill-defined sentence endings.</p>"},{"location":"reference/edsnlp/pipelines/core/sentences/factory/#edsnlp.pipelines.core.sentences.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.sentences'</code> </p> <code>punct_chars</code> <p>Punctuation characters.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>use_endlines</code> <p>Whether to use endlines prediction.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires the upstream <code>eds.normalizer</code> pipe).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/core/sentences/factory/#edsnlp.pipelines.core.sentences.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.sentences</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/core/sentences/terms/","title":"<code>edsnlp.pipelines.core.sentences.terms</code>","text":""},{"location":"reference/edsnlp/pipelines/core/terminology/","title":"<code>edsnlp.pipelines.core.terminology</code>","text":""},{"location":"reference/edsnlp/pipelines/core/terminology/factory/","title":"<code>edsnlp.pipelines.core.terminology.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/core/terminology/factory/#edsnlp.pipelines.core.terminology.factory.create_component","title":"<code>create_component = Language.factory('eds.terminology', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>EDS-NLP simplifies the terminology matching process by exposing a <code>eds.terminology</code> pipeline that can match on terms or regular expressions.</p> <p>The terminology matcher is very similar to the generic matcher, although the use case differs slightly. The generic matcher is designed to extract any entity, while the terminology matcher is specifically tailored towards high volume terminologies.</p> <p>There are some key differences:</p> <ol> <li>It labels every matched entity to the same value, provided to the pipeline</li> <li>The keys provided in the <code>regex</code> and <code>terms</code> dictionaries are used as the    <code>kb_id_</code> of the entity, which handles fine-grained labelling</li> </ol> <p>For instance, a terminology matcher could detect every drug mention under the top-level label <code>drug</code>, and link each individual mention to a given drug through its <code>kb_id_</code> attribute.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/factory/#edsnlp.pipelines.core.terminology.factory.create_component--examples","title":"Examples","text":"<p>Let us redefine the pipeline :</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],  # (1)\n    flu=[\"grippe saisonni\u00e8re\"],  # (2)\n)\n\nregex = dict(\n    covid=r\"coronavirus|covid[-\\s]?19|sars[-\\s]cov[-\\s]2\",  # (3)\n)\n\nnlp.add_pipe(\n    \"eds.terminology\",\n    config=dict(\n        label=\"disease\",\n        terms=terms,\n        regex=regex,\n        attr=\"LOWER\",\n    ),\n)\n</code></pre> <ol> <li>Every key in the <code>terms</code> dictionary is mapped to a concept.</li> <li>The <code>eds.matcher</code> pipeline expects a list of expressions, or a single expression.</li> <li>We can also define regular expression patterns.</li> </ol> <p>This snippet is complete, and should run as is.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/factory/#edsnlp.pipelines.core.terminology.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>terms</code> <p>A dictionary of terms.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A dictionary of regular expressions.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>The default attribute to use for matching. Can be overridden using the <code>terms</code> and <code>regex</code> configurations.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>exact</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher class</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p> <p>Patterns, be they <code>terms</code> or <code>regex</code>, are defined as dictionaries where keys become the <code>kb_id_</code> of the extracted entities. Dictionary values are either a single expression or a list of expressions that match the concept (see example).</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/factory/#edsnlp.pipelines.core.terminology.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.terminology</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/","title":"<code>edsnlp.pipelines.core.terminology.terminology</code>","text":""},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher","title":"<code>TerminologyMatcher</code>","text":"<p>           Bases: <code>BaseNERComponent</code></p> <p>EDS-NLP simplifies the terminology matching process by exposing a <code>eds.terminology</code> pipeline that can match on terms or regular expressions.</p> <p>The terminology matcher is very similar to the generic matcher, although the use case differs slightly. The generic matcher is designed to extract any entity, while the terminology matcher is specifically tailored towards high volume terminologies.</p> <p>There are some key differences:</p> <ol> <li>It labels every matched entity to the same value, provided to the pipeline</li> <li>The keys provided in the <code>regex</code> and <code>terms</code> dictionaries are used as the    <code>kb_id_</code> of the entity, which handles fine-grained labelling</li> </ol> <p>For instance, a terminology matcher could detect every drug mention under the top-level label <code>drug</code>, and link each individual mention to a given drug through its <code>kb_id_</code> attribute.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher--examples","title":"Examples","text":"<p>Let us redefine the pipeline :</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\n\nterms = dict(\n    covid=[\"coronavirus\", \"covid19\"],  # (1)\n    flu=[\"grippe saisonni\u00e8re\"],  # (2)\n)\n\nregex = dict(\n    covid=r\"coronavirus|covid[-\\s]?19|sars[-\\s]cov[-\\s]2\",  # (3)\n)\n\nnlp.add_pipe(\n    \"eds.terminology\",\n    config=dict(\n        label=\"disease\",\n        terms=terms,\n        regex=regex,\n        attr=\"LOWER\",\n    ),\n)\n</code></pre> <ol> <li>Every key in the <code>terms</code> dictionary is mapped to a concept.</li> <li>The <code>eds.matcher</code> pipeline expects a list of expressions, or a single expression.</li> <li>We can also define regular expression patterns.</li> </ol> <p>This snippet is complete, and should run as is.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>terms</code> <p>A dictionary of terms.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A dictionary of regular expressions.</p> <p> TYPE: <code>Optional[Patterns]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>The default attribute to use for matching. Can be overridden using the <code>terms</code> and <code>regex</code> configurations.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>exact</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher class</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True}</code> </p> <p>Patterns, be they <code>terms</code> or <code>regex</code>, are defined as dictionaries where keys become the <code>kb_id_</code> of the extracted entities. Dictionary values are either a single expression or a list of expressions that match the concept (see example).</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.terminology</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher.process","title":"<code>process</code>","text":"<p>Find matching spans in doc.</p> <p>Post-process matches to account for terminology.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object.</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>spans</code> <p>List of Spans returned by the matchers.</p> <p> TYPE: <code>List[Span]</code> </p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher.__call__","title":"<code>__call__</code>","text":"<p>Adds spans to document.</p>"},{"location":"reference/edsnlp/pipelines/core/terminology/terminology/#edsnlp.pipelines.core.terminology.terminology.TerminologyMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for extracted terms.</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/factories/","title":"<code>edsnlp.pipelines.factories</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/","title":"<code>edsnlp.pipelines.misc</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/","title":"<code>edsnlp.pipelines.misc.consultation_dates</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/","title":"<code>edsnlp.pipelines.misc.consultation_dates.consultation_dates</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher","title":"<code>ConsultationDatesMatcher</code>","text":"<p>           Bases: <code>GenericMatcher</code></p> <p>The <code>eds.consultation-dates</code> matcher consists of two main parts:</p> <ul> <li>A matcher which finds mentions of consultation events (more details below)</li> <li>A date parser (see the corresponding pipe) that links a date to those events</li> </ul>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher--examples","title":"Examples","text":"<p>Note</p> <p>The matcher has been built to run on consultation notes (<code>CR-CONS</code> at APHP), so please filter accordingly before proceeding.</p> <pre><code>import spacy\n\n# HIHIHI\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        lowercase=True,\n        accents=True,\n        quotes=True,\n        pollution=False,\n    ),\n)\nnlp.add_pipe(\"eds.consultation_dates\")\n\ntext = \"\"\"\nXXX\nObjet : Compte-Rendu de Consultation du 03/10/2018.\nXXX\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans[\"consultation_dates\"]\n# Out: [Consultation du 03/10/2018]\n\ndoc.spans[\"consultation_dates\"][0]._.consultation_date.to_datetime()\n# Out: DateTime(2018, 10, 3, 0, 0, 0, tzinfo=Timezone('Europe/Paris'))\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.consultation_dates</code> pipeline declares one extension on the <code>Span</code> object: the <code>consultation_date</code> attribute, which is a Python <code>datetime</code> object.</p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>Language pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>consultation_mention</code> <p>List of RegEx for consultation mentions.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains terms directly referring to consultations, such as \"Consultation du...\" or \"Compte rendu du...\". This list is the only one enabled by default since it is fairly precise and not error-prone.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>True</code> </p> <code>town_mention</code> <p>List of RegEx for all AP-HP hospitals' towns mentions.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains the towns of each AP-HP's hospital. Its goal is to fetch dates mentioned as \"Paris, le 13 d\u00e9cembre 2015\". It has a high recall but poor precision, since those dates can often be dates of letter redaction instead of consultation dates.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>False</code> </p> <code>document_date_mention</code> <p>List of RegEx for document date.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains expressions mentioning the date of creation/edition of a document, such as \"Date du rapport: 13/12/2015\" or \"Sign\u00e9 le 13/12/2015\". Like <code>town_mention</code> patterns, it has a high recall but is prone to errors since document date and consultation date aren't necessary similar.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.consultation_dates</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher.process","title":"<code>process</code>","text":"<p>Finds entities</p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/consultation_dates/#edsnlp.pipelines.misc.consultation_dates.consultation_dates.ConsultationDatesMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object with additional <code>doc.spans['consultation_dates]</code> <code>SpanGroup</code></p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/factory/","title":"<code>edsnlp.pipelines.misc.consultation_dates.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/factory/#edsnlp.pipelines.misc.consultation_dates.factory.create_component","title":"<code>create_component = Language.factory('eds.consultation_dates', assigns=['doc.spans', 'doc.ents'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.consultation-dates</code> matcher consists of two main parts:</p> <ul> <li>A matcher which finds mentions of consultation events (more details below)</li> <li>A date parser (see the corresponding pipe) that links a date to those events</li> </ul>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/factory/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--examples","title":"Examples","text":"<p>Note</p> <p>The matcher has been built to run on consultation notes (<code>CR-CONS</code> at APHP), so please filter accordingly before proceeding.</p> <pre><code>import spacy\n\n# HIHIHI\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        lowercase=True,\n        accents=True,\n        quotes=True,\n        pollution=False,\n    ),\n)\nnlp.add_pipe(\"eds.consultation_dates\")\n\ntext = \"\"\"\nXXX\nObjet : Compte-Rendu de Consultation du 03/10/2018.\nXXX\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans[\"consultation_dates\"]\n# Out: [Consultation du 03/10/2018]\n\ndoc.spans[\"consultation_dates\"][0]._.consultation_date.to_datetime()\n# Out: DateTime(2018, 10, 3, 0, 0, 0, tzinfo=Timezone('Europe/Paris'))\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/factory/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.consultation_dates</code> pipeline declares one extension on the <code>Span</code> object: the <code>consultation_date</code> attribute, which is a Python <code>datetime</code> object.</p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/factory/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>Language pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>consultation_mention</code> <p>List of RegEx for consultation mentions.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains terms directly referring to consultations, such as \"Consultation du...\" or \"Compte rendu du...\". This list is the only one enabled by default since it is fairly precise and not error-prone.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>True</code> </p> <code>town_mention</code> <p>List of RegEx for all AP-HP hospitals' towns mentions.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains the towns of each AP-HP's hospital. Its goal is to fetch dates mentioned as \"Paris, le 13 d\u00e9cembre 2015\". It has a high recall but poor precision, since those dates can often be dates of letter redaction instead of consultation dates.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>False</code> </p> <code>document_date_mention</code> <p>List of RegEx for document date.</p> <ul> <li>If <code>type==list</code>: Overrides the default list</li> <li>If <code>type==bool</code>: Uses the default list of True, disable if False</li> </ul> <p>This list contains expressions mentioning the date of creation/edition of a document, such as \"Date du rapport: 13/12/2015\" or \"Sign\u00e9 le 13/12/2015\". Like <code>town_mention</code> patterns, it has a high recall but is prone to errors since document date and consultation date aren't necessary similar.</p> <p> TYPE: <code>Union[List[str], bool]</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/factory/#edsnlp.pipelines.misc.consultation_dates.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.consultation_dates</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/consultation_dates/patterns/","title":"<code>edsnlp.pipelines.misc.consultation_dates.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/","title":"<code>edsnlp.pipelines.misc.dates</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/dates/","title":"<code>edsnlp.pipelines.misc.dates.dates</code>","text":"<p><code>eds.dates</code> pipeline.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher","title":"<code>DatesMatcher</code>","text":"<p>           Bases: <code>BaseNERComponent</code></p> <p>The <code>eds.dates</code> matcher detects and normalize dates within a medical document. We use simple regular expressions to extract date mentions.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher--scope","title":"Scope","text":"<p>The <code>eds.dates</code> pipeline finds absolute (eg <code>23/08/2021</code>) and relative (eg <code>hier</code>, <code>la semaine derni\u00e8re</code>) dates alike. It also handles mentions of duration.</p> Type Example <code>absolute</code> <code>3 mai</code>, <code>03/05/2020</code> <code>relative</code> <code>hier</code>, <code>la semaine derni\u00e8re</code> <code>duration</code> <code>pendant quatre jours</code> <p>See the tutorial for a presentation of a full pipeline featuring the <code>eds.dates</code> component.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher--usage","title":"Usage","text":"<pre><code>import spacy\n\nimport pendulum\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.dates\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac. \"\n    \"Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a un an pendant une semaine. \"\n    \"Il a \u00e9t\u00e9 diagnostiqu\u00e9 en mai 1995.\"\n)\n\ndoc = nlp(text)\n\ndates = doc.spans[\"dates\"]\ndates\n# Out: [23 ao\u00fbt 2021, il y a un an, mai 1995]\n\ndates[0]._.date.to_datetime()\n# Out: 2021-08-23T00:00:00+02:00\n\ndates[1]._.date.to_datetime()\n# Out: None\n\nnote_datetime = pendulum.datetime(2021, 8, 27, tz=\"Europe/Paris\")\n\ndates[1]._.date.to_datetime(note_datetime=note_datetime)\n# Out: 2020-08-27T00:00:00+02:00\n\ndate_2_output = dates[2]._.date.to_datetime(\n    note_datetime=note_datetime,\n    infer_from_context=True,\n    tz=\"Europe/Paris\",\n    default_day=15,\n)\ndate_2_output\n# Out: 1995-05-15T00:00:00+02:00\n\ndoc.spans[\"durations\"]\n# Out: [pendant une semaine]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.dates</code> pipeline declares two extensions on the <code>Span</code> object:</p> <ul> <li>the <code>span._.date</code> attribute of a date contains a parsed version of the date.</li> <li>the <code>span._.duration</code> attribute of a duration contains a parsed version of the   duration.</li> </ul> <p>As with other components, you can use the <code>span._.value</code> attribute to get either the parsed date or the duration depending on the span.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the pipeline component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.dates</code> </p> <code>absolute</code> <p>List of regular expressions for absolute dates.</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>relative</code> <p>List of regular expressions for relative dates (eg <code>hier</code>, <code>la semaine prochaine</code>).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>duration</code> <p>List of regular expressions for durations (eg <code>pendant trois mois</code>).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>false_positive</code> <p>List of regular expressions for false positive (eg phone numbers, etc).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Where to look for dates in the doc. By default, look in the whole doc. You can combine this with the <code>merge_mode</code> argument for interesting results.</p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>merge_mode</code> <p>How to merge matched dates with the spans from <code>span_getter</code>, if given:</p> <ul> <li><code>intersect</code>: return only the matches that fall in the <code>span_getter</code> spans</li> <li><code>align</code>: if a date overlaps a span from <code>span_getter</code> (e.g. a date extracted   by a machine learning model), return the <code>span_getter</code> span instead, and   assign all the parsed information (<code>._.date</code> / <code>._.duration</code>) to it. Otherwise   don't return the date.</li> </ul> <p> TYPE: <code>Literal['intersect', 'align']</code> DEFAULT: <code>intersect</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> and <code>merge_mode</code> instead. Whether to look on dates in the whole document or in specific sentences:</p> <ul> <li>If <code>True</code>: Only look in the sentences of each entity in doc.ents</li> <li>If False: Look in the whole document</li> <li>If given a string <code>key</code> or list of string: Only look in the sentences of   each entity in <code>doc.spans[key]</code></li> </ul> <p> TYPE: <code>Union[bool, str, Iterable[str]]</code> DEFAULT: <code>False</code> </p> <code>detect_periods</code> <p>Whether to detect periods (experimental)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>detect_time</code> <p>Whether to detect time inside dates</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>period_proximity_threshold</code> <p>Max number of words between two dates to extract a period.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>as_ents</code> <p>Deprecated, use span_setter instead. Whether to treat dates as entities</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>spaCy attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>LOWER</code> </p> <code>date_label</code> <p>Label to use for dates</p> <p> TYPE: <code>str</code> DEFAULT: <code>date</code> </p> <code>duration_label</code> <p>Label to use for durations</p> <p> TYPE: <code>str</code> DEFAULT: <code>duration</code> </p> <code>period_label</code> <p>Label to use for periods</p> <p> TYPE: <code>str</code> DEFAULT: <code>period</code> </p> <code>span_setter</code> <p>How to set matches in the doc.</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'dates': ['date'], 'durations': ['duration'], ...</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.dates</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.set_extensions","title":"<code>set_extensions</code>","text":"<p>Set extensions for the dates pipeline.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.process","title":"<code>process</code>","text":"<p>Find dates in doc.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>dates</code> <p>list of date spans</p> <p> TYPE: <code>List[Tuple[Span, Dict[str, str]]]</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.parse","title":"<code>parse</code>","text":"<p>Parse dates/durations using the groupdict returned by the matcher.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.parse--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>matches</code> <p>List of tuples containing the spans and groupdict returned by the matcher.</p> <p> TYPE: <code>List[Tuple[Span, Dict[str, str]]]</code> </p> RETURNS DESCRIPTION <code>Tuple[List[Span], List[Span]]</code> <p>List of processed spans, with the date parsed.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.process_periods","title":"<code>process_periods</code>","text":"<p>Experimental period detection.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.process_periods--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>dates</code> <p>List of detected dates.</p> <p> TYPE: <code>List[Span]</code> </p> RETURNS DESCRIPTION <code>List[Span]</code> <p>List of detected periods.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.__call__","title":"<code>__call__</code>","text":"<p>Tags dates.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/dates/#edsnlp.pipelines.misc.dates.dates.DatesMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for dates</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/dates/factory/","title":"<code>edsnlp.pipelines.misc.dates.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/factory/#edsnlp.pipelines.misc.dates.factory.create_component","title":"<code>create_component = Language.factory('eds.dates', assigns=['doc.spans', 'doc.ents'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.dates</code> matcher detects and normalize dates within a medical document. We use simple regular expressions to extract date mentions.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/factory/#edsnlp.pipelines.misc.dates.factory.create_component--scope","title":"Scope","text":"<p>The <code>eds.dates</code> pipeline finds absolute (eg <code>23/08/2021</code>) and relative (eg <code>hier</code>, <code>la semaine derni\u00e8re</code>) dates alike. It also handles mentions of duration.</p> Type Example <code>absolute</code> <code>3 mai</code>, <code>03/05/2020</code> <code>relative</code> <code>hier</code>, <code>la semaine derni\u00e8re</code> <code>duration</code> <code>pendant quatre jours</code> <p>See the tutorial for a presentation of a full pipeline featuring the <code>eds.dates</code> component.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/factory/#edsnlp.pipelines.misc.dates.factory.create_component--usage","title":"Usage","text":"<pre><code>import spacy\n\nimport pendulum\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.dates\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur \u00e0 l'estomac. \"\n    \"Il lui \u00e9tait arriv\u00e9 la m\u00eame chose il y a un an pendant une semaine. \"\n    \"Il a \u00e9t\u00e9 diagnostiqu\u00e9 en mai 1995.\"\n)\n\ndoc = nlp(text)\n\ndates = doc.spans[\"dates\"]\ndates\n# Out: [23 ao\u00fbt 2021, il y a un an, mai 1995]\n\ndates[0]._.date.to_datetime()\n# Out: 2021-08-23T00:00:00+02:00\n\ndates[1]._.date.to_datetime()\n# Out: None\n\nnote_datetime = pendulum.datetime(2021, 8, 27, tz=\"Europe/Paris\")\n\ndates[1]._.date.to_datetime(note_datetime=note_datetime)\n# Out: 2020-08-27T00:00:00+02:00\n\ndate_2_output = dates[2]._.date.to_datetime(\n    note_datetime=note_datetime,\n    infer_from_context=True,\n    tz=\"Europe/Paris\",\n    default_day=15,\n)\ndate_2_output\n# Out: 1995-05-15T00:00:00+02:00\n\ndoc.spans[\"durations\"]\n# Out: [pendant une semaine]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/dates/factory/#edsnlp.pipelines.misc.dates.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.dates</code> pipeline declares two extensions on the <code>Span</code> object:</p> <ul> <li>the <code>span._.date</code> attribute of a date contains a parsed version of the date.</li> <li>the <code>span._.duration</code> attribute of a duration contains a parsed version of the   duration.</li> </ul> <p>As with other components, you can use the <code>span._.value</code> attribute to get either the parsed date or the duration depending on the span.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/factory/#edsnlp.pipelines.misc.dates.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the pipeline component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.dates</code> </p> <code>absolute</code> <p>List of regular expressions for absolute dates.</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>relative</code> <p>List of regular expressions for relative dates (eg <code>hier</code>, <code>la semaine prochaine</code>).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>duration</code> <p>List of regular expressions for durations (eg <code>pendant trois mois</code>).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>false_positive</code> <p>List of regular expressions for false positive (eg phone numbers, etc).</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Where to look for dates in the doc. By default, look in the whole doc. You can combine this with the <code>merge_mode</code> argument for interesting results.</p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>merge_mode</code> <p>How to merge matched dates with the spans from <code>span_getter</code>, if given:</p> <ul> <li><code>intersect</code>: return only the matches that fall in the <code>span_getter</code> spans</li> <li><code>align</code>: if a date overlaps a span from <code>span_getter</code> (e.g. a date extracted   by a machine learning model), return the <code>span_getter</code> span instead, and   assign all the parsed information (<code>._.date</code> / <code>._.duration</code>) to it. Otherwise   don't return the date.</li> </ul> <p> TYPE: <code>Literal['intersect', 'align']</code> DEFAULT: <code>intersect</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> and <code>merge_mode</code> instead. Whether to look on dates in the whole document or in specific sentences:</p> <ul> <li>If <code>True</code>: Only look in the sentences of each entity in doc.ents</li> <li>If False: Look in the whole document</li> <li>If given a string <code>key</code> or list of string: Only look in the sentences of   each entity in <code>doc.spans[key]</code></li> </ul> <p> TYPE: <code>Union[bool, str, Iterable[str]]</code> DEFAULT: <code>False</code> </p> <code>detect_periods</code> <p>Whether to detect periods (experimental)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>detect_time</code> <p>Whether to detect time inside dates</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>period_proximity_threshold</code> <p>Max number of words between two dates to extract a period.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>as_ents</code> <p>Deprecated, use span_setter instead. Whether to treat dates as entities</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>spaCy attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>LOWER</code> </p> <code>date_label</code> <p>Label to use for dates</p> <p> TYPE: <code>str</code> DEFAULT: <code>date</code> </p> <code>duration_label</code> <p>Label to use for durations</p> <p> TYPE: <code>str</code> DEFAULT: <code>duration</code> </p> <code>period_label</code> <p>Label to use for periods</p> <p> TYPE: <code>str</code> DEFAULT: <code>period</code> </p> <code>span_setter</code> <p>How to set matches in the doc.</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'dates': ['date'], 'durations': ['duration'], ...</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/dates/factory/#edsnlp.pipelines.misc.dates.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.dates</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/","title":"<code>edsnlp.pipelines.misc.dates.models</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.BaseDate","title":"<code>BaseDate</code>","text":"<p>           Bases: <code>BaseModel</code></p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.BaseDate.remove_space","title":"<code>remove_space</code>","text":"<p>Remove spaces. Useful for coping with ill-formatted PDF extractions.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.AbsoluteDate","title":"<code>AbsoluteDate</code>","text":"<p>           Bases: <code>BaseDate</code></p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.AbsoluteDate.to_datetime","title":"<code>to_datetime</code>","text":"<p>Convert the date to a pendulum.datetime object.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.AbsoluteDate.to_datetime--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>tz</code> <p>The timezone to use. Defaults to \"Europe/Paris\".</p> <p> TYPE: <code>Optional[Union[str, timezone]]</code> DEFAULT: <code>'Europe/Paris'</code> </p> <code>note_datetime</code> <p>The datetime of the note. Used to infer missing parts of the date.</p> <p> TYPE: <code>Optional[Union[datetime, datetime]]</code> DEFAULT: <code>None</code> </p> <code>infer_from_context</code> <p>Whether to infer missing parts of the date from the note datetime. In a (year, month, day) triplet:</p> <pre><code>- if only year is missing, it will be inferred from the note datetime\n- if only month is missing, it will be inferred from the note datetime\n- if only day is missing, it will be set to `default_day`\n- if only the year is given, the day and month will be set to\n  `default_day` and `default_month`\n- if only the month is given, the day will be set to `default_day`\n  and the year will be inferred from the note datetime\n- if only the day is given, the month and year will be inferred from\n  the note datetime\n</code></pre> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> <code>default_day</code> <p>Default day to use when inferring missing parts of the date.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>default_month</code> <p>Default month to use when inferring missing parts of the date.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Optional[datetime]</code>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.Relative","title":"<code>Relative</code>","text":"<p>           Bases: <code>BaseDate</code></p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.Relative.parse_unit","title":"<code>parse_unit</code>","text":"<p>Units need to be handled separately.</p> <p>This validator modifies the key corresponding to the unit with the detected value</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.Relative.parse_unit--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>d</code> <p>Original data</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>Transformed data</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.RelativeDate","title":"<code>RelativeDate</code>","text":"<p>           Bases: <code>Relative</code></p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.RelativeDate.handle_specifics","title":"<code>handle_specifics</code>","text":"<p>Specific patterns such as <code>aujourd'hui</code>, <code>hier</code>, etc, need to be handled separately.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/models/#edsnlp.pipelines.misc.dates.models.RelativeDate.handle_specifics--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>d</code> <p>Original data.</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>Modified data.</p>"},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/","title":"<code>edsnlp.pipelines.misc.dates.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/absolute/","title":"<code>edsnlp.pipelines.misc.dates.patterns.absolute</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/days/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.days</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/delimiters/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.delimiters</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/directions/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.directions</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/modes/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.modes</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/months/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.months</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/numbers/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.numbers</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/time/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.time</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/units/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.units</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/atomic/years/","title":"<code>edsnlp.pipelines.misc.dates.patterns.atomic.years</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/current/","title":"<code>edsnlp.pipelines.misc.dates.patterns.current</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/duration/","title":"<code>edsnlp.pipelines.misc.dates.patterns.duration</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/false_positive/","title":"<code>edsnlp.pipelines.misc.dates.patterns.false_positive</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/dates/patterns/relative/","title":"<code>edsnlp.pipelines.misc.dates.patterns.relative</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/measurements/","title":"<code>edsnlp.pipelines.misc.measurements</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/","title":"<code>edsnlp.pipelines.misc.measurements.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component","title":"<code>create_component = Language.factory('eds.measurements', assigns=['doc.spans', 'doc.ents'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.measurements</code> matcher detects and normalizes numerical measurements within a medical document.</p> <p>Warning</p> <p>The <code>measurements</code> pipeline is still in active development and has not been rigorously validated. If you come across a measurement expression that goes undetected, please file an issue !</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component--scope","title":"Scope","text":"<p>The <code>eds.measurements</code> matcher can extract simple (e.g. <code>3cm</code>) measurements. It can also detect elliptic enumerations (eg <code>32, 33 et 34kg</code>) of measurements of the same type and split the measurements accordingly.</p> <p>The normalized value can then be accessed via the <code>span._.{measure_name}</code> attribute, for instance <code>span._.size</code> or <code>span._.weight</code> and be converted on the fly to a desired unit. Like for other components, the <code>span._.value</code> extension can also be used to access the normalized value for any measurement span.</p> <p>The current matcher annotates the following measurements out of the box:</p> Measurement name Example <code>size</code> <code>1m50</code>, <code>1.50m</code> <code>weight</code> <code>12kg</code>, <code>1kg300</code> <code>bmi</code> <code>BMI: 24</code>, <code>24 kg.m-2</code> <code>volume</code> <code>2 cac</code>, <code>8ml</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.measurements\",\n    config=dict(\n        measurements=[\"size\", \"weight\", \"bmi\"],\n        extract_ranges=True,\n    ),\n)\n\ntext = \"\"\"\nLe patient est admis hier, fait 1m78 pour 76kg.\nLes deux nodules b\u00e9nins sont larges de 1,2 et 2.4mm.\nBMI: 24.\n\nLe nodule fait entre 1 et 1.5 cm\n\"\"\"\n\ndoc = nlp(text)\n\nmeasurements = doc.spans[\"measurements\"]\n\nmeasurements\n# Out: [1m78, 76kg, 1,2, 2.4mm, 24, entre 1 et 1.5 cm]\n\nmeasurements[0]\n# Out: 1m78\n\nstr(measurements[0]._.size), str(measurements[0]._.value)\n# Out: ('1.78 m', '1.78 m')\n\nmeasurements[0]._.value.cm\n# Out: 178.0\n\nmeasurements[2]\n# Out: 1,2\n\nstr(measurements[2]._.value)\n# Out: '1.2 mm'\n\nstr(measurements[2]._.value.mm)\n# Out: 1.2\n\nmeasurements[4]\n# Out: 24\n\nstr(measurements[4]._.value)\n# Out: '24 kg_per_m2'\n\nstr(measurements[4]._.value.kg_per_m2)\n# Out: 24\n\nstr(measurements[5]._.value)\n# Out: 1-1.5 cm\n</code></pre> <p>To extract all sizes in centimeters, and average range measurements, you can use the following snippet:</p> <pre><code>sizes = [\n    sum(item.cm for item in m._.value) / len(m._.value)\n    for m in doc.spans[\"measurements\"]\n    if m.label_ == \"size\"\n]\nsizes\n# Out: [178.0, 0.12, 0.24, 1.25]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component--customization","title":"Customization","text":"<p>You can declare custom measurements by altering the patterns:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.measurements\",\n    config=dict(\n        measurements={\n            \"my_custom_surface_measurement\": {\n                # This measurement unit is homogenous to square meters\n                \"unit\": \"m2\",\n                # Handle cases like \"surface: 1.8\" (implied m2),\n                # vs \"surface: 50\" (implied cm2)\n                \"unitless_patterns\": [\n                    {\n                        \"terms\": [\"surface\", \"aire\"],\n                        \"ranges\": [\n                            {\"unit\": \"m2\", \"min\": 0, \"max\": 9},\n                            {\"unit\": \"cm2\", \"min\": 10, \"max\": 100},\n                        ],\n                    }\n                ],\n            },\n        }\n    ),\n)\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.measurements</code> pipeline declares its extensions dynamically, depending on the <code>measurements</code> parameter: each measurement gets its own extension, and is assigned to a different span group.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.measurements</code> </p> <code>measurements</code> <p>A mapping from measure names to MsrConfig Each measure's configuration has the following shape: <pre><code>{\n  # the unit (e.g. \"kg\"),\n  \"unit\": str,\n  \"unitless_patterns\": {\n    # preceding trigger terms\n    \"terms\": List[str],\n    # unitless ranges -&gt; unit patterns\n    \"ranges\": List[\n      {\"min\": int, \"max\": int, \"unit\": str},\n      {\"min\": int, \"unit\": str},\n      ...,\n    ],\n    ...\n  }\n}\n</code></pre></p> <p> TYPE: <code>Union[str, List[Union[str, MsrConfig]], Dict[str, MsrConfig]]</code> DEFAULT: <code>['weight', 'size', 'bmi', 'volume']</code> </p> <code>number_terms</code> <p>A mapping of numbers to their lexical variants</p> <p> TYPE: <code>Dict[str, List[str]]</code> DEFAULT: <code>{'0.125': ['\u215b'], '0.16666666': ['\u2159'], '0.2': ['...</code> </p> <code>stopwords</code> <p>A list of stopwords that do not matter when placed between a unitless trigger and a number</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['par', 'sur', 'de', 'a', ',', 'et']</code> </p> <code>unit_divisors</code> <p>A list of terms used to divide two units (like: m / s)</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['/', 'par']</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>ignore_excluded</code> <p>Whether to exclude pollution patterns when matching in the text</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>compose_units</code> <p>Whether to compose units (like \"m/s\" or \"m.s-1\")</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extract_ranges</code> <p>Whether to extract ranges (like \"entre 1 et 2 cm\")</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>range_patterns</code> <p>A list of \"{FROM} xx {TO} yy\" patterns to match range measurements</p> <p> TYPE: <code>List[Tuple[Optional[str], Optional[str]]]</code> DEFAULT: <code>[('De', '\u00e0'), ('De', 'a'), ('de', '\u00e0'), ('de', ...</code> </p> <code>after_snippet_limit</code> <p>Maximum word distance after to link a part of a measurement after its number</p> <p> TYPE: <code>int</code> DEFAULT: <code>6</code> </p> <code>before_snippet_limit</code> <p>Maximum word distance after to link a part of a measurement before its number</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>span_setter</code> <p>How to set the spans in the document. By default, each measurement will be assigned to its own span group (using either the \"name\" field of the config, or the key if you passed a dict), and to the \"measurements\" group.</p> <p> TYPE: <code>Optional[SpanSetterArg]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Where to look for measurements in the doc. By default, look in the whole doc. You can combine this with the <code>merge_mode</code> argument for interesting results.</p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>merge_mode</code> <p>How to merge matches with the spans from <code>span_getter</code>, if given:</p> <ul> <li><code>intersect</code>: return only the matches that fall in the <code>span_getter</code> spans</li> <li><code>align</code>: if a match overlaps a span from <code>span_getter</code> (e.g. a match   extracted by a machine learning model), return the <code>span_getter</code> span   instead, and assign all the parsed information (<code>._.date</code> / <code>._.duration</code>)   to it. Otherwise, don't return the date.</li> </ul> <p> TYPE: <code>Literal['intersect', 'align']</code> DEFAULT: <code>intersect</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/factory/#edsnlp.pipelines.misc.measurements.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.measurements</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/","title":"<code>edsnlp.pipelines.misc.measurements.measurements</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.Measurement","title":"<code>Measurement</code>","text":"<p>           Bases: <code>ABC</code></p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.Measurement.__len__","title":"<code>__len__</code>  <code>abstractmethod</code>","text":"<p>Number of items in the measure (only one for SimpleMeasurement)</p> RETURNS DESCRIPTION <code>Iterable[SimpleMeasurement]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.Measurement.__iter__","title":"<code>__iter__</code>  <code>abstractmethod</code>","text":"<p>Iter over items of the measure (only one for SimpleMeasurement)</p> RETURNS DESCRIPTION <code>Iterable[SimpleMeasurement]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.Measurement.__getitem__","title":"<code>__getitem__</code>  <code>abstractmethod</code>","text":"<p>Access items of the measure (only one for SimpleMeasurement)</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.Measurement.__getitem__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>item</code> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>SimpleMeasurement</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.SimpleMeasurement","title":"<code>SimpleMeasurement</code>","text":"<p>           Bases: <code>Measurement</code></p> <p>The SimpleMeasurement class contains the value and unit for a single non-composite measure</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.SimpleMeasurement--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>value</code> <p> TYPE: <code>float</code> </p> <code>unit</code> <p> TYPE: <code>str</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher","title":"<code>MeasurementsMatcher</code>","text":"<p>           Bases: <code>BaseNERComponent</code></p> <p>The <code>eds.measurements</code> matcher detects and normalizes numerical measurements within a medical document.</p> <p>Warning</p> <p>The <code>measurements</code> pipeline is still in active development and has not been rigorously validated. If you come across a measurement expression that goes undetected, please file an issue !</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher--scope","title":"Scope","text":"<p>The <code>eds.measurements</code> matcher can extract simple (e.g. <code>3cm</code>) measurements. It can also detect elliptic enumerations (eg <code>32, 33 et 34kg</code>) of measurements of the same type and split the measurements accordingly.</p> <p>The normalized value can then be accessed via the <code>span._.{measure_name}</code> attribute, for instance <code>span._.size</code> or <code>span._.weight</code> and be converted on the fly to a desired unit. Like for other components, the <code>span._.value</code> extension can also be used to access the normalized value for any measurement span.</p> <p>The current matcher annotates the following measurements out of the box:</p> Measurement name Example <code>size</code> <code>1m50</code>, <code>1.50m</code> <code>weight</code> <code>12kg</code>, <code>1kg300</code> <code>bmi</code> <code>BMI: 24</code>, <code>24 kg.m-2</code> <code>volume</code> <code>2 cac</code>, <code>8ml</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.measurements\",\n    config=dict(\n        measurements=[\"size\", \"weight\", \"bmi\"],\n        extract_ranges=True,\n    ),\n)\n\ntext = \"\"\"\nLe patient est admis hier, fait 1m78 pour 76kg.\nLes deux nodules b\u00e9nins sont larges de 1,2 et 2.4mm.\nBMI: 24.\n\nLe nodule fait entre 1 et 1.5 cm\n\"\"\"\n\ndoc = nlp(text)\n\nmeasurements = doc.spans[\"measurements\"]\n\nmeasurements\n# Out: [1m78, 76kg, 1,2, 2.4mm, 24, entre 1 et 1.5 cm]\n\nmeasurements[0]\n# Out: 1m78\n\nstr(measurements[0]._.size), str(measurements[0]._.value)\n# Out: ('1.78 m', '1.78 m')\n\nmeasurements[0]._.value.cm\n# Out: 178.0\n\nmeasurements[2]\n# Out: 1,2\n\nstr(measurements[2]._.value)\n# Out: '1.2 mm'\n\nstr(measurements[2]._.value.mm)\n# Out: 1.2\n\nmeasurements[4]\n# Out: 24\n\nstr(measurements[4]._.value)\n# Out: '24 kg_per_m2'\n\nstr(measurements[4]._.value.kg_per_m2)\n# Out: 24\n\nstr(measurements[5]._.value)\n# Out: 1-1.5 cm\n</code></pre> <p>To extract all sizes in centimeters, and average range measurements, you can use the following snippet:</p> <pre><code>sizes = [\n    sum(item.cm for item in m._.value) / len(m._.value)\n    for m in doc.spans[\"measurements\"]\n    if m.label_ == \"size\"\n]\nsizes\n# Out: [178.0, 0.12, 0.24, 1.25]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher--customization","title":"Customization","text":"<p>You can declare custom measurements by altering the patterns:</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\n    \"eds.measurements\",\n    config=dict(\n        measurements={\n            \"my_custom_surface_measurement\": {\n                # This measurement unit is homogenous to square meters\n                \"unit\": \"m2\",\n                # Handle cases like \"surface: 1.8\" (implied m2),\n                # vs \"surface: 50\" (implied cm2)\n                \"unitless_patterns\": [\n                    {\n                        \"terms\": [\"surface\", \"aire\"],\n                        \"ranges\": [\n                            {\"unit\": \"m2\", \"min\": 0, \"max\": 9},\n                            {\"unit\": \"cm2\", \"min\": 10, \"max\": 100},\n                        ],\n                    }\n                ],\n            },\n        }\n    ),\n)\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.measurements</code> pipeline declares its extensions dynamically, depending on the <code>measurements</code> parameter: each measurement gets its own extension, and is assigned to a different span group.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.measurements</code> </p> <code>measurements</code> <p>A mapping from measure names to MsrConfig Each measure's configuration has the following shape: <pre><code>{\n  # the unit (e.g. \"kg\"),\n  \"unit\": str,\n  \"unitless_patterns\": {\n    # preceding trigger terms\n    \"terms\": List[str],\n    # unitless ranges -&gt; unit patterns\n    \"ranges\": List[\n      {\"min\": int, \"max\": int, \"unit\": str},\n      {\"min\": int, \"unit\": str},\n      ...,\n    ],\n    ...\n  }\n}\n</code></pre></p> <p> TYPE: <code>Union[str, List[Union[str, MsrConfig]], Dict[str, MsrConfig]]</code> DEFAULT: <code>['weight', 'size', 'bmi', 'volume']</code> </p> <code>number_terms</code> <p>A mapping of numbers to their lexical variants</p> <p> TYPE: <code>Dict[str, List[str]]</code> DEFAULT: <code>{'0.125': ['\u215b'], '0.16666666': ['\u2159'], '0.2': ['...</code> </p> <code>stopwords</code> <p>A list of stopwords that do not matter when placed between a unitless trigger and a number</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['par', 'sur', 'de', 'a', ',', 'et']</code> </p> <code>unit_divisors</code> <p>A list of terms used to divide two units (like: m / s)</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['/', 'par']</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>ignore_excluded</code> <p>Whether to exclude pollution patterns when matching in the text</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>compose_units</code> <p>Whether to compose units (like \"m/s\" or \"m.s-1\")</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extract_ranges</code> <p>Whether to extract ranges (like \"entre 1 et 2 cm\")</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>range_patterns</code> <p>A list of \"{FROM} xx {TO} yy\" patterns to match range measurements</p> <p> TYPE: <code>List[Tuple[Optional[str], Optional[str]]]</code> DEFAULT: <code>[('De', '\u00e0'), ('De', 'a'), ('de', '\u00e0'), ('de', ...</code> </p> <code>after_snippet_limit</code> <p>Maximum word distance after to link a part of a measurement after its number</p> <p> TYPE: <code>int</code> DEFAULT: <code>6</code> </p> <code>before_snippet_limit</code> <p>Maximum word distance after to link a part of a measurement before its number</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>span_setter</code> <p>How to set the spans in the document. By default, each measurement will be assigned to its own span group (using either the \"name\" field of the config, or the key if you passed a dict), and to the \"measurements\" group.</p> <p> TYPE: <code>Optional[SpanSetterArg]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Where to look for measurements in the doc. By default, look in the whole doc. You can combine this with the <code>merge_mode</code> argument for interesting results.</p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>merge_mode</code> <p>How to merge matches with the spans from <code>span_getter</code>, if given:</p> <ul> <li><code>intersect</code>: return only the matches that fall in the <code>span_getter</code> spans</li> <li><code>align</code>: if a match overlaps a span from <code>span_getter</code> (e.g. a match   extracted by a machine learning model), return the <code>span_getter</code> span   instead, and assign all the parsed information (<code>._.date</code> / <code>._.duration</code>)   to it. Otherwise, don't return the date.</li> </ul> <p> TYPE: <code>Literal['intersect', 'align']</code> DEFAULT: <code>intersect</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.measurements</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.set_extensions","title":"<code>set_extensions</code>","text":"<p>Set extensions for the measurements pipeline.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.extract_units","title":"<code>extract_units</code>","text":"<p>Extracts unit spans from the document by extracting unit atoms (declared in the units_config parameter) and aggregating them automatically Ex: \"il faut 2 g par jour\" =&gt; we extract [g]=unit(g), [par]=divisor(per), [jour]=unit(day) =&gt; we aggregate these adjacent matches together to compose a new unit g_per_day</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.extract_units--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>term_matches</code> <p> TYPE: <code>Iterable[Span]</code> </p> RETURNS DESCRIPTION <code>Iterable[Span]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.make_pseudo_sentence","title":"<code>make_pseudo_sentence</code>  <code>classmethod</code>","text":"<p>Creates a pseudo sentence (one letter per entity) to extract higher order patterns Ex: the sentence \"Il font {1}{,} {2} {et} {3} {cm} de long{.}\" is transformed into \"wn,n,nuw.\"</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.make_pseudo_sentence--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>The document or span to transform</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> <code>matches</code> <p>List of tuple of span and whether the span represents a sentence end</p> <p> TYPE: <code>List[Tuple[Span, bool]]</code> </p> <code>pseudo_mapping</code> <p>A mapping from label to char in the pseudo sentence</p> <p> TYPE: <code>Dict[int, str]</code> </p> RETURNS DESCRIPTION <code>(str, List[int])</code> <ul> <li>the pseudo sentence</li> <li>a list of offsets to convert match indices into pseudo sent char indices</li> </ul>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.get_matches","title":"<code>get_matches</code>","text":"<p>Extract and filter regex and phrase matches in the document to prepare the measurement extraction. Returns the matches and a list of hashes to quickly find unit matches</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.get_matches--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> RETURNS DESCRIPTION <code>Tuple[List[Span, bool], Set[int]]</code> <ul> <li>List of tuples of spans and whether the spans represents a sentence end</li> <li>List of hash label to distinguish unit from other matches</li> </ul>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.extract_measurements","title":"<code>extract_measurements</code>","text":"<p>Extracts measure entities from the document</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.extract_measurements--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>List[Span]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.merge_adjacent_measurements","title":"<code>merge_adjacent_measurements</code>  <code>classmethod</code>","text":"<p>Aggregates extracted measurements together when they are adjacent to handle cases like - 1 meter 50 cm - 30\u00b0 4' 54\"</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.merge_adjacent_measurements--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>measurements</code> <p> TYPE: <code>List[Span]</code> </p> RETURNS DESCRIPTION <code>List[Span]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.merge_measurements_in_ranges","title":"<code>merge_measurements_in_ranges</code>","text":"<p>Aggregates extracted measurements together when they are adjacent to handle cases like - 1 meter 50 cm - 30\u00b0 4' 54\"</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.merge_measurements_in_ranges--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>measurements</code> <p> TYPE: <code>List[Span]</code> </p> RETURNS DESCRIPTION <code>List[Span]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.merge_with_existing","title":"<code>merge_with_existing</code>","text":"<p>Merges the extracted measurements with the existing measurements in the document.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.merge_with_existing--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>extracted</code> <p>The extracted measurements</p> <p> TYPE: <code>List[Span]</code> </p> <code>existing</code> <p>The existing measurements in the document</p> <p> TYPE: <code>List[Span]</code> </p> RETURNS DESCRIPTION <code>List[Span]</code>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.__call__","title":"<code>__call__</code>","text":"<p>Adds measurements to document's \"measurements\" SpanGroup.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/measurements/#edsnlp.pipelines.misc.measurements.measurements.MeasurementsMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for extracted measurements.</p>"},{"location":"reference/edsnlp/pipelines/misc/measurements/patterns/","title":"<code>edsnlp.pipelines.misc.measurements.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/reason/","title":"<code>edsnlp.pipelines.misc.reason</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/reason/factory/","title":"<code>edsnlp.pipelines.misc.reason.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/reason/factory/#edsnlp.pipelines.misc.reason.factory.create_component","title":"<code>create_component = Language.factory('eds.reason', assigns=['doc.spans', 'doc.ents'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.reason</code> matcher uses a rule-based algorithm to detect spans that relate to the reason of the hospitalisation. It was designed at AP-HP's EDS.</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/factory/#edsnlp.pipelines.misc.reason.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and looks for spans of hospitalisation reasons. It is complete and can be run as is.</p> <pre><code>import spacy\n\ntext = \"\"\"COMPTE RENDU D'HOSPITALISATION du 11/07/2018 au 12/07/2018\nMOTIF D'HOSPITALISATION\nMonsieur Dupont Jean Michel, de sexe masculin, \u00e2g\u00e9e de 39 ans, n\u00e9e le 23/11/1978,\na \u00e9t\u00e9 hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nANT\u00c9C\u00c9DENTS\nAnt\u00e9c\u00e9dents m\u00e9dicaux :\nPremier \u00e9pisode d'asthme en mai 2018.\"\"\"\n\nnlp = spacy.blank(\"eds\")\n\n# Extraction of entities\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=dict(\n            respiratoire=[\n                \"asthmatique\",\n                \"asthme\",\n                \"toux\",\n            ]\n        )\n    ),\n)\n\n\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.reason\", config=dict(use_sections=True))\ndoc = nlp(text)\n\nreason = doc.spans[\"reasons\"][0]\nreason\n# Out: hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nreason._.is_reason\n# Out: True\n\nentities = reason._.ents_reason\nentities\n# Out: [asthme]\n\nentities[0].label_\n# Out: 'respiratoire'\n\nent = entities[0]\nent._.is_reason\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/reason/factory/#edsnlp.pipelines.misc.reason.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.reason</code> pipeline adds the key <code>reasons</code> to <code>doc.spans</code> and declares one extension, on the <code>Span</code> objects called <code>ents_reason</code>.</p> <p>The <code>ents_reason</code> extension is a list of named entities that overlap the <code>Span</code>, typically entities found in upstream components like <code>matcher</code>.</p> <p>It also declares the boolean extension <code>is_reason</code>. This extension is set to True for the Reason Spans but also for the entities that overlap the reason span.</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/factory/#edsnlp.pipelines.misc.reason.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.reason</code> </p> <code>reasons</code> <p>Reason patterns</p> <p> TYPE: <code>Dict[str, Union[List[str], str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>Default token attribute to use to build the text to match on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>use_sections</code> <p>Whether or not use the <code>sections</code> matcher to improve results.</p> <p> TYPE: <code>(bool)</code> DEFAULT: <code>False</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/reason/factory/#edsnlp.pipelines.misc.reason.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.reason</code> matcher was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/patterns/","title":"<code>edsnlp.pipelines.misc.reason.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/reason/reason/","title":"<code>edsnlp.pipelines.misc.reason.reason</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher","title":"<code>ReasonMatcher</code>","text":"<p>           Bases: <code>GenericMatcher</code></p> <p>The <code>eds.reason</code> matcher uses a rule-based algorithm to detect spans that relate to the reason of the hospitalisation. It was designed at AP-HP's EDS.</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and looks for spans of hospitalisation reasons. It is complete and can be run as is.</p> <pre><code>import spacy\n\ntext = \"\"\"COMPTE RENDU D'HOSPITALISATION du 11/07/2018 au 12/07/2018\nMOTIF D'HOSPITALISATION\nMonsieur Dupont Jean Michel, de sexe masculin, \u00e2g\u00e9e de 39 ans, n\u00e9e le 23/11/1978,\na \u00e9t\u00e9 hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nANT\u00c9C\u00c9DENTS\nAnt\u00e9c\u00e9dents m\u00e9dicaux :\nPremier \u00e9pisode d'asthme en mai 2018.\"\"\"\n\nnlp = spacy.blank(\"eds\")\n\n# Extraction of entities\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(\n        terms=dict(\n            respiratoire=[\n                \"asthmatique\",\n                \"asthme\",\n                \"toux\",\n            ]\n        )\n    ),\n)\n\n\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.reason\", config=dict(use_sections=True))\ndoc = nlp(text)\n\nreason = doc.spans[\"reasons\"][0]\nreason\n# Out: hospitalis\u00e9 du 11/08/2019 au 17/08/2019 pour attaque d'asthme.\n\nreason._.is_reason\n# Out: True\n\nentities = reason._.ents_reason\nentities\n# Out: [asthme]\n\nentities[0].label_\n# Out: 'respiratoire'\n\nent = entities[0]\nent._.is_reason\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.reason</code> pipeline adds the key <code>reasons</code> to <code>doc.spans</code> and declares one extension, on the <code>Span</code> objects called <code>ents_reason</code>.</p> <p>The <code>ents_reason</code> extension is a list of named entities that overlap the <code>Span</code>, typically entities found in upstream components like <code>matcher</code>.</p> <p>It also declares the boolean extension <code>is_reason</code>. This extension is set to True for the Reason Spans but also for the entities that overlap the reason span.</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.reason</code> </p> <code>reasons</code> <p>Reason patterns</p> <p> TYPE: <code>Dict[str, Union[List[str], str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>Default token attribute to use to build the text to match on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>use_sections</code> <p>Whether or not use the <code>sections</code> matcher to improve results.</p> <p> TYPE: <code>(bool)</code> DEFAULT: <code>False</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.reason</code> matcher was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher.__call__","title":"<code>__call__</code>","text":"<p>Find spans related to the reasons of the hospitalisation</p>"},{"location":"reference/edsnlp/pipelines/misc/reason/reason/#edsnlp.pipelines.misc.reason.reason.ReasonMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>Doc</code>"},{"location":"reference/edsnlp/pipelines/misc/sections/","title":"<code>edsnlp.pipelines.misc.sections</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/sections/factory/","title":"<code>edsnlp.pipelines.misc.sections.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/sections/factory/#edsnlp.pipelines.misc.sections.factory.create_component","title":"<code>create_component = Language.factory('eds.sections', assigns=['doc.spans', 'doc.ents'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.sections</code> component extracts section titles from clinical documents. A \"section\" is then defined as the span of text between two titles.</p> <p>Here is the list of sections that are currently targeted :</p> <ul> <li><code>allergies</code></li> <li><code>ant\u00e9c\u00e9dents</code></li> <li><code>ant\u00e9c\u00e9dents familiaux</code></li> <li><code>traitements entr\u00e9e</code></li> <li><code>conclusion</code></li> <li><code>conclusion entr\u00e9e</code></li> <li><code>habitus</code></li> <li><code>correspondants</code></li> <li><code>diagnostic</code></li> <li><code>donn\u00e9es biom\u00e9triques entr\u00e9e</code></li> <li><code>examens</code></li> <li><code>examens compl\u00e9mentaires</code></li> <li><code>facteurs de risques</code></li> <li><code>histoire de la maladie</code></li> <li><code>actes</code></li> <li><code>motif</code></li> <li><code>prescriptions</code></li> <li><code>traitements sortie</code></li> <li><code>evolution</code></li> <li><code>modalites sortie</code></li> <li><code>vaccinations</code></li> <li><code>introduction</code></li> </ul> <p>Remarks :</p> <ul> <li>section <code>introduction</code> corresponds to the span of text between the header   \"COMPTE RENDU D'HOSPITALISATION\" (usually denoting the beginning of the document)   and the title of the following detected section</li> <li>this matcher works well for hospitalization summaries (CRH), but not necessarily   for all types of documents (in particular for emergency or scan summaries   CR-IMAGERIE)</li> </ul> <p>Experimental</p> <p>Should you rely on <code>eds.sections</code> for critical downstream tasks, make sure to validate the results to make sure that the component works in your case.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/factory/#edsnlp.pipelines.misc.sections.factory.create_component--examples","title":"Examples","text":"<p>The following snippet detects section titles. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\n\ntext = \"\"\"\nCRU du 10/09/2021\nMotif :\nPatient admis pour suspicion de COVID\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans[\"section_titles\"]\n# Out: [Motif]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/sections/factory/#edsnlp.pipelines.misc.sections.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.sections</code> matcher adds two fields to the <code>doc.spans</code> attribute :</p> <ol> <li>The <code>section_titles</code> key contains the list of all section titles extracted using    the list declared in the <code>terms.py</code> module.</li> <li>The <code>sections</code> key contains a list of sections, ie spans of text between two    section titles (or the last title and the end of the document).</li> </ol> <p>If the document has entities before calling this matcher an attribute <code>section</code> is added to each entity.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/factory/#edsnlp.pipelines.misc.sections.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>sections</code> <p>Dictionary of terms to look for.</p> <p> TYPE: <code>Dict[str, List[str]]</code> DEFAULT: <code>{'allergies': ['allergies'], 'ant\u00e9c\u00e9dents': ['a...</code> </p> <code>attr</code> <p>Default attribute to match on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>add_patterns</code> <p>Whether add update patterns to match start / end of lines</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/sections/factory/#edsnlp.pipelines.misc.sections.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.sections</code> matcher was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/patterns/","title":"<code>edsnlp.pipelines.misc.sections.patterns</code>","text":"<p>These section titles were extracted from a work performed by Ivan Lerner at AP-HP. It supplied a number of documents annotated for section titles.</p> <p>The section titles were reviewed by Gilles Chatellier, who gave meaningful insights.</p> <p>See sections/section-dataset notebook for detail.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/","title":"<code>edsnlp.pipelines.misc.sections.sections</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher","title":"<code>SectionsMatcher</code>","text":"<p>           Bases: <code>GenericMatcher</code></p> <p>The <code>eds.sections</code> component extracts section titles from clinical documents. A \"section\" is then defined as the span of text between two titles.</p> <p>Here is the list of sections that are currently targeted :</p> <ul> <li><code>allergies</code></li> <li><code>ant\u00e9c\u00e9dents</code></li> <li><code>ant\u00e9c\u00e9dents familiaux</code></li> <li><code>traitements entr\u00e9e</code></li> <li><code>conclusion</code></li> <li><code>conclusion entr\u00e9e</code></li> <li><code>habitus</code></li> <li><code>correspondants</code></li> <li><code>diagnostic</code></li> <li><code>donn\u00e9es biom\u00e9triques entr\u00e9e</code></li> <li><code>examens</code></li> <li><code>examens compl\u00e9mentaires</code></li> <li><code>facteurs de risques</code></li> <li><code>histoire de la maladie</code></li> <li><code>actes</code></li> <li><code>motif</code></li> <li><code>prescriptions</code></li> <li><code>traitements sortie</code></li> <li><code>evolution</code></li> <li><code>modalites sortie</code></li> <li><code>vaccinations</code></li> <li><code>introduction</code></li> </ul> <p>Remarks :</p> <ul> <li>section <code>introduction</code> corresponds to the span of text between the header   \"COMPTE RENDU D'HOSPITALISATION\" (usually denoting the beginning of the document)   and the title of the following detected section</li> <li>this matcher works well for hospitalization summaries (CRH), but not necessarily   for all types of documents (in particular for emergency or scan summaries   CR-IMAGERIE)</li> </ul> <p>Experimental</p> <p>Should you rely on <code>eds.sections</code> for critical downstream tasks, make sure to validate the results to make sure that the component works in your case.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher--examples","title":"Examples","text":"<p>The following snippet detects section titles. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\n\ntext = \"\"\"\nCRU du 10/09/2021\nMotif :\nPatient admis pour suspicion de COVID\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.spans[\"section_titles\"]\n# Out: [Motif]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.sections</code> matcher adds two fields to the <code>doc.spans</code> attribute :</p> <ol> <li>The <code>section_titles</code> key contains the list of all section titles extracted using    the list declared in the <code>terms.py</code> module.</li> <li>The <code>sections</code> key contains a list of sections, ie spans of text between two    section titles (or the last title and the end of the document).</li> </ol> <p>If the document has entities before calling this matcher an attribute <code>section</code> is added to each entity.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>sections</code> <p>Dictionary of terms to look for.</p> <p> TYPE: <code>Dict[str, List[str]]</code> DEFAULT: <code>{'allergies': ['allergies'], 'ant\u00e9c\u00e9dents': ['a...</code> </p> <code>attr</code> <p>Default attribute to match on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>add_patterns</code> <p>Whether add update patterns to match start / end of lines</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.sections</code> matcher was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher.__call__","title":"<code>__call__</code>","text":"<p>Divides the doc into sections</p>"},{"location":"reference/edsnlp/pipelines/misc/sections/sections/#edsnlp.pipelines.misc.sections.sections.SectionsMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for sections</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/tables/","title":"<code>edsnlp.pipelines.misc.tables</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/tables/factory/","title":"<code>edsnlp.pipelines.misc.tables.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/tables/factory/#edsnlp.pipelines.misc.tables.factory.create_component","title":"<code>create_component = Language.factory('eds.tables', assigns=['doc.spans', 'doc.ents'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.tables</code> matcher detects tables in a documents.</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/factory/#edsnlp.pipelines.misc.tables.factory.create_component--examples","title":"Examples","text":"<p><pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.tables\")\n\ntext = \"\"\"\nSERVICE\nMEDECINE INTENSIVE \u2013\nREANIMATION\nR\u00e9animation / Surveillance Continue\nM\u00e9dicale\n\nCOMPTE RENDU D'HOSPITALISATION du 05/06/2020 au 10/06/2020\nMadame DUPONT Marie, n\u00e9e le 16/05/1900, \u00e2g\u00e9e de 20 ans, a \u00e9t\u00e9 hospitalis\u00e9e en\nr\u00e9animation du 05/06/1920 au 10/06/1920 pour intoxication m\u00e9dicamenteuse volontaire.\n\nExamens compl\u00e9mentaires\nH\u00e9matologie\nNum\u00e9ration\nLeucocytes \u00a6x10*9/L \u00a64.97 \u00a64.09-11\nH\u00e9maties \u00a6x10*12/L\u00a64.68 \u00a64.53-5.79\nH\u00e9moglobine \u00a6g/dL \u00a614.8 \u00a613.4-16.7\nH\u00e9matocrite \u00a6% \u00a644.2 \u00a639.2-48.6\nVGM \u00a6fL \u00a694.4 + \u00a679.6-94\nTCMH \u00a6pg \u00a631.6 \u00a627.3-32.8\nCCMH \u00a6g/dL \u00a633.5 \u00a632.4-36.3\nPlaquettes \u00a6x10*9/L \u00a6191 \u00a6172-398\nVMP \u00a6fL \u00a611.5 + \u00a67.4-10.8\n\nSur le plan neurologique : Devant la persistance d'une confusion \u00e0 distance de\nl'intoxication au\n...\n\n2/2Pat : &lt;NOM&gt; &lt;Prenom&gt;|F |&lt;date&gt; | &lt;ipp&gt; |Intitul\u00e9 RCP\n\"\"\"\n\ndoc = nlp(text)\n\n# A table span\ntable = doc.spans[\"tables\"][0]\n\n# Leucocytes \u00a6x10*9/L \u00a64.97 \u00a64.09-11\n# H\u00e9maties \u00a6x10*12/L\u00a64.68 \u00a64.53-5.79\n# H\u00e9moglobine \u00a6g/dL \u00a614.8 \u00a613.4-16.7\n# H\u00e9matocrite \u00a6% \u00a644.2 \u00a639.2-48.6\n# VGM \u00a6fL \u00a694.4 + \u00a679.6-94\n# TCMH \u00a6pg \u00a631.6 \u00a627.3-32.8\n# CCMH \u00a6g/dL \u00a633.5 \u00a632.4-36.3\n# Plaquettes \u00a6x10*9/L \u00a6191 \u00a6172-398\n# VMP \u00a6fL \u00a611.5 + \u00a67.4-10.8\n\n# Convert span to Pandas table\ndf = table._.to_pd_table()\ntype(df)\n# Out: pandas.core.frame.DataFrame\n</code></pre> The pandas DataFrame:</p> 0 1 2 3 0 Leucocytes x10*9/L 4.97 4.09-11 1 H\u00e9maties x10*12/L 4.68 4.53-5.79 2 H\u00e9moglobine g/dL 14.8 13.4-16.7 3 H\u00e9matocrite % 44.2 39.2-48.6 4 VGM fL 94.4 + 79.6-94 5 TCMH pg 31.6 27.3-32.8 6 CCMH g/dL 33.5 32.4-36.3 7 Plaquettes x10*9/L 191 172-398 8 VMP fL 11.5 + 7.4-10.8"},{"location":"reference/edsnlp/pipelines/misc/tables/factory/#edsnlp.pipelines.misc.tables.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.tables</code> pipeline declares the <code>span._.to_pd_table()</code> Span extension. This function returns a parsed pandas version of the table.</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/factory/#edsnlp.pipelines.misc.tables.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.tables</code> </p> <code>tables_pattern</code> <p>The regex pattern to identify tables. The key of dictionary should be <code>tables</code></p> <p> TYPE: <code>Optional[Dict[str, str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr'. We can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/tables/factory/#edsnlp.pipelines.misc.tables.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.tables</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/patterns/","title":"<code>edsnlp.pipelines.misc.tables.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/tables/tables/","title":"<code>edsnlp.pipelines.misc.tables.tables</code>","text":""},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher","title":"<code>TablesMatcher</code>","text":"<p>           Bases: <code>GenericMatcher</code></p> <p>The <code>eds.tables</code> matcher detects tables in a documents.</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher--examples","title":"Examples","text":"<p><pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.tables\")\n\ntext = \"\"\"\nSERVICE\nMEDECINE INTENSIVE \u2013\nREANIMATION\nR\u00e9animation / Surveillance Continue\nM\u00e9dicale\n\nCOMPTE RENDU D'HOSPITALISATION du 05/06/2020 au 10/06/2020\nMadame DUPONT Marie, n\u00e9e le 16/05/1900, \u00e2g\u00e9e de 20 ans, a \u00e9t\u00e9 hospitalis\u00e9e en\nr\u00e9animation du 05/06/1920 au 10/06/1920 pour intoxication m\u00e9dicamenteuse volontaire.\n\nExamens compl\u00e9mentaires\nH\u00e9matologie\nNum\u00e9ration\nLeucocytes \u00a6x10*9/L \u00a64.97 \u00a64.09-11\nH\u00e9maties \u00a6x10*12/L\u00a64.68 \u00a64.53-5.79\nH\u00e9moglobine \u00a6g/dL \u00a614.8 \u00a613.4-16.7\nH\u00e9matocrite \u00a6% \u00a644.2 \u00a639.2-48.6\nVGM \u00a6fL \u00a694.4 + \u00a679.6-94\nTCMH \u00a6pg \u00a631.6 \u00a627.3-32.8\nCCMH \u00a6g/dL \u00a633.5 \u00a632.4-36.3\nPlaquettes \u00a6x10*9/L \u00a6191 \u00a6172-398\nVMP \u00a6fL \u00a611.5 + \u00a67.4-10.8\n\nSur le plan neurologique : Devant la persistance d'une confusion \u00e0 distance de\nl'intoxication au\n...\n\n2/2Pat : &lt;NOM&gt; &lt;Prenom&gt;|F |&lt;date&gt; | &lt;ipp&gt; |Intitul\u00e9 RCP\n\"\"\"\n\ndoc = nlp(text)\n\n# A table span\ntable = doc.spans[\"tables\"][0]\n\n# Leucocytes \u00a6x10*9/L \u00a64.97 \u00a64.09-11\n# H\u00e9maties \u00a6x10*12/L\u00a64.68 \u00a64.53-5.79\n# H\u00e9moglobine \u00a6g/dL \u00a614.8 \u00a613.4-16.7\n# H\u00e9matocrite \u00a6% \u00a644.2 \u00a639.2-48.6\n# VGM \u00a6fL \u00a694.4 + \u00a679.6-94\n# TCMH \u00a6pg \u00a631.6 \u00a627.3-32.8\n# CCMH \u00a6g/dL \u00a633.5 \u00a632.4-36.3\n# Plaquettes \u00a6x10*9/L \u00a6191 \u00a6172-398\n# VMP \u00a6fL \u00a611.5 + \u00a67.4-10.8\n\n# Convert span to Pandas table\ndf = table._.to_pd_table()\ntype(df)\n# Out: pandas.core.frame.DataFrame\n</code></pre> The pandas DataFrame:</p> 0 1 2 3 0 Leucocytes x10*9/L 4.97 4.09-11 1 H\u00e9maties x10*12/L 4.68 4.53-5.79 2 H\u00e9moglobine g/dL 14.8 13.4-16.7 3 H\u00e9matocrite % 44.2 39.2-48.6 4 VGM fL 94.4 + 79.6-94 5 TCMH pg 31.6 27.3-32.8 6 CCMH g/dL 33.5 32.4-36.3 7 Plaquettes x10*9/L 191 172-398 8 VMP fL 11.5 + 7.4-10.8"},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher--extensions","title":"Extensions","text":"<p>The <code>eds.tables</code> pipeline declares the <code>span._.to_pd_table()</code> Span extension. This function returns a parsed pandas version of the table.</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component.</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.tables</code> </p> <code>tables_pattern</code> <p>The regex pattern to identify tables. The key of dictionary should be <code>tables</code></p> <p> TYPE: <code>Optional[Dict[str, str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr'. We can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.tables</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher.__call__","title":"<code>__call__</code>","text":"<p>Find spans that contain tables</p>"},{"location":"reference/edsnlp/pipelines/misc/tables/tables/#edsnlp.pipelines.misc.tables.tables.TablesMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>Doc</code>"},{"location":"reference/edsnlp/pipelines/ner/","title":"<code>edsnlp.pipelines.ner</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/adicap/","title":"<code>edsnlp.pipelines.ner.adicap</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/","title":"<code>edsnlp.pipelines.ner.adicap.adicap</code>","text":"<p><code>eds.adicap</code> pipeline</p> <ol><li><p><p>sant\u00e9 A., 2019. Th\u00e9saurus de la codification ADICAP - Index raisonn\u00e9 des l\u00e9sions.</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/#edsnlp.pipelines.ner.adicap.adicap.AdicapMatcher","title":"<code>AdicapMatcher</code>","text":"<p>           Bases: <code>ContextualMatcher</code></p> <p>The <code>eds.adicap</code> pipeline component matches the ADICAP codes. It was developped to run on anapathology reports.</p> <p>Document type</p> <p>It was developped to work on anapathology reports. We recommend also to use the <code>eds</code> language (<code>spacy.blank(\"eds\")</code>)</p> <p>The compulsory characters of the ADICAP code are identified and decoded. These characters represent the following attributes:</p> Field [en] Field [fr] Attribute Sampling mode Mode de prelevement sampling_mode Technic Type de technique technic Organ and regions Appareils, organes et r\u00e9gions organ Pathology Pathologie g\u00e9n\u00e9rale pathology Pathology type Type de la pathologie pathology_type Behaviour type Type de comportement behaviour_type <p>The pathology field takes 4 different values corresponding to the 4 possible interpretations of the ADICAP code, which are : \"PATHOLOGIE G\u00c9N\u00c9RALE NON TUMORALE\", \"PATHOLOGIE TUMORALE\", \"PATHOLOGIE PARTICULIERE DES ORGANES\" and \"CYTOPATHOLOGIE\".</p> <p>Depending on the pathology value the behaviour type meaning changes, when the pathology is tumoral then it describes the malignancy of the tumor.</p> <p>For further details about the ADICAP code follow this link.</p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/#edsnlp.pipelines.ner.adicap.adicap.AdicapMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.adicap\")\n\ntext = \"\"\"\nCOMPTE RENDU D\u2019EXAMEN\n\nAnt\u00e9riorit\u00e9(s) :  NEANT\n\n\nRenseignements cliniques :\nContexte d'exploration d'un carcinome canalaire infiltrant du quadrant sup\u00e9ro-\nexterne du sein droit. La l\u00e9sion biopsi\u00e9e ce jour est situ\u00e9e \u00e0 5,5 cm de la l\u00e9sion\ndu quadrant sup\u00e9ro-externe, \u00e0 l'union des quadrants inf\u00e9rieurs.\n\n\nMacrobiopsie 10G sur une zone de prise de contraste focale \u00e0 l'union des quadrants\ninf\u00e9rieurs du sein droit, mesurant 4 mm, class\u00e9e ACR4\n\n14 fragments ont \u00e9t\u00e9 communiqu\u00e9s fix\u00e9s en formol (lame n\u00b0 1a et lame n\u00b0 1b) . Il\nn'y a pas eu d'\u00e9chantillon congel\u00e9. Ces fragments ont \u00e9t\u00e9 inclus en paraffine en\ntotalit\u00e9 et coup\u00e9s sur plusieurs niveaux.\nHistologiquement, il s'agit d'un parenchyme mammaire fibroadipeux parfois\nl\u00e9g\u00e8rement dystrophique avec quelques petits kystes. Il n'y a pas d'hyperplasie\n\u00e9pith\u00e9liale, pas d'atypie, pas de prolif\u00e9ration tumorale. On note quelques\nsuffusions h\u00e9morragiques focales.\n\nConclusion :\nL\u00e9gers remaniements dystrophiques \u00e0 l'union des quadrants inf\u00e9rieurs du sein droit.\nAbsence d'atypies ou de prolif\u00e9ration tumorale.\n\nCodification :   BHGS0040\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (BHGS0040,)\n\nent = doc.ents[0]\n\nent.label_\n# Out: adicap\n\nent._.adicap.dict()\n# Out: {'code': 'BHGS0040',\n# 'sampling_mode': 'BIOPSIE CHIRURGICALE',\n# 'technic': 'HISTOLOGIE ET CYTOLOGIE PAR INCLUSION',\n# 'organ': \"SEIN (\u00c9GALEMENT UTILIS\u00c9 CHEZ L'HOMME)\",\n# 'pathology': 'PATHOLOGIE G\u00c9N\u00c9RALE NON TUMORALE',\n# 'pathology_type': 'ETAT SUBNORMAL - LESION MINEURE',\n# 'behaviour_type': 'CARACTERES GENERAUX'}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/#edsnlp.pipelines.ner.adicap.adicap.AdicapMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.adicap</code> </p> <code>pattern</code> <p>The regex pattern to use for matching ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>([A-Z]\\.?[A-Z]\\.?[A-Z]{2}\\.?(?:\\d{4}|\\d{4}|[A-Z...</code> </p> <code>prefix</code> <p>The regex pattern to use for matching the prefix before ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>(?i)(codification|adicap)</code> </p> <code>window</code> <p>Number of tokens to look for prefix. It will never go further the start of the sentence</p> <p> TYPE: <code>int</code> DEFAULT: <code>500</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>adicap</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'adicap': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/#edsnlp.pipelines.ner.adicap.adicap.AdicapMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.adicap</code> pipeline was developed by AP-HP's Data Science team. The codes were downloaded from the website of 'Agence du num\u00e9rique en sant\u00e9' (\"Th\u00e9saurus de la codification ADICAP - Index raisonn\u00e9 des l\u00e9sions\", sant\u00e9, 2019)</p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/#edsnlp.pipelines.ner.adicap.adicap.AdicapMatcher.process","title":"<code>process</code>","text":"<p>Tags ADICAP mentions.</p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/adicap/#edsnlp.pipelines.ner.adicap.adicap.AdicapMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for ADICAP</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/factory/","title":"<code>edsnlp.pipelines.ner.adicap.factory</code>","text":"<ol><li><p><p>sant\u00e9 A., 2019. Th\u00e9saurus de la codification ADICAP - Index raisonn\u00e9 des l\u00e9sions.</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/ner/adicap/factory/#edsnlp.pipelines.ner.adicap.factory.create_component","title":"<code>create_component = Language.factory('eds.adicap', assigns=['doc.ents', 'doc.spans'])(AdicapMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.adicap</code> pipeline component matches the ADICAP codes. It was developped to run on anapathology reports.</p> <p>Document type</p> <p>It was developped to work on anapathology reports. We recommend also to use the <code>eds</code> language (<code>spacy.blank(\"eds\")</code>)</p> <p>The compulsory characters of the ADICAP code are identified and decoded. These characters represent the following attributes:</p> Field [en] Field [fr] Attribute Sampling mode Mode de prelevement sampling_mode Technic Type de technique technic Organ and regions Appareils, organes et r\u00e9gions organ Pathology Pathologie g\u00e9n\u00e9rale pathology Pathology type Type de la pathologie pathology_type Behaviour type Type de comportement behaviour_type <p>The pathology field takes 4 different values corresponding to the 4 possible interpretations of the ADICAP code, which are : \"PATHOLOGIE G\u00c9N\u00c9RALE NON TUMORALE\", \"PATHOLOGIE TUMORALE\", \"PATHOLOGIE PARTICULIERE DES ORGANES\" and \"CYTOPATHOLOGIE\".</p> <p>Depending on the pathology value the behaviour type meaning changes, when the pathology is tumoral then it describes the malignancy of the tumor.</p> <p>For further details about the ADICAP code follow this link.</p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/factory/#edsnlp.pipelines.ner.adicap.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.adicap\")\n\ntext = \"\"\"\nCOMPTE RENDU D\u2019EXAMEN\n\nAnt\u00e9riorit\u00e9(s) :  NEANT\n\n\nRenseignements cliniques :\nContexte d'exploration d'un carcinome canalaire infiltrant du quadrant sup\u00e9ro-\nexterne du sein droit. La l\u00e9sion biopsi\u00e9e ce jour est situ\u00e9e \u00e0 5,5 cm de la l\u00e9sion\ndu quadrant sup\u00e9ro-externe, \u00e0 l'union des quadrants inf\u00e9rieurs.\n\n\nMacrobiopsie 10G sur une zone de prise de contraste focale \u00e0 l'union des quadrants\ninf\u00e9rieurs du sein droit, mesurant 4 mm, class\u00e9e ACR4\n\n14 fragments ont \u00e9t\u00e9 communiqu\u00e9s fix\u00e9s en formol (lame n\u00b0 1a et lame n\u00b0 1b) . Il\nn'y a pas eu d'\u00e9chantillon congel\u00e9. Ces fragments ont \u00e9t\u00e9 inclus en paraffine en\ntotalit\u00e9 et coup\u00e9s sur plusieurs niveaux.\nHistologiquement, il s'agit d'un parenchyme mammaire fibroadipeux parfois\nl\u00e9g\u00e8rement dystrophique avec quelques petits kystes. Il n'y a pas d'hyperplasie\n\u00e9pith\u00e9liale, pas d'atypie, pas de prolif\u00e9ration tumorale. On note quelques\nsuffusions h\u00e9morragiques focales.\n\nConclusion :\nL\u00e9gers remaniements dystrophiques \u00e0 l'union des quadrants inf\u00e9rieurs du sein droit.\nAbsence d'atypies ou de prolif\u00e9ration tumorale.\n\nCodification :   BHGS0040\n\"\"\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (BHGS0040,)\n\nent = doc.ents[0]\n\nent.label_\n# Out: adicap\n\nent._.adicap.dict()\n# Out: {'code': 'BHGS0040',\n# 'sampling_mode': 'BIOPSIE CHIRURGICALE',\n# 'technic': 'HISTOLOGIE ET CYTOLOGIE PAR INCLUSION',\n# 'organ': \"SEIN (\u00c9GALEMENT UTILIS\u00c9 CHEZ L'HOMME)\",\n# 'pathology': 'PATHOLOGIE G\u00c9N\u00c9RALE NON TUMORALE',\n# 'pathology_type': 'ETAT SUBNORMAL - LESION MINEURE',\n# 'behaviour_type': 'CARACTERES GENERAUX'}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/adicap/factory/#edsnlp.pipelines.ner.adicap.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.adicap</code> </p> <code>pattern</code> <p>The regex pattern to use for matching ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>([A-Z]\\.?[A-Z]\\.?[A-Z]{2}\\.?(?:\\d{4}|\\d{4}|[A-Z...</code> </p> <code>prefix</code> <p>The regex pattern to use for matching the prefix before ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>(?i)(codification|adicap)</code> </p> <code>window</code> <p>Number of tokens to look for prefix. It will never go further the start of the sentence</p> <p> TYPE: <code>int</code> DEFAULT: <code>500</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>adicap</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'adicap': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/factory/#edsnlp.pipelines.ner.adicap.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.adicap</code> pipeline was developed by AP-HP's Data Science team. The codes were downloaded from the website of 'Agence du num\u00e9rique en sant\u00e9' (\"Th\u00e9saurus de la codification ADICAP - Index raisonn\u00e9 des l\u00e9sions\", sant\u00e9, 2019)</p>"},{"location":"reference/edsnlp/pipelines/ner/adicap/models/","title":"<code>edsnlp.pipelines.ner.adicap.models</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/adicap/patterns/","title":"<code>edsnlp.pipelines.ner.adicap.patterns</code>","text":"<p>Source : https://esante.gouv.fr/sites/default/files/media_entity/documents/cgts_sem_adicap_fiche-detaillee.pdf</p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/","title":"<code>edsnlp.pipelines.ner.behaviors</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/","title":"<code>edsnlp.pipelines.ner.behaviors.alcohol</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/alcohol/","title":"<code>edsnlp.pipelines.ner.behaviors.alcohol.alcohol</code>","text":"<p><code>eds.alcohol</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.alcohol.AlcoholMatcher","title":"<code>AlcoholMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.alcohol</code> pipeline component extracts mentions of alcohol consumption. It won't match occasional consumption, nor acute intoxication.</p> Details of the used patterns <pre><code># fmt: off\ndefault_patterns = dict(\n    source=\"alcohol\",\n    regex=[\n        r\"\\balco[ol]\",\n        r\"\\bethyl\",\n        r\"(?&lt;!(25.?)|(sevrage)).?\\boh\\b\",\n        r\"exogenose\",\n        r\"delirium.tremens\",\n    ],\n    exclude=[\n        dict(\n            regex=[\n                \"occasion\",\n                \"episod\",\n                \"festi\",\n                \"rare\",\n                \"libre\",  # OH-libres\n                \"aigu\",\n            ],\n            window=(-3, 5),\n        ),\n        dict(\n            regex=[\"pansement\", \"compress\"],\n            window=-3,\n        ),\n    ],\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"stopped\",\n            regex=r\"(?&lt;!non )(?&lt;!pas )(sevr|arret|stop|ancien)\",\n            window=(-3, 5),\n        ),\n        dict(\n            name=\"zero_after\",\n            regex=r\"^[a-z]*\\s*:?[\\s-]*(0|oui|non(?! sevr))\",\n            window=6,\n        ),\n    ],\n)\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.alcohol.AlcoholMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"PRESENT\"</code></li> <li><code>\"ABSTINENCE\"</code> if the patient stopped its consumption</li> <li><code>\"ABSENT\"</code> if the patient has no alcohol dependence</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.alcohol.AlcoholMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.alcohol\")\n</code></pre> <p>Below are a few examples:</p> 12345678 <pre><code>text = \"Patient alcoolique.\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [alcoolique]\n</code></pre> <pre><code>text = \"OH chronique.\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [OH]\n</code></pre> <pre><code>text = \"Prise d'alcool occasionnelle\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Application d'un pansement alcoolis\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Alcoolisme sevr\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcoolisme sevr\u00e9]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevr\u00e9]}\n</code></pre> <pre><code>text = \"Alcoolisme non sevr\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcoolisme]\n</code></pre> <pre><code>text = \"Alcool: 0\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcool: 0]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'zero_after': [0]}\n</code></pre> <pre><code>text = \"Le patient est en cours de sevrage \u00e9thylotabagique\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [sevrage \u00e9thylotabagique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevrage]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.alcohol.AlcoholMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.alcohol</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>{'source': 'alcohol', 'regex': ['\\\\balco[ol]', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>alcohol</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'alcohol': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/alcohol/#edsnlp.pipelines.ner.behaviors.alcohol.alcohol.AlcoholMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.alcohol</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/factory/","title":"<code>edsnlp.pipelines.ner.behaviors.alcohol.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/factory/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component","title":"<code>create_component = Language.factory('eds.alcohol', assigns=['doc.ents', 'doc.spans'])(AlcoholMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.alcohol</code> pipeline component extracts mentions of alcohol consumption. It won't match occasional consumption, nor acute intoxication.</p> Details of the used patterns <pre><code># fmt: off\ndefault_patterns = dict(\n    source=\"alcohol\",\n    regex=[\n        r\"\\balco[ol]\",\n        r\"\\bethyl\",\n        r\"(?&lt;!(25.?)|(sevrage)).?\\boh\\b\",\n        r\"exogenose\",\n        r\"delirium.tremens\",\n    ],\n    exclude=[\n        dict(\n            regex=[\n                \"occasion\",\n                \"episod\",\n                \"festi\",\n                \"rare\",\n                \"libre\",  # OH-libres\n                \"aigu\",\n            ],\n            window=(-3, 5),\n        ),\n        dict(\n            regex=[\"pansement\", \"compress\"],\n            window=-3,\n        ),\n    ],\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"stopped\",\n            regex=r\"(?&lt;!non )(?&lt;!pas )(sevr|arret|stop|ancien)\",\n            window=(-3, 5),\n        ),\n        dict(\n            name=\"zero_after\",\n            regex=r\"^[a-z]*\\s*:?[\\s-]*(0|oui|non(?! sevr))\",\n            window=6,\n        ),\n    ],\n)\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/factory/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"PRESENT\"</code></li> <li><code>\"ABSTINENCE\"</code> if the patient stopped its consumption</li> <li><code>\"ABSENT\"</code> if the patient has no alcohol dependence</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/factory/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.alcohol\")\n</code></pre> <p>Below are a few examples:</p> 12345678 <pre><code>text = \"Patient alcoolique.\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [alcoolique]\n</code></pre> <pre><code>text = \"OH chronique.\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [OH]\n</code></pre> <pre><code>text = \"Prise d'alcool occasionnelle\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Application d'un pansement alcoolis\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Alcoolisme sevr\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcoolisme sevr\u00e9]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevr\u00e9]}\n</code></pre> <pre><code>text = \"Alcoolisme non sevr\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcoolisme]\n</code></pre> <pre><code>text = \"Alcool: 0\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [Alcool: 0]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'zero_after': [0]}\n</code></pre> <pre><code>text = \"Le patient est en cours de sevrage \u00e9thylotabagique\"\ndoc = nlp(text)\nspans = doc.spans[\"alcohol\"]\n\nspans\n# Out: [sevrage \u00e9thylotabagique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevrage]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/factory/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.alcohol</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>{'source': 'alcohol', 'regex': ['\\\\balco[ol]', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>alcohol</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'alcohol': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/factory/#edsnlp.pipelines.ner.behaviors.alcohol.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.alcohol</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/alcohol/patterns/","title":"<code>edsnlp.pipelines.ner.behaviors.alcohol.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/","title":"<code>edsnlp.pipelines.ner.behaviors.tobacco</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/factory/","title":"<code>edsnlp.pipelines.ner.behaviors.tobacco.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/factory/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component","title":"<code>create_component = Language.factory('eds.tobacco', assigns=['doc.ents', 'doc.spans'])(TobaccoMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.tobacco</code> pipeline component extracts mentions of tobacco consumption.</p> Details of the used patterns <pre><code># fmt: off\nPA = r\"(?:\\bp/?a\\b|paquets?.?annee)\"\nQUANTITY = r\"(?P&lt;quantity&gt;[\\d]{1,3})\"\nPUNCT = r\"\\.,-;\\(\\)\"\n\ndefault_patterns = [\n    dict(\n        source=\"tobacco\",\n        regex=[\n            r\"tabagi\",\n            r\"tabac\",\n            r\"\\bfume\\b\",\n            r\"\\bfumeu\",\n            r\"\\bpipes?\\b\",\n        ],\n        exclude=dict(\n            regex=[\n                \"occasion\",\n                \"moder\",\n                \"quelqu\",\n                \"festi\",\n                \"rare\",\n                \"sujet\",  # Example : Chez le sujet fumeur ... generic sentences\n            ],\n            window=(-3, 5),\n        ),\n        regex_attr=\"NORM\",\n        assign=[\n            dict(\n                name=\"stopped\",\n                regex=r\"(?&lt;!non )(?&lt;!pas )(\\bex\\b|sevr|arret|stop|ancien)\",\n                window=(-3, 15),\n            ),\n            dict(\n                name=\"zero_after\",\n                regex=r\"^[a-z]*\\s*:?[\\s-]*(0|non(?! sevr))\",\n                window=6,\n            ),\n            dict(\n                name=\"PA\",\n                regex=rf\"{QUANTITY}[^{PUNCT}]{{0,10}}{PA}|{PA}[^{PUNCT}]{{0,10}}{QUANTITY}\",\n                window=(-10, 10),\n                reduce_mode=\"keep_first\",\n            ),\n            dict(\n                name=\"secondhand\",\n                regex=\"(passif)\",\n                window=5,\n                reduce_mode=\"keep_first\",\n            ),\n        ],\n    )\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/factory/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"PRESENT\"</code></li> <li><code>\"ABSTINENCE\"</code> if the patient stopped its consumption</li> <li><code>\"ABSENT\"</code> if the patient has no tobacco dependence</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>PA</code>: the mentioned year-pack (= paquet-ann\u00e9e)</li> <li><code>secondhand</code>: if secondhand smoking</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/factory/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.tobacco\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Tabagisme \u00e9valu\u00e9 \u00e0 15 PA\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabagisme \u00e9valu\u00e9 \u00e0 15 PA]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'PA': 15}\n</code></pre> <pre><code>text = \"Patient tabagique\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [tabagique]\n</code></pre> <pre><code>text = \"Tabagisme festif\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"On a un tabagisme ancien\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [tabagisme ancien]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [ancien]}\n</code></pre> <pre><code>text = \"Tabac: 0\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabac: 0]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'zero_after': [0]}\n</code></pre> <pre><code>text = \"Tabagisme passif\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabagisme passif]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'secondhand': passif}\n</code></pre> <pre><code>text = \"Tabac: sevr\u00e9 depuis 5 ans\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabac: sevr\u00e9]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevr\u00e9]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/factory/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.tobacco</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'tobacco', 'regex': ['tabagi', 'tab...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>tobacco</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'tobacco': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/factory/#edsnlp.pipelines.ner.behaviors.tobacco.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.tobacco</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/patterns/","title":"<code>edsnlp.pipelines.ner.behaviors.tobacco.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/tobacco/","title":"<code>edsnlp.pipelines.ner.behaviors.tobacco.tobacco</code>","text":"<p><code>eds.tobacco</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.tobacco.TobaccoMatcher","title":"<code>TobaccoMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.tobacco</code> pipeline component extracts mentions of tobacco consumption.</p> Details of the used patterns <pre><code># fmt: off\nPA = r\"(?:\\bp/?a\\b|paquets?.?annee)\"\nQUANTITY = r\"(?P&lt;quantity&gt;[\\d]{1,3})\"\nPUNCT = r\"\\.,-;\\(\\)\"\n\ndefault_patterns = [\n    dict(\n        source=\"tobacco\",\n        regex=[\n            r\"tabagi\",\n            r\"tabac\",\n            r\"\\bfume\\b\",\n            r\"\\bfumeu\",\n            r\"\\bpipes?\\b\",\n        ],\n        exclude=dict(\n            regex=[\n                \"occasion\",\n                \"moder\",\n                \"quelqu\",\n                \"festi\",\n                \"rare\",\n                \"sujet\",  # Example : Chez le sujet fumeur ... generic sentences\n            ],\n            window=(-3, 5),\n        ),\n        regex_attr=\"NORM\",\n        assign=[\n            dict(\n                name=\"stopped\",\n                regex=r\"(?&lt;!non )(?&lt;!pas )(\\bex\\b|sevr|arret|stop|ancien)\",\n                window=(-3, 15),\n            ),\n            dict(\n                name=\"zero_after\",\n                regex=r\"^[a-z]*\\s*:?[\\s-]*(0|non(?! sevr))\",\n                window=6,\n            ),\n            dict(\n                name=\"PA\",\n                regex=rf\"{QUANTITY}[^{PUNCT}]{{0,10}}{PA}|{PA}[^{PUNCT}]{{0,10}}{QUANTITY}\",\n                window=(-10, 10),\n                reduce_mode=\"keep_first\",\n            ),\n            dict(\n                name=\"secondhand\",\n                regex=\"(passif)\",\n                window=5,\n                reduce_mode=\"keep_first\",\n            ),\n        ],\n    )\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.tobacco.TobaccoMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"PRESENT\"</code></li> <li><code>\"ABSTINENCE\"</code> if the patient stopped its consumption</li> <li><code>\"ABSENT\"</code> if the patient has no tobacco dependence</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>PA</code>: the mentioned year-pack (= paquet-ann\u00e9e)</li> <li><code>secondhand</code>: if secondhand smoking</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.tobacco.TobaccoMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.tobacco\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Tabagisme \u00e9valu\u00e9 \u00e0 15 PA\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabagisme \u00e9valu\u00e9 \u00e0 15 PA]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'PA': 15}\n</code></pre> <pre><code>text = \"Patient tabagique\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [tabagique]\n</code></pre> <pre><code>text = \"Tabagisme festif\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"On a un tabagisme ancien\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [tabagisme ancien]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [ancien]}\n</code></pre> <pre><code>text = \"Tabac: 0\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabac: 0]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'zero_after': [0]}\n</code></pre> <pre><code>text = \"Tabagisme passif\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabagisme passif]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSENT\n\nspan._.assigned\n# Out: {'secondhand': passif}\n</code></pre> <pre><code>text = \"Tabac: sevr\u00e9 depuis 5 ans\"\ndoc = nlp(text)\nspans = doc.spans[\"tobacco\"]\n\nspans\n# Out: [Tabac: sevr\u00e9]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: ABSTINENCE\n\nspan._.assigned\n# Out: {'stopped': [sevr\u00e9]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.tobacco.TobaccoMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.tobacco</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'tobacco', 'regex': ['tabagi', 'tab...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>tobacco</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'tobacco': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/behaviors/tobacco/tobacco/#edsnlp.pipelines.ner.behaviors.tobacco.tobacco.TobaccoMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.tobacco</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/cim10/","title":"<code>edsnlp.pipelines.ner.cim10</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/cim10/factory/","title":"<code>edsnlp.pipelines.ner.cim10.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/cim10/factory/#edsnlp.pipelines.ner.cim10.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.cim10</code> pipeline component extract terms from documents using the CIM10 (French-language ICD) terminology as a reference.</p> <p>Very low recall</p> <p>When using the <code>exact</code> matching mode, this component has a very poor recall performance. We can use the <code>simstring</code> mode to retrieve approximate matches, albeit at the cost of a significantly higher computation time.</p>"},{"location":"reference/edsnlp/pipelines/ner/cim10/factory/#edsnlp.pipelines.ner.cim10.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.cim10\", config=dict(term_matcher=\"simstring\"))\n\ntext = \"Le patient est suivi pour fi\u00e8vres typho\u00efde et paratypho\u00efde.\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (fi\u00e8vres typho\u00efde et paratypho\u00efde,)\n\nent = doc.ents[0]\n\nent.label_\n# Out: cim10\n\nent.kb_id_\n# Out: A01\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/cim10/factory/#edsnlp.pipelines.ner.cim10.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.cim10'</code> </p> <code>attr</code> <p>The default attribute to use for matching.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>'exact'</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher term matcher</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cim10'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'cim10': True}</code> </p> RETURNS DESCRIPTION <code>TerminologyMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/cim10/factory/#edsnlp.pipelines.ner.cim10.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.cim10</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/ner/cim10/patterns/","title":"<code>edsnlp.pipelines.ner.cim10.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/covid/","title":"<code>edsnlp.pipelines.ner.covid</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/covid/factory/","title":"<code>edsnlp.pipelines.ner.covid.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/covid/factory/#edsnlp.pipelines.ner.covid.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.covid</code> pipeline component detects mentions of COVID19.</p>"},{"location":"reference/edsnlp/pipelines/ner/covid/factory/#edsnlp.pipelines.ner.covid.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.covid\")\n\ntext = \"Le patient est admis pour une infection au coronavirus.\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (infection au coronavirus,)\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/covid/factory/#edsnlp.pipelines.ner.covid.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.covid'</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>Union[str, Dict[str, str]]</code> DEFAULT: <code>'LOWER'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>patterns</code> <p>The regex pattern to use</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>patterns</code> </p> <code>label</code> <p>Label to use for matches</p> <p> TYPE: <code>str</code> DEFAULT: <code>'covid'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'covid': True}</code> </p> RETURNS DESCRIPTION <code>GenericMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/covid/factory/#edsnlp.pipelines.ner.covid.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.covid</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/ner/covid/patterns/","title":"<code>edsnlp.pipelines.ner.covid.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/","title":"<code>edsnlp.pipelines.ner.disorders</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/","title":"<code>edsnlp.pipelines.ner.disorders.aids</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/aids/","title":"<code>edsnlp.pipelines.ner.disorders.aids.aids</code>","text":"<p><code>eds.aids</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/aids/#edsnlp.pipelines.ner.disorders.aids.aids.AIDSMatcher","title":"<code>AIDSMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.aids</code> pipeline component extracts mentions of AIDS. It will notably match:</p> <ul> <li>Mentions of VIH/HIV at the SIDA/AIDS stage</li> <li>Mentions of VIH/HIV with opportunistic(s) infection(s)</li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre> <p>On HIV infection</p> <p>pre-AIDS HIV infection are not extracted, only AIDS.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/aids/#edsnlp.pipelines.ner.disorders.aids.aids.AIDSMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>opportunist</code>: list of opportunist infections extracted around the HIV mention</li> <li><code>stage</code>: stage of the HIV infection</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/aids/#edsnlp.pipelines.ner.disorders.aids.aids.AIDSMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.aids\")\n</code></pre> <p>Below are a few examples:</p> SIDAVIHCoinfectionVIH stade SIDA <pre><code>text = \"Patient atteint du VIH au stade SIDA.\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH au stade SIDA]\n</code></pre> <pre><code>text = \"Patient atteint du VIH.\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Il y a un VIH avec coinfection pneumocystose\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'opportunist': [coinfection, pneumocystose]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un VIH stade C\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': [C]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/aids/#edsnlp.pipelines.ner.disorders.aids.aids.AIDSMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.aids</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'aids', 'regex': ['(vih.{1,5}stade....</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>aids</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'aids': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/aids/#edsnlp.pipelines.ner.disorders.aids.aids.AIDSMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.aids</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/factory/","title":"<code>edsnlp.pipelines.ner.disorders.aids.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/factory/#edsnlp.pipelines.ner.disorders.aids.factory.create_component","title":"<code>create_component = Language.factory('eds.aids', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.aids</code> pipeline component extracts mentions of AIDS. It will notably match:</p> <ul> <li>Mentions of VIH/HIV at the SIDA/AIDS stage</li> <li>Mentions of VIH/HIV with opportunistic(s) infection(s)</li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre> <p>On HIV infection</p> <p>pre-AIDS HIV infection are not extracted, only AIDS.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/factory/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>opportunist</code>: list of opportunist infections extracted around the HIV mention</li> <li><code>stage</code>: stage of the HIV infection</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/factory/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.aids\")\n</code></pre> <p>Below are a few examples:</p> SIDAVIHCoinfectionVIH stade SIDA <pre><code>text = \"Patient atteint du VIH au stade SIDA.\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH au stade SIDA]\n</code></pre> <pre><code>text = \"Patient atteint du VIH.\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Il y a un VIH avec coinfection pneumocystose\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'opportunist': [coinfection, pneumocystose]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un VIH stade C\"\ndoc = nlp(text)\nspans = doc.spans[\"aids\"]\n\nspans\n# Out: [VIH]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': [C]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/factory/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.aids</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'aids', 'regex': ['(vih.{1,5}stade....</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>aids</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'aids': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/factory/#edsnlp.pipelines.ner.disorders.aids.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.aids</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/aids/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.aids.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/base/","title":"<code>edsnlp.pipelines.ner.disorders.base</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/base/#edsnlp.pipelines.ner.disorders.base.DisorderMatcher","title":"<code>DisorderMatcher</code>","text":"<p>           Bases: <code>ContextualMatcher</code></p> <p>Base class used to implement various disorders or behaviors extraction pipes</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/base/#edsnlp.pipelines.ner.disorders.base.DisorderMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> </p> <code>patterns</code> <p>The configuration dictionary</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> </p> <code>include_assigned</code> <p>Whether to include (eventual) assign matches to the final entity</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>detailed_status_mapping</code> <p>Mapping from integer status (0, 1 or 2) to human-readable string</p> <p> TYPE: <code>Dict[int, str]</code> DEFAULT: <code>{0: 'ABSENT', 1: 'PRESENT'}</code> </p> <p>alignment_mode : str     Overwrite alignment mode. regex_flags : Union[re.RegexFlag, int]     RegExp flags to use when matching, filtering and assigning (See     the re docs)</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/base/#edsnlp.pipelines.ner.disorders.base.DisorderMatcher.__call__","title":"<code>__call__</code>","text":"<p>Tags entities.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/base/#edsnlp.pipelines.ner.disorders.base.DisorderMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>annotated spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/","title":"<code>edsnlp.pipelines.ner.disorders.cerebrovascular_accident</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/cerebrovascular_accident/","title":"<code>edsnlp.pipelines.ner.disorders.cerebrovascular_accident.cerebrovascular_accident</code>","text":"<p><code>eds.cerebrovascular_accident</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/cerebrovascular_accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.cerebrovascular_accident.CerebrovascularAccidentMatcher","title":"<code>CerebrovascularAccidentMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.cerebrovascular_accident</code> pipeline component extracts mentions of cerebrovascular accident. It will notably match:</p> <ul> <li>Mentions of AVC/AIT</li> <li>Mentions of bleeding, hemorrhage, thrombus, ischemia, etc., localized in the brain</li> </ul> Details of the used patterns <pre><code># fmt: off\nimport re\n\nfrom edsnlp.utils.resources import get_AVC_care_site\n\nfrom ..terms import BRAIN, HEART, PERIPHERAL\n\nAVC_CARE_SITES_REGEX = [\n    r\"\\b\" + re.escape(cs.strip()) + r\"\\b\" for cs in get_AVC_care_site(prefix=True)\n] + [\n    r\"h[o\u00f4]p\",\n    r\"\\brcp\",\n    r\"service\",\n    r\"\\bsau\",\n    r\"ap.?hp\",\n    r\"\\burg\",\n    r\"finess\",\n    r\"\\bsiret\",\n    r\"[\u00e0a] avc\",\n    r\"consult\",\n]\n\navc = dict(\n    source=\"avc\",\n    regex=[\n        r\"\\bavc\\b\",\n    ],\n    exclude=[\n        dict(\n            regex=AVC_CARE_SITES_REGEX,\n            window=(-5, 5),\n            regex_flags=re.S | re.I,\n            limit_to_sentence=False,\n        ),\n        dict(\n            regex=r\"\\b[a-z]\\.\",\n            window=2,\n            limit_to_sentence=False,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"(hemorr?agie|hematome)\",\n        r\"angiopath\",\n        r\"angioplasti\",\n        r\"infarctus\",\n        r\"occlusion\",\n        r\"saignement\",\n        r\"embol\",\n        r\"vascularite\",\n        r\"\\bhsd\\b\",\n        r\"thrombos\",\n        r\"thrombol[^y]\",\n        r\"thrombophi\",\n        r\"thrombi[^n]\",\n        r\"thrombus\",\n        r\"thrombectomi\",\n        r\"phleb\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=[\n        dict(\n            regex=r\"pulmo|poumon\",\n            window=4,\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"brain_localized\",\n            regex=\"(\" + r\"|\".join(BRAIN) + \")\",\n            window=(-15, 15),\n            limit_to_sentence=False,\n            include_assigned=False,\n        ),\n    ],\n)\n\ngeneral = dict(\n    source=\"general\",\n    regex=[\n        r\"accident.{1,5}vasculaires.{1,5}cereb\",\n        r\"accident.{1,5}vasculaire.{1,5}ischemi\",\n        r\"accident.{1,5}ischemi\",\n        r\"moya.?moya\",\n        r\"occlusion.{1,5}(artere|veine).{1,20}retine\",\n        r\"vasculopathies?.cerebrales?.ischemique\",\n        r\"maladies?.des.petites.arteres\",\n        r\"maladies?.des.petits.vaisseaux\",\n        r\"thrombolyse\",\n        r\"\\bsusac\\b\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bAIC\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nAIT = dict(\n    source=\"AIT\",\n    regex=[\n        r\"\\bAIC\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n        r\"\\bAIT\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nischemia = dict(\n    source=\"ischemia\",\n    regex=[\n        r\"ischemi\",\n    ],\n    exclude=[\n        dict(\n            regex=PERIPHERAL + HEART,\n            window=(-7, 7),\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"brain\",\n            regex=\"(\" + r\"|\".join(BRAIN) + \")\",\n            window=(-10, 15),\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    avc,\n    with_localization,\n    general,\n    acronym,\n    AIT,\n    ischemia,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/cerebrovascular_accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.cerebrovascular_accident.CerebrovascularAccidentMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/cerebrovascular_accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.cerebrovascular_accident.CerebrovascularAccidentMatcher--usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.cerebrovascular_accident\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Patient hospitalis\u00e9 \u00e0 AVC.\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Hospitalisation pour un AVC.\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [AVC]\n</code></pre> <pre><code>text = \"Saignement intracranien\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Saignement]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [intracranien]}\n</code></pre> <pre><code>text = \"Thrombose p\u00e9riph\u00e9rique\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Thrombose sylvienne\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Thrombose]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [sylvienne]}\n</code></pre> <pre><code>text = \"Infarctus c\u00e9r\u00e9bral\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Infarctus]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [c\u00e9r\u00e9bral]}\n</code></pre> <pre><code>text = \"Soign\u00e9 via un thrombolyse\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [thrombolyse]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/cerebrovascular_accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.cerebrovascular_accident.CerebrovascularAccidentMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.cerebrovascular_accident</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'avc', 'regex': ['\\\\bavc\\\\b'], 'exc...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>cerebrovascular_accident</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'cerebrovascular_accident': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/cerebrovascular_accident/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.cerebrovascular_accident.CerebrovascularAccidentMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.cerebrovascular_accident</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/factory/","title":"<code>edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/factory/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component","title":"<code>create_component = Language.factory('eds.cerebrovascular_accident', assigns=['doc.ents', 'doc.spans'])(CerebrovascularAccidentMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.cerebrovascular_accident</code> pipeline component extracts mentions of cerebrovascular accident. It will notably match:</p> <ul> <li>Mentions of AVC/AIT</li> <li>Mentions of bleeding, hemorrhage, thrombus, ischemia, etc., localized in the brain</li> </ul> Details of the used patterns <pre><code># fmt: off\nimport re\n\nfrom edsnlp.utils.resources import get_AVC_care_site\n\nfrom ..terms import BRAIN, HEART, PERIPHERAL\n\nAVC_CARE_SITES_REGEX = [\n    r\"\\b\" + re.escape(cs.strip()) + r\"\\b\" for cs in get_AVC_care_site(prefix=True)\n] + [\n    r\"h[o\u00f4]p\",\n    r\"\\brcp\",\n    r\"service\",\n    r\"\\bsau\",\n    r\"ap.?hp\",\n    r\"\\burg\",\n    r\"finess\",\n    r\"\\bsiret\",\n    r\"[\u00e0a] avc\",\n    r\"consult\",\n]\n\navc = dict(\n    source=\"avc\",\n    regex=[\n        r\"\\bavc\\b\",\n    ],\n    exclude=[\n        dict(\n            regex=AVC_CARE_SITES_REGEX,\n            window=(-5, 5),\n            regex_flags=re.S | re.I,\n            limit_to_sentence=False,\n        ),\n        dict(\n            regex=r\"\\b[a-z]\\.\",\n            window=2,\n            limit_to_sentence=False,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"(hemorr?agie|hematome)\",\n        r\"angiopath\",\n        r\"angioplasti\",\n        r\"infarctus\",\n        r\"occlusion\",\n        r\"saignement\",\n        r\"embol\",\n        r\"vascularite\",\n        r\"\\bhsd\\b\",\n        r\"thrombos\",\n        r\"thrombol[^y]\",\n        r\"thrombophi\",\n        r\"thrombi[^n]\",\n        r\"thrombus\",\n        r\"thrombectomi\",\n        r\"phleb\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=[\n        dict(\n            regex=r\"pulmo|poumon\",\n            window=4,\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"brain_localized\",\n            regex=\"(\" + r\"|\".join(BRAIN) + \")\",\n            window=(-15, 15),\n            limit_to_sentence=False,\n            include_assigned=False,\n        ),\n    ],\n)\n\ngeneral = dict(\n    source=\"general\",\n    regex=[\n        r\"accident.{1,5}vasculaires.{1,5}cereb\",\n        r\"accident.{1,5}vasculaire.{1,5}ischemi\",\n        r\"accident.{1,5}ischemi\",\n        r\"moya.?moya\",\n        r\"occlusion.{1,5}(artere|veine).{1,20}retine\",\n        r\"vasculopathies?.cerebrales?.ischemique\",\n        r\"maladies?.des.petites.arteres\",\n        r\"maladies?.des.petits.vaisseaux\",\n        r\"thrombolyse\",\n        r\"\\bsusac\\b\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bAIC\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nAIT = dict(\n    source=\"AIT\",\n    regex=[\n        r\"\\bAIC\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n        r\"\\bAIT\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nischemia = dict(\n    source=\"ischemia\",\n    regex=[\n        r\"ischemi\",\n    ],\n    exclude=[\n        dict(\n            regex=PERIPHERAL + HEART,\n            window=(-7, 7),\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"brain\",\n            regex=\"(\" + r\"|\".join(BRAIN) + \")\",\n            window=(-10, 15),\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    avc,\n    with_localization,\n    general,\n    acronym,\n    AIT,\n    ischemia,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/factory/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/factory/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.cerebrovascular_accident\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Patient hospitalis\u00e9 \u00e0 AVC.\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Hospitalisation pour un AVC.\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [AVC]\n</code></pre> <pre><code>text = \"Saignement intracranien\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Saignement]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [intracranien]}\n</code></pre> <pre><code>text = \"Thrombose p\u00e9riph\u00e9rique\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Thrombose sylvienne\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Thrombose]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [sylvienne]}\n</code></pre> <pre><code>text = \"Infarctus c\u00e9r\u00e9bral\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [Infarctus]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'brain_localized': [c\u00e9r\u00e9bral]}\n</code></pre> <pre><code>text = \"Soign\u00e9 via un thrombolyse\"\ndoc = nlp(text)\nspans = doc.spans[\"cerebrovascular_accident\"]\n\nspans\n# Out: [thrombolyse]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/factory/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.cerebrovascular_accident</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'avc', 'regex': ['\\\\bavc\\\\b'], 'exc...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>cerebrovascular_accident</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'cerebrovascular_accident': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/factory/#edsnlp.pipelines.ner.disorders.cerebrovascular_accident.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.cerebrovascular_accident</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/cerebrovascular_accident/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.cerebrovascular_accident.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/","title":"<code>edsnlp.pipelines.ner.disorders.ckd</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/ckd/","title":"<code>edsnlp.pipelines.ner.disorders.ckd.ckd</code>","text":"<p><code>eds.ckd</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/ckd/#edsnlp.pipelines.ner.disorders.ckd.ckd.CKDMatcher","title":"<code>CKDMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.CKD</code> pipeline component extracts mentions of CKD (Chronic Kidney Disease). It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Kidney transplantation</li> <li>Chronic dialysis</li> <li>Renal failure from stage 3 to 5. The stage is extracted by trying 3 methods:<ul> <li>Extracting the mentioned stage directly (\"IRC stade IV\")</li> <li>Extracting the severity directly (\"IRC terminale\")</li> <li>Extracting the mentioned GFR (DFG in french) (\"IRC avec DFG estim\u00e9 \u00e0 30   mL/min/1,73m2)\")</li> </ul> </li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/ckd/#edsnlp.pipelines.ner.disorders.ckd.ckd.CKDMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>stage</code>: mentioned renal failure stage</li> <li><code>status</code>: mentioned renal failure severity (e.g. mod\u00e9r\u00e9e, s\u00e9v\u00e8re, terminale,   etc.)</li> <li><code>dfg</code>: mentioned DFG</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/ckd/#edsnlp.pipelines.ner.disorders.ckd.ckd.CKDMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.CKD\")\n</code></pre> <p>Below are a few examples:</p> 1234567891011 <pre><code>text = \"Patient atteint d'une glom\u00e9rulopathie.\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [glom\u00e9rulopathie]\n</code></pre> <pre><code>text = \"Patient atteint d'une tubulopathie aig\u00fce.\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Patient transplant\u00e9 r\u00e9nal\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [transplant\u00e9 r\u00e9nal]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une insuffisance r\u00e9nale aig\u00fce sur chronique\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [insuffisance r\u00e9nale aig\u00fce sur chronique]\n</code></pre> <pre><code>text = \"Le patient a \u00e9t\u00e9 dialys\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Le patient est dialys\u00e9 chaque lundi\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [dialys\u00e9 chaque lundi]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'chronic': [lundi]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC s\u00e9v\u00e8re\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC s\u00e9v\u00e8re]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'status': s\u00e9v\u00e8re}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC au stade IV\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC au stade IV]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': IV}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC avec DFG \u00e0 30\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC avec DFG \u00e0 30]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'dfg': 30}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une maladie r\u00e9nale avec DFG \u00e0 110\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/ckd/#edsnlp.pipelines.ner.disorders.ckd.ckd.CKDMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.ckd</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['glomerulonephrit...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>ckd</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'ckd': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/ckd/#edsnlp.pipelines.ner.disorders.ckd.ckd.CKDMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.CKD</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/factory/","title":"<code>edsnlp.pipelines.ner.disorders.ckd.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/factory/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component","title":"<code>create_component = Language.factory('eds.ckd', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.CKD</code> pipeline component extracts mentions of CKD (Chronic Kidney Disease). It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Kidney transplantation</li> <li>Chronic dialysis</li> <li>Renal failure from stage 3 to 5. The stage is extracted by trying 3 methods:<ul> <li>Extracting the mentioned stage directly (\"IRC stade IV\")</li> <li>Extracting the severity directly (\"IRC terminale\")</li> <li>Extracting the mentioned GFR (DFG in french) (\"IRC avec DFG estim\u00e9 \u00e0 30   mL/min/1,73m2)\")</li> </ul> </li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/factory/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>stage</code>: mentioned renal failure stage</li> <li><code>status</code>: mentioned renal failure severity (e.g. mod\u00e9r\u00e9e, s\u00e9v\u00e8re, terminale,   etc.)</li> <li><code>dfg</code>: mentioned DFG</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/factory/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.CKD\")\n</code></pre> <p>Below are a few examples:</p> 1234567891011 <pre><code>text = \"Patient atteint d'une glom\u00e9rulopathie.\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [glom\u00e9rulopathie]\n</code></pre> <pre><code>text = \"Patient atteint d'une tubulopathie aig\u00fce.\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Patient transplant\u00e9 r\u00e9nal\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [transplant\u00e9 r\u00e9nal]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une insuffisance r\u00e9nale aig\u00fce sur chronique\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [insuffisance r\u00e9nale aig\u00fce sur chronique]\n</code></pre> <pre><code>text = \"Le patient a \u00e9t\u00e9 dialys\u00e9\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Le patient est dialys\u00e9 chaque lundi\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [dialys\u00e9 chaque lundi]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'chronic': [lundi]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC s\u00e9v\u00e8re\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC s\u00e9v\u00e8re]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'status': s\u00e9v\u00e8re}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC au stade IV\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC au stade IV]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': IV}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une IRC avec DFG \u00e0 30\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: [IRC avec DFG \u00e0 30]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'dfg': 30}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une maladie r\u00e9nale avec DFG \u00e0 110\"\ndoc = nlp(text)\nspans = doc.spans[\"ckd\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/factory/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.ckd</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['glomerulonephrit...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>ckd</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'ckd': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/factory/#edsnlp.pipelines.ner.disorders.ckd.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.CKD</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/ckd/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.ckd.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/","title":"<code>edsnlp.pipelines.ner.disorders.congestive_heart_failure</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/congestive_heart_failure/","title":"<code>edsnlp.pipelines.ner.disorders.congestive_heart_failure.congestive_heart_failure</code>","text":"<p><code>eds.congestive_heart_failure</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/congestive_heart_failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.congestive_heart_failure.CongestiveHeartFailureMatcher","title":"<code>CongestiveHeartFailureMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.congestive_heart_failure</code> pipeline component extracts mentions of congestive heart failure. It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Heart transplantation</li> <li>AF (Atrial Fibrillation)</li> <li>Pacemaker</li> </ul> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import ASYMPTOMATIC\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"defaillance.{1,10}cardi\",\n        r\"(\u0153|oe)deme.{1,10}pulmon\",\n        r\"(\u0153|oe)deme.{1,10}poumon\",\n        r\"decompensation.{1,10}card\",\n        r\"choc.{1,30}cardio\",\n        r\"greffe.{1,10}c(\u0153|oe)ur\",\n        r\"greffe.{1,10}cardia\",\n        r\"transplantation.{1,10}c(\u0153|oe)ur\",\n        r\"transplantation.{1,10}cardia\",\n        r\"arret.{1,10}cardi\",\n        r\"c(\u0153|oe)ur pulmo\",\n        r\"foie.card\",\n        r\"pace.?maker\",\n        r\"stimulateur.cardiaque\",\n        r\"valve.{1,30}(meca|artific)\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nsymptomatic = dict(\n    source=\"symptomatic\",\n    regex=[\n        r\"cardiopathi\",\n        r\"cardiomyopathi\",\n        r\"d(i|y)sfonction.{1,15}(ventricul|\\bvg|cardiaque)\",\n        r\"valvulopathie\",\n        r\"\\bic\\b.{1,10}(droite|gauche)\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=ASYMPTOMATIC + [r\"(?&lt;!\\bnon.)ischem\"],  # Exclusion of ischemic events\n        window=5,\n    ),\n)\n\nwith_minimum_severity = dict(\n    source=\"min_severity\",\n    regex=[\n        r\"insuffisance.{1,10}(\\bcardi|\\bdiasto|\\bventri|\\bmitral|tri.?cusp)\",\n        r\"(retrecissement|stenose).(aortique|mitral)\",\n        r\"\\brac\\b\",\n        r\"\\brm\\b\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=ASYMPTOMATIC + [\"minime\", \"modere\", r\"non.serre\"],\n        window=5,\n    ),\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bOAP\\b\",\n        r\"\\bCMH\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nAF_main_pattern = dict(\n    source=\"AF_main\",\n    regex=[\n        r\"fibrill?ation.{1,3}(atriale|auriculaire|ventriculaire)\",\n        r\"flutter\",\n        r\"brady.?arythmie\",\n        r\"pace.?maker\",\n    ],\n)\n\nAF_acronym = dict(\n    source=\"AF_acronym\",\n    regex=[\n        r\"\\bFA\\b\",\n        r\"\\bAC.?FA\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    symptomatic,\n    acronym,\n    AF_main_pattern,\n    AF_acronym,\n    with_minimum_severity,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/congestive_heart_failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.congestive_heart_failure.CongestiveHeartFailureMatcher--usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.congestive_heart_failure\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Pr\u00e9sence d'un oed\u00e8me pulmonaire\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [oed\u00e8me pulmonaire]\n</code></pre> <pre><code>text = \"Le patient est \u00e9quip\u00e9 d'un pace-maker\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [pace-maker]\n</code></pre> <pre><code>text = \"Un cardiopathie non d\u00e9compens\u00e9e\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Insuffisance cardiaque\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [Insuffisance cardiaque]\n</code></pre> <pre><code>text = \"Insuffisance cardiaque minime\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/congestive_heart_failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.congestive_heart_failure.CongestiveHeartFailureMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>(str)</code> DEFAULT: <code>eds.congestive_heart_failure</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['defaillance.{1,1...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>congestive_heart_failure</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'congestive_heart_failure': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/congestive_heart_failure/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.congestive_heart_failure.CongestiveHeartFailureMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.congestive_heart_failure</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/factory/","title":"<code>edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/factory/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component","title":"<code>create_component = Language.factory('eds.congestive_heart_failure', assigns=['doc.ents', 'doc.spans'])(CongestiveHeartFailureMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.congestive_heart_failure</code> pipeline component extracts mentions of congestive heart failure. It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Heart transplantation</li> <li>AF (Atrial Fibrillation)</li> <li>Pacemaker</li> </ul> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import ASYMPTOMATIC\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"defaillance.{1,10}cardi\",\n        r\"(\u0153|oe)deme.{1,10}pulmon\",\n        r\"(\u0153|oe)deme.{1,10}poumon\",\n        r\"decompensation.{1,10}card\",\n        r\"choc.{1,30}cardio\",\n        r\"greffe.{1,10}c(\u0153|oe)ur\",\n        r\"greffe.{1,10}cardia\",\n        r\"transplantation.{1,10}c(\u0153|oe)ur\",\n        r\"transplantation.{1,10}cardia\",\n        r\"arret.{1,10}cardi\",\n        r\"c(\u0153|oe)ur pulmo\",\n        r\"foie.card\",\n        r\"pace.?maker\",\n        r\"stimulateur.cardiaque\",\n        r\"valve.{1,30}(meca|artific)\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nsymptomatic = dict(\n    source=\"symptomatic\",\n    regex=[\n        r\"cardiopathi\",\n        r\"cardiomyopathi\",\n        r\"d(i|y)sfonction.{1,15}(ventricul|\\bvg|cardiaque)\",\n        r\"valvulopathie\",\n        r\"\\bic\\b.{1,10}(droite|gauche)\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=ASYMPTOMATIC + [r\"(?&lt;!\\bnon.)ischem\"],  # Exclusion of ischemic events\n        window=5,\n    ),\n)\n\nwith_minimum_severity = dict(\n    source=\"min_severity\",\n    regex=[\n        r\"insuffisance.{1,10}(\\bcardi|\\bdiasto|\\bventri|\\bmitral|tri.?cusp)\",\n        r\"(retrecissement|stenose).(aortique|mitral)\",\n        r\"\\brac\\b\",\n        r\"\\brm\\b\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=ASYMPTOMATIC + [\"minime\", \"modere\", r\"non.serre\"],\n        window=5,\n    ),\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bOAP\\b\",\n        r\"\\bCMH\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nAF_main_pattern = dict(\n    source=\"AF_main\",\n    regex=[\n        r\"fibrill?ation.{1,3}(atriale|auriculaire|ventriculaire)\",\n        r\"flutter\",\n        r\"brady.?arythmie\",\n        r\"pace.?maker\",\n    ],\n)\n\nAF_acronym = dict(\n    source=\"AF_acronym\",\n    regex=[\n        r\"\\bFA\\b\",\n        r\"\\bAC.?FA\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    symptomatic,\n    acronym,\n    AF_main_pattern,\n    AF_acronym,\n    with_minimum_severity,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/factory/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component--usage","title":"Usage","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.congestive_heart_failure\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Pr\u00e9sence d'un oed\u00e8me pulmonaire\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [oed\u00e8me pulmonaire]\n</code></pre> <pre><code>text = \"Le patient est \u00e9quip\u00e9 d'un pace-maker\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [pace-maker]\n</code></pre> <pre><code>text = \"Un cardiopathie non d\u00e9compens\u00e9e\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Insuffisance cardiaque\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: [Insuffisance cardiaque]\n</code></pre> <pre><code>text = \"Insuffisance cardiaque minime\"\ndoc = nlp(text)\nspans = doc.spans[\"congestive_heart_failure\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/factory/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>(str)</code> DEFAULT: <code>eds.congestive_heart_failure</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['defaillance.{1,1...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>congestive_heart_failure</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'congestive_heart_failure': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/factory/#edsnlp.pipelines.ner.disorders.congestive_heart_failure.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.congestive_heart_failure</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/congestive_heart_failure/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.congestive_heart_failure.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/","title":"<code>edsnlp.pipelines.ner.disorders.connective_tissue_disease</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/connective_tissue_disease/","title":"<code>edsnlp.pipelines.ner.disorders.connective_tissue_disease.connective_tissue_disease</code>","text":"<p><code>eds.connective_tissue_disease</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/connective_tissue_disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.connective_tissue_disease.ConnectiveTissueDiseaseMatcher","title":"<code>ConnectiveTissueDiseaseMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.connective_tissue_disease</code> pipeline component extracts mentions of connective tissue diseases.</p> Details of the used patterns <pre><code># fmt: off\nTO_EXCLUDE = r\"(?&lt;!a )((\\bacc\\b)|anti.?coag|anti.?corps|buschke|(\\bac\\b)|(\\bbio))\"\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"arthrites.{1,5}juveniles.{1,5}idiopa\",\n        r\"myosite\",\n        r\"myopathie.{1,5}inflammatoire\",\n        r\"polyarthrite.{1,5}chronique.{1,5}evol\",\n        r\"polymyosie\",\n        r\"polyarthrites.{1,5}(rhizo|rhuma)\",\n        r\"sclerodermie\",\n        r\"connectivite\",\n        r\"sarcoidose\",\n    ],\n    exclude=dict(\n        regex=[TO_EXCLUDE],\n        window=(-7, 7),\n    ),\n    regex_attr=\"NORM\",\n)\n\nlupus = dict(\n    source=\"lupus\",\n    regex=[\n        r\"\\blupus\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nlupique = dict(\n    source=\"lupique\",\n    regex=[\n        r\"\\blupique\",\n    ],\n    exclude=dict(\n        regex=[TO_EXCLUDE],\n        window=(-7, 7),\n    ),\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronyms\",\n    regex=[\n        r\"\\bAJI\\b\",\n        r\"\\bLED\\b\",\n        r\"\\bPCE\\b\",\n        r\"\\bCREST\\b\",\n        r\"\\bPPR\\b\",\n        r\"\\bMICI\\b\",\n        r\"\\bMNAI\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nnamed_disease = dict(\n    source=\"named_disease\",\n    regex=[\n        r\"libman.?lack\",\n        r\"\\bstill\",\n        r\"felty\",\n        r\"forestier.?certon\",\n        r\"gou(g|j)erot\",\n        r\"raynaud\",\n        r\"thibierge.?weiss\",\n        r\"sjogren\",\n        r\"gou(g|j)erot.?sjogren\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    lupus,\n    lupique,\n    acronym,\n    named_disease,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/connective_tissue_disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.connective_tissue_disease.ConnectiveTissueDiseaseMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/connective_tissue_disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.connective_tissue_disease.ConnectiveTissueDiseaseMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.connective_tissue_disease\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Pr\u00e9sence d'une scl\u00e9rodermie.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [scl\u00e9rodermie]\n</code></pre> <pre><code>text = \"Patient atteint d'un lupus.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [lupus]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'anticoagulants lupiques,\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Il y a une MICI.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [MICI]\n</code></pre> <pre><code>text = \"Syndrome de Raynaud\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [Raynaud]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/connective_tissue_disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.connective_tissue_disease.ConnectiveTissueDiseaseMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.connective_tissue_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['arthrites.{1,5}j...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>connective_tissue_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'connective_tissue_disease': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/connective_tissue_disease/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.connective_tissue_disease.ConnectiveTissueDiseaseMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.connective_tissue_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/factory/","title":"<code>edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/factory/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component","title":"<code>create_component = Language.factory('eds.connective_tissue_disease', assigns=['doc.ents', 'doc.spans'])(ConnectiveTissueDiseaseMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.connective_tissue_disease</code> pipeline component extracts mentions of connective tissue diseases.</p> Details of the used patterns <pre><code># fmt: off\nTO_EXCLUDE = r\"(?&lt;!a )((\\bacc\\b)|anti.?coag|anti.?corps|buschke|(\\bac\\b)|(\\bbio))\"\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"arthrites.{1,5}juveniles.{1,5}idiopa\",\n        r\"myosite\",\n        r\"myopathie.{1,5}inflammatoire\",\n        r\"polyarthrite.{1,5}chronique.{1,5}evol\",\n        r\"polymyosie\",\n        r\"polyarthrites.{1,5}(rhizo|rhuma)\",\n        r\"sclerodermie\",\n        r\"connectivite\",\n        r\"sarcoidose\",\n    ],\n    exclude=dict(\n        regex=[TO_EXCLUDE],\n        window=(-7, 7),\n    ),\n    regex_attr=\"NORM\",\n)\n\nlupus = dict(\n    source=\"lupus\",\n    regex=[\n        r\"\\blupus\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nlupique = dict(\n    source=\"lupique\",\n    regex=[\n        r\"\\blupique\",\n    ],\n    exclude=dict(\n        regex=[TO_EXCLUDE],\n        window=(-7, 7),\n    ),\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronyms\",\n    regex=[\n        r\"\\bAJI\\b\",\n        r\"\\bLED\\b\",\n        r\"\\bPCE\\b\",\n        r\"\\bCREST\\b\",\n        r\"\\bPPR\\b\",\n        r\"\\bMICI\\b\",\n        r\"\\bMNAI\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nnamed_disease = dict(\n    source=\"named_disease\",\n    regex=[\n        r\"libman.?lack\",\n        r\"\\bstill\",\n        r\"felty\",\n        r\"forestier.?certon\",\n        r\"gou(g|j)erot\",\n        r\"raynaud\",\n        r\"thibierge.?weiss\",\n        r\"sjogren\",\n        r\"gou(g|j)erot.?sjogren\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    lupus,\n    lupique,\n    acronym,\n    named_disease,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/factory/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/factory/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.connective_tissue_disease\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Pr\u00e9sence d'une scl\u00e9rodermie.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [scl\u00e9rodermie]\n</code></pre> <pre><code>text = \"Patient atteint d'un lupus.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [lupus]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'anticoagulants lupiques,\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Il y a une MICI.\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [MICI]\n</code></pre> <pre><code>text = \"Syndrome de Raynaud\"\ndoc = nlp(text)\nspans = doc.spans[\"connective_tissue_disease\"]\n\nspans\n# Out: [Raynaud]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/factory/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.connective_tissue_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['arthrites.{1,5}j...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>connective_tissue_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'connective_tissue_disease': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/factory/#edsnlp.pipelines.ner.disorders.connective_tissue_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.connective_tissue_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/connective_tissue_disease/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.connective_tissue_disease.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/","title":"<code>edsnlp.pipelines.ner.disorders.copd</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/copd/","title":"<code>edsnlp.pipelines.ner.disorders.copd.copd</code>","text":"<p><code>eds.copd</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/copd/#edsnlp.pipelines.ner.disorders.copd.copd.COPDMatcher","title":"<code>COPDMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.copd</code> pipeline component extracts mentions of COPD (Chronic obstructive pulmonary disease). It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Pulmonary hypertension</li> <li>Long-term oxygen therapy</li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/copd/#edsnlp.pipelines.ner.disorders.copd.copd.COPDMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/copd/#edsnlp.pipelines.ner.disorders.copd.copd.COPDMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.copd\")\n</code></pre> <p>Below are a few examples:</p> 123456 <pre><code>text = \"Une fibrose interstitielle diffuse idiopathique\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [fibrose interstitielle diffuse idiopathique]\n</code></pre> <pre><code>text = \"Patient atteint de pneumoconiose\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [pneumoconiose]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une HTAP.\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [HTAP]\n</code></pre> <pre><code>text = \"On voit une hypertension pulmonaire minime\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"La patiente a \u00e9t\u00e9 mis sous oxyg\u00e9norequ\u00e9rance\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"La patiente est sous oxyg\u00e9norequ\u00e9rance au long cours\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [oxyg\u00e9norequ\u00e9rance au long cours]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'long': [long cours]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/copd/#edsnlp.pipelines.ner.disorders.copd.copd.COPDMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.copd</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['alveolites.{1,5}...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>copd</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'copd': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/copd/#edsnlp.pipelines.ner.disorders.copd.copd.COPDMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.copd</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/factory/","title":"<code>edsnlp.pipelines.ner.disorders.copd.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/factory/#edsnlp.pipelines.ner.disorders.copd.factory.create_component","title":"<code>create_component = Language.factory('eds.copd', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.copd</code> pipeline component extracts mentions of COPD (Chronic obstructive pulmonary disease). It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Pulmonary hypertension</li> <li>Long-term oxygen therapy</li> </ul> Details of the used patterns <pre><code># fmt: off\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/factory/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/factory/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.copd\")\n</code></pre> <p>Below are a few examples:</p> 123456 <pre><code>text = \"Une fibrose interstitielle diffuse idiopathique\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [fibrose interstitielle diffuse idiopathique]\n</code></pre> <pre><code>text = \"Patient atteint de pneumoconiose\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [pneumoconiose]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'une HTAP.\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [HTAP]\n</code></pre> <pre><code>text = \"On voit une hypertension pulmonaire minime\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"La patiente a \u00e9t\u00e9 mis sous oxyg\u00e9norequ\u00e9rance\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"La patiente est sous oxyg\u00e9norequ\u00e9rance au long cours\"\ndoc = nlp(text)\nspans = doc.spans[\"copd\"]\n\nspans\n# Out: [oxyg\u00e9norequ\u00e9rance au long cours]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'long': [long cours]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/factory/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.copd</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['alveolites.{1,5}...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>copd</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'copd': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/factory/#edsnlp.pipelines.ner.disorders.copd.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.copd</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/copd/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.copd.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/","title":"<code>edsnlp.pipelines.ner.disorders.dementia</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/dementia/","title":"<code>edsnlp.pipelines.ner.disorders.dementia.dementia</code>","text":"<p><code>eds.dementia</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/dementia/#edsnlp.pipelines.ner.disorders.dementia.dementia.DementiaMatcher","title":"<code>DementiaMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.dementia</code> pipeline component extracts mentions of dementia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"demence\",\n        r\"dementiel\",\n        r\"corps de le[vw]y\",\n        r\"deficits?.chroniques?.cognitif\",\n        r\"troubles?.mnesique?\",\n        r\"troubles?.praxique\",\n        r\"troubles?.attentionel\",\n        r\"troubles?.degeneratif.{1,15}fonctions.{1,5}sup\",\n        r\"maladies?.cerebrales?.degen\",\n        r\"troubles?.neurocogn\",\n        r\"deficits?.cognitif\",\n        r\"(trouble|dysfonction).{1,20} cogniti\",\n        r\"atteinte.{1,7}spheres?cogniti\",\n        r\"syndrome.{1,10}(frontal|neuro.deg)\",\n        r\"dysfonction.{1,25}cogni\",\n        r\"(?&lt;!specialisee )alzheimer\",\n        r\"demence.{1,20}(\\balz|\\bpark)\",\n        r\"binswanger\",\n        r\"gehring\",\n        r\"\\bpick\",\n        r\"de guam\",\n        r\"[kc]reutzfeld.{1,5}ja[ck]ob\",\n        r\"huntington\",\n        r\"korsako[fv]\",\n        r\"atrophie.{1,10}(cortico|hippocamp|cereb|lobe)\",\n    ],\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bSLA\\b\",\n        r\"\\bDFT\\b\",\n        r\"\\bDFT\",\n        r\"\\bTNC\\b\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=r\"\\banti\",  # anticorps\n        window=-15,\n        regex_attr=\"NORM\",\n    ),\n)\n\ncharcot = dict(\n    source=\"charcot\",\n    regex=[\n        r\"maladie.{1,10}charcot\",\n    ],\n    exclude=dict(\n        regex=[\n            \"pied de\",\n            \"marie.?tooth\",\n        ],\n        window=(-3, 3),\n    ),\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    charcot,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/dementia/#edsnlp.pipelines.ner.disorders.dementia.dementia.DementiaMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/dementia/#edsnlp.pipelines.ner.disorders.dementia.dementia.DementiaMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.dementia\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"D'importants d\u00e9ficits cognitifs\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [d\u00e9ficits cognitifs]\n</code></pre> <pre><code>text = \"Patient atteint de d\u00e9mence\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [d\u00e9mence]\n</code></pre> <pre><code>text = \"On retrouve des anti-SLA\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une maladie de Charcot\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [maladie de Charcot]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/dementia/#edsnlp.pipelines.ner.disorders.dementia.dementia.DementiaMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.dementia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['demence', 'demen...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>dementia</code> </p> <code>span_setter</code> <p>The span setter to use</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'dementia': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/dementia/#edsnlp.pipelines.ner.disorders.dementia.dementia.DementiaMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.dementia</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/factory/","title":"<code>edsnlp.pipelines.ner.disorders.dementia.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/factory/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component","title":"<code>create_component = Language.factory('eds.dementia', assigns=['doc.ents', 'doc.spans'])(DementiaMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.dementia</code> pipeline component extracts mentions of dementia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"demence\",\n        r\"dementiel\",\n        r\"corps de le[vw]y\",\n        r\"deficits?.chroniques?.cognitif\",\n        r\"troubles?.mnesique?\",\n        r\"troubles?.praxique\",\n        r\"troubles?.attentionel\",\n        r\"troubles?.degeneratif.{1,15}fonctions.{1,5}sup\",\n        r\"maladies?.cerebrales?.degen\",\n        r\"troubles?.neurocogn\",\n        r\"deficits?.cognitif\",\n        r\"(trouble|dysfonction).{1,20} cogniti\",\n        r\"atteinte.{1,7}spheres?cogniti\",\n        r\"syndrome.{1,10}(frontal|neuro.deg)\",\n        r\"dysfonction.{1,25}cogni\",\n        r\"(?&lt;!specialisee )alzheimer\",\n        r\"demence.{1,20}(\\balz|\\bpark)\",\n        r\"binswanger\",\n        r\"gehring\",\n        r\"\\bpick\",\n        r\"de guam\",\n        r\"[kc]reutzfeld.{1,5}ja[ck]ob\",\n        r\"huntington\",\n        r\"korsako[fv]\",\n        r\"atrophie.{1,10}(cortico|hippocamp|cereb|lobe)\",\n    ],\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bSLA\\b\",\n        r\"\\bDFT\\b\",\n        r\"\\bDFT\",\n        r\"\\bTNC\\b\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=r\"\\banti\",  # anticorps\n        window=-15,\n        regex_attr=\"NORM\",\n    ),\n)\n\ncharcot = dict(\n    source=\"charcot\",\n    regex=[\n        r\"maladie.{1,10}charcot\",\n    ],\n    exclude=dict(\n        regex=[\n            \"pied de\",\n            \"marie.?tooth\",\n        ],\n        window=(-3, 3),\n    ),\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    charcot,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/factory/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/factory/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.dementia\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"D'importants d\u00e9ficits cognitifs\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [d\u00e9ficits cognitifs]\n</code></pre> <pre><code>text = \"Patient atteint de d\u00e9mence\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [d\u00e9mence]\n</code></pre> <pre><code>text = \"On retrouve des anti-SLA\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une maladie de Charcot\"\ndoc = nlp(text)\nspans = doc.spans[\"dementia\"]\n\nspans\n# Out: [maladie de Charcot]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/factory/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.dementia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['demence', 'demen...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>dementia</code> </p> <code>span_setter</code> <p>The span setter to use</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'dementia': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/factory/#edsnlp.pipelines.ner.disorders.dementia.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.dementia</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/dementia/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.dementia.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/","title":"<code>edsnlp.pipelines.ner.disorders.diabetes</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/","title":"<code>edsnlp.pipelines.ner.disorders.diabetes.diabetes</code>","text":"<p><code>eds.diabetes</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.diabetes.DiabetesMatcher","title":"<code>DiabetesMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.diabetes</code> pipeline component extracts mentions of diabetes.</p> Details of the used patterns <pre><code># fmt: off\nCOMPLICATIONS = [\n    r\"nephropat\",\n    r\"neuropat\",\n    r\"retinopat\",\n    r\"glomerulopathi\",\n    r\"glomeruloscleros\",\n    r\"angiopathi\",\n    r\"origine\",\n]\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"\\bds?n?id\\b\",\n        r\"\\bdiabet[^o]\",\n        r\"\\bdb\\b\",\n        r\"\\bdt.?(i|ii|1|2)\\b\",\n    ],\n    exclude=dict(\n        regex=[\n            \"insipide\",\n            \"nephrogenique\",\n            \"aigu\",\n            r\"\\bdr\\b\",  # Dr. ...\n            \"endocrino\",  # Section title\n            \"soins aux pieds\",  # Section title\n            \"nutrition\",  # Section title\n            r\"\\s?:\\n+\\W+(?!oui|non|\\W)\",  # General pattern for section title\n        ],\n        window=(-5, 5),\n    ),\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"complicated_before\",\n            regex=r\"(\" + r\"|\".join(COMPLICATIONS + [\"origine\"]) + r\")\",\n            window=-3,\n        ),\n        dict(\n            name=\"complicated_after\",\n            regex=r\"(\"\n            + r\"|\".join([r\"(?&lt;!sans )compli\", r\"(?&lt;!a)symptomatique\"] + COMPLICATIONS)\n            + r\")\",\n            window=12,\n        ),\n        dict(\n            name=\"type\",\n            regex=r\"type.(i|ii|1|2)\",\n            window=6,\n        ),\n        dict(\n            name=\"insulin\",\n            regex=r\"insulino.?(dep|req)\",\n            window=6,\n        ),\n        dict(\n            name=\"corticoid\",\n            regex=r\"(bctc\\b|cortico(?:.?induit)?)\",\n            window=6,\n        ),\n    ],\n)\n\ncomplicated_pattern = dict(\n    source=\"complicated\",\n    regex=[\n        r\"(mal|maux).perforants?(.plantaire)?\",\n        r\"pieds? diabeti\",\n    ],\n    exclude=dict(\n        regex=\"soins aux\",  # Section title\n        window=-2,\n    ),\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    complicated_pattern,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.diabetes.DiabetesMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"WITH_COMPLICATION\"</code> if the diabetes is  complicated (e.g., via organ    damages)</li> <li><code>\"WITHOUT_COMPLICATION\"</code> otherwise</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>type</code>: type of diabetes (I or II)</li> <li><code>insulin</code>: if the diabetes is insulin-dependent</li> <li><code>corticoid</code>: if the diabetes is corticoid-induced</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.diabetes.DiabetesMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.diabetes\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Pr\u00e9sence d'un DT2\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [DT2]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un DNID\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [DNID]\n</code></pre> <pre><code>text = \"Patient diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [diab\u00e9tique]\n</code></pre> <pre><code>text = \"Un diab\u00e8te insipide\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Atteinte neurologique d'origine diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [origine diab\u00e9tique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n\nspan._.assigned\n# Out: {'complicated_before': [origine]}\n</code></pre> <pre><code>text = \"Une r\u00e9tinopathie diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [r\u00e9tinopathie diab\u00e9tique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n\nspan._.assigned\n# Out: {'complicated_before': [r\u00e9tinopathie]}\n</code></pre> <pre><code>text = \"Il y a un mal perforant plantaire\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [mal perforant plantaire]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.diabetes.DiabetesMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.diabetes</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['\\\\bds?n?id\\\\b', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>diabetes</code> </p> <code>span_setter</code> <p>The span setter to use</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'diabetes': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.diabetes.DiabetesMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.diabetes</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/diabetes/#edsnlp.pipelines.ner.disorders.diabetes.diabetes.DiabetesMatcher.has_far_complications","title":"<code>has_far_complications</code>","text":"<p>Handles the common case where complications are listed as bullet points, sometimes fairly far from the anchor.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/factory/","title":"<code>edsnlp.pipelines.ner.disorders.diabetes.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/factory/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component","title":"<code>create_component = Language.factory('eds.diabetes', assigns=['doc.ents', 'doc.spans'])(DiabetesMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.diabetes</code> pipeline component extracts mentions of diabetes.</p> Details of the used patterns <pre><code># fmt: off\nCOMPLICATIONS = [\n    r\"nephropat\",\n    r\"neuropat\",\n    r\"retinopat\",\n    r\"glomerulopathi\",\n    r\"glomeruloscleros\",\n    r\"angiopathi\",\n    r\"origine\",\n]\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"\\bds?n?id\\b\",\n        r\"\\bdiabet[^o]\",\n        r\"\\bdb\\b\",\n        r\"\\bdt.?(i|ii|1|2)\\b\",\n    ],\n    exclude=dict(\n        regex=[\n            \"insipide\",\n            \"nephrogenique\",\n            \"aigu\",\n            r\"\\bdr\\b\",  # Dr. ...\n            \"endocrino\",  # Section title\n            \"soins aux pieds\",  # Section title\n            \"nutrition\",  # Section title\n            r\"\\s?:\\n+\\W+(?!oui|non|\\W)\",  # General pattern for section title\n        ],\n        window=(-5, 5),\n    ),\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"complicated_before\",\n            regex=r\"(\" + r\"|\".join(COMPLICATIONS + [\"origine\"]) + r\")\",\n            window=-3,\n        ),\n        dict(\n            name=\"complicated_after\",\n            regex=r\"(\"\n            + r\"|\".join([r\"(?&lt;!sans )compli\", r\"(?&lt;!a)symptomatique\"] + COMPLICATIONS)\n            + r\")\",\n            window=12,\n        ),\n        dict(\n            name=\"type\",\n            regex=r\"type.(i|ii|1|2)\",\n            window=6,\n        ),\n        dict(\n            name=\"insulin\",\n            regex=r\"insulino.?(dep|req)\",\n            window=6,\n        ),\n        dict(\n            name=\"corticoid\",\n            regex=r\"(bctc\\b|cortico(?:.?induit)?)\",\n            window=6,\n        ),\n    ],\n)\n\ncomplicated_pattern = dict(\n    source=\"complicated\",\n    regex=[\n        r\"(mal|maux).perforants?(.plantaire)?\",\n        r\"pieds? diabeti\",\n    ],\n    exclude=dict(\n        regex=\"soins aux\",  # Section title\n        window=-2,\n    ),\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    complicated_pattern,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/factory/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"WITH_COMPLICATION\"</code> if the diabetes is  complicated (e.g., via organ    damages)</li> <li><code>\"WITHOUT_COMPLICATION\"</code> otherwise</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>type</code>: type of diabetes (I or II)</li> <li><code>insulin</code>: if the diabetes is insulin-dependent</li> <li><code>corticoid</code>: if the diabetes is corticoid-induced</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/factory/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.diabetes\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Pr\u00e9sence d'un DT2\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [DT2]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un DNID\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [DNID]\n</code></pre> <pre><code>text = \"Patient diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [diab\u00e9tique]\n</code></pre> <pre><code>text = \"Un diab\u00e8te insipide\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Atteinte neurologique d'origine diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [origine diab\u00e9tique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n\nspan._.assigned\n# Out: {'complicated_before': [origine]}\n</code></pre> <pre><code>text = \"Une r\u00e9tinopathie diab\u00e9tique\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [r\u00e9tinopathie diab\u00e9tique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n\nspan._.assigned\n# Out: {'complicated_before': [r\u00e9tinopathie]}\n</code></pre> <pre><code>text = \"Il y a un mal perforant plantaire\"\ndoc = nlp(text)\nspans = doc.spans[\"diabetes\"]\n\nspans\n# Out: [mal perforant plantaire]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: WITH_COMPLICATION\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/factory/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.diabetes</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['\\\\bds?n?id\\\\b', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>diabetes</code> </p> <code>span_setter</code> <p>The span setter to use</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'diabetes': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/factory/#edsnlp.pipelines.ner.disorders.diabetes.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.diabetes</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/diabetes/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.diabetes.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/helpers/","title":"<code>edsnlp.pipelines.ner.disorders.helpers</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/helpers/#edsnlp.pipelines.ner.disorders.helpers.get_all_pipes","title":"<code>get_all_pipes</code>","text":"<p>Get all comorbidity pipe names</p> RETURNS DESCRIPTION <code>_type_</code> <p>description</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/","title":"<code>edsnlp.pipelines.ner.disorders.hemiplegia</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/factory/","title":"<code>edsnlp.pipelines.ner.disorders.hemiplegia.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/factory/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component","title":"<code>create_component = Language.factory('eds.hemiplegia', assigns=['doc.ents', 'doc.spans'])(HemiplegiaMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.hemiplegia</code> pipeline component extracts mentions of hemiplegia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"hemiplegi\",\n        r\"tetraplegi\",\n        r\"quadriplegi\",\n        r\"paraplegi\",\n        r\"neuropathie.{1,25}motrice.{1,30}type [5V]\",\n        r\"charcot.?marie.?tooth\",\n        r\"locked.?in\",\n        r\"syndrome.{1,5}(enfermement|verrouillage)|(desafferen)\",\n        r\"paralysie.{1,10}hemicorps\",\n        r\"paralysie.{1,10}jambe\",\n        r\"paralysie.{1,10}membre\",\n        r\"paralysie.{1,10}cote\",\n        r\"paralysie.{1,5}cerebrale.{1,5}spastique\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLIS\\b\",\n        r\"\\bNMSH\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/factory/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/factory/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.hemiplegia\")\n</code></pre> <p>Below are a few examples:</p> 123 <pre><code>text = \"Patient h\u00e9mipl\u00e9gique\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [h\u00e9mipl\u00e9gique]\n</code></pre> <pre><code>text = \"Paralysie des membres inf\u00e9rieurs\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [Paralysie des membres]\n</code></pre> <pre><code>text = \"Patient en LIS\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [LIS]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/factory/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.hemiplegia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['hemiplegi', 'tet...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>hemiplegia</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'hemiplegia': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/factory/#edsnlp.pipelines.ner.disorders.hemiplegia.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.hemiplegia</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/hemiplegia/","title":"<code>edsnlp.pipelines.ner.disorders.hemiplegia.hemiplegia</code>","text":"<p><code>eds.hemiplegia</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.hemiplegia.HemiplegiaMatcher","title":"<code>HemiplegiaMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.hemiplegia</code> pipeline component extracts mentions of hemiplegia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"hemiplegi\",\n        r\"tetraplegi\",\n        r\"quadriplegi\",\n        r\"paraplegi\",\n        r\"neuropathie.{1,25}motrice.{1,30}type [5V]\",\n        r\"charcot.?marie.?tooth\",\n        r\"locked.?in\",\n        r\"syndrome.{1,5}(enfermement|verrouillage)|(desafferen)\",\n        r\"paralysie.{1,10}hemicorps\",\n        r\"paralysie.{1,10}jambe\",\n        r\"paralysie.{1,10}membre\",\n        r\"paralysie.{1,10}cote\",\n        r\"paralysie.{1,5}cerebrale.{1,5}spastique\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLIS\\b\",\n        r\"\\bNMSH\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.hemiplegia.HemiplegiaMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.hemiplegia.HemiplegiaMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.hemiplegia\")\n</code></pre> <p>Below are a few examples:</p> 123 <pre><code>text = \"Patient h\u00e9mipl\u00e9gique\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [h\u00e9mipl\u00e9gique]\n</code></pre> <pre><code>text = \"Paralysie des membres inf\u00e9rieurs\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [Paralysie des membres]\n</code></pre> <pre><code>text = \"Patient en LIS\"\ndoc = nlp(text)\nspans = doc.spans[\"hemiplegia\"]\n\nspans\n# Out: [LIS]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.hemiplegia.HemiplegiaMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.hemiplegia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['hemiplegi', 'tet...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>hemiplegia</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'hemiplegia': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/hemiplegia/#edsnlp.pipelines.ner.disorders.hemiplegia.hemiplegia.HemiplegiaMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.hemiplegia</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/hemiplegia/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.hemiplegia.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/","title":"<code>edsnlp.pipelines.ner.disorders.leukemia</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/factory/","title":"<code>edsnlp.pipelines.ner.disorders.leukemia.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/factory/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component","title":"<code>create_component = Language.factory('eds.leukemia', assigns=['doc.ents', 'doc.spans'])(LeukemiaMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.leukemia</code> pipeline component extracts mentions of leukemia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"leucemie\",\n        r\"(syndrome.)?myeloproliferatif\",\n        r\"m[yi]eloprolifer\",\n    ],\n    exclude=dict(\n        regex=[\n            \"plasmocyte\",\n            \"benin\",\n            \"benign\",\n        ],\n        window=5,\n    ),\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLAM\\b\",\n        r\"\\bLAM.?[0-9]\",\n        r\"\\bLAL\\b\",\n        r\"\\bLMC\\b\",\n        r\"\\bLCE\\b\",\n        r\"\\bLMM[JC]\\b\",\n        r\"\\bLCN\\b\",\n        r\"\\bAREB\\b\",\n        r\"\\bAPMF\\b\",\n        r\"\\bLLC\\b\",\n        r\"\\bSMD\\b\",\n        r\"LA my[\u00e9\u00e8e]lomonocytaire\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=\"anti\",\n        window=-20,\n    ),\n)\n\nother = dict(\n    source=\"other\",\n    regex=[\n        r\"myelofibrose\",\n        r\"vaquez\",\n        r\"thrombocytemie.{1,3}essentielle\",\n        r\"splenomegalie.{1,3}myeloide\",\n        r\"mastocytose.{1,5}maligne\",\n        r\"polyglobulie.{1,10}essentielle\",\n        r\"letterer.?siwe\",\n        r\"anemie.refractaire.{1,20}blaste\",\n        r\"m[iy]elod[iy]splasi\",\n        r\"syndrome.myelo.?dysplasique\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    other,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/factory/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/factory/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.leukemia\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Sydrome my\u00e9loprolif\u00e9ratif\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [my\u00e9loprolif\u00e9ratif]\n</code></pre> <pre><code>text = \"Sydrome my\u00e9loprolif\u00e9ratif b\u00e9nin\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Patient atteint d'une LAM\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [LAM]\n</code></pre> <pre><code>text = \"Une maladie de Vaquez\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [Vaquez]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/factory/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.leukemia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['leucemie', '(syn...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>leukemia</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'leukemia': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/factory/#edsnlp.pipelines.ner.disorders.leukemia.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.leukemia</code> component was developed by AP-HP's Data Science team with a team  of medical experts. A paper describing in details the development of those  components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/leukemia/","title":"<code>edsnlp.pipelines.ner.disorders.leukemia.leukemia</code>","text":"<p><code>eds.leukemia</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.leukemia.LeukemiaMatcher","title":"<code>LeukemiaMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.leukemia</code> pipeline component extracts mentions of leukemia.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"leucemie\",\n        r\"(syndrome.)?myeloproliferatif\",\n        r\"m[yi]eloprolifer\",\n    ],\n    exclude=dict(\n        regex=[\n            \"plasmocyte\",\n            \"benin\",\n            \"benign\",\n        ],\n        window=5,\n    ),\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLAM\\b\",\n        r\"\\bLAM.?[0-9]\",\n        r\"\\bLAL\\b\",\n        r\"\\bLMC\\b\",\n        r\"\\bLCE\\b\",\n        r\"\\bLMM[JC]\\b\",\n        r\"\\bLCN\\b\",\n        r\"\\bAREB\\b\",\n        r\"\\bAPMF\\b\",\n        r\"\\bLLC\\b\",\n        r\"\\bSMD\\b\",\n        r\"LA my[\u00e9\u00e8e]lomonocytaire\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=\"anti\",\n        window=-20,\n    ),\n)\n\nother = dict(\n    source=\"other\",\n    regex=[\n        r\"myelofibrose\",\n        r\"vaquez\",\n        r\"thrombocytemie.{1,3}essentielle\",\n        r\"splenomegalie.{1,3}myeloide\",\n        r\"mastocytose.{1,5}maligne\",\n        r\"polyglobulie.{1,10}essentielle\",\n        r\"letterer.?siwe\",\n        r\"anemie.refractaire.{1,20}blaste\",\n        r\"m[iy]elod[iy]splasi\",\n        r\"syndrome.myelo.?dysplasique\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    other,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.leukemia.LeukemiaMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.leukemia.LeukemiaMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.leukemia\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Sydrome my\u00e9loprolif\u00e9ratif\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [my\u00e9loprolif\u00e9ratif]\n</code></pre> <pre><code>text = \"Sydrome my\u00e9loprolif\u00e9ratif b\u00e9nin\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Patient atteint d'une LAM\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [LAM]\n</code></pre> <pre><code>text = \"Une maladie de Vaquez\"\ndoc = nlp(text)\nspans = doc.spans[\"leukemia\"]\n\nspans\n# Out: [Vaquez]\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.leukemia.LeukemiaMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.leukemia</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['leucemie', '(syn...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>leukemia</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'leukemia': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/leukemia/#edsnlp.pipelines.ner.disorders.leukemia.leukemia.LeukemiaMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.leukemia</code> component was developed by AP-HP's Data Science team with a team  of medical experts. A paper describing in details the development of those  components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/leukemia/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.leukemia.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/","title":"<code>edsnlp.pipelines.ner.disorders.liver_disease</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/factory/","title":"<code>edsnlp.pipelines.ner.disorders.liver_disease.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/factory/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component","title":"<code>create_component = Language.factory('eds.liver_disease', assigns=['doc.ents', 'doc.spans'])(LiverDiseaseMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.liver_disease</code> pipeline component extracts mentions of liver disease.</p> Details of the used patterns <pre><code># fmt: off\nmild = dict(\n    source=\"mild\",\n    regex=[\n        r\"cholangites?.{1,10}(sclero|secondaire)\",\n        r\"fibrose.{1,10}(hepatique|foie)\",\n        r\"hepatite.{1,15}chronique\",\n        r\"hepatopathie\",\n        r\"\\bnash\\b\",\n        r\"(maladie|sydrome).{1,10}Hanot\",\n        r\"surinfections.{1,5}delta\",\n        r\"\\bcbp\\b\",\n        r\"\\bmaf\\b\",\n        r\"(maladie|syndrome).{1,8}hanot\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=\"\\bdots?\\b\",\n        window=-5,\n    ),\n)\n\nmoderate_severe = dict(\n    source=\"moderate_severe\",\n    regex=[\n        r\"cirrhose\",\n        r\"necrose.{1,10}(hepati|foie)\",\n        r\"varice.{1,10}(estomac|oesopha|gastr)\",\n        r\"\\bvo\\b.{1,5}(stade|grade).(1|2|3|i{1,3})\",\n        r\"hypertension.{1,5}portale\",\n        r\"scleroses.{1,5}hepatoportale\",\n        r\"sydrome.{1,10}hepato.?ren\",\n        r\"insuffisance.{1,5}hepa\",\n        r\"encephalopathie.{1,5}hepa\",\n        r\"\\btips\\b\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ntransplant = dict(\n    source=\"transplant\",\n    regex=[\n        r\"(?&lt;!pre.?)(greffe|transplant).{1,12}(hepatique|foie)\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=\"chc\",\n        window=(-5, 5),\n    ),\n)\n\ndefault_patterns = [\n    mild,\n    moderate_severe,\n    transplant,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/factory/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"MILD\"</code> for mild liver diseases</li> <li><code>\"MODERATE_TO_SEVERE\"</code> else</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/factory/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.liver_disease\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Il y a une fibrose h\u00e9patique\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [fibrose h\u00e9patique]\n</code></pre> <pre><code>text = \"Une h\u00e9patite B chronique\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [h\u00e9patite B chronique]\n</code></pre> <pre><code>text = \"Le patient consulte pour une cirrhose\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [cirrhose]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: MODERATE_TO_SEVERE\n</code></pre> <pre><code>text = \"Greffe h\u00e9patique.\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [Greffe h\u00e9patique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: MODERATE_TO_SEVERE\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/factory/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.liver_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'mild', 'regex': ['cholangites?.{1,...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>liver_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'liver_disease': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/factory/#edsnlp.pipelines.ner.disorders.liver_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.liver_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/liver_disease/","title":"<code>edsnlp.pipelines.ner.disorders.liver_disease.liver_disease</code>","text":"<p><code>eds.liver_disease</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/liver_disease/#edsnlp.pipelines.ner.disorders.liver_disease.liver_disease.LiverDiseaseMatcher","title":"<code>LiverDiseaseMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.liver_disease</code> pipeline component extracts mentions of liver disease.</p> Details of the used patterns <pre><code># fmt: off\nmild = dict(\n    source=\"mild\",\n    regex=[\n        r\"cholangites?.{1,10}(sclero|secondaire)\",\n        r\"fibrose.{1,10}(hepatique|foie)\",\n        r\"hepatite.{1,15}chronique\",\n        r\"hepatopathie\",\n        r\"\\bnash\\b\",\n        r\"(maladie|sydrome).{1,10}Hanot\",\n        r\"surinfections.{1,5}delta\",\n        r\"\\bcbp\\b\",\n        r\"\\bmaf\\b\",\n        r\"(maladie|syndrome).{1,8}hanot\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=\"\\bdots?\\b\",\n        window=-5,\n    ),\n)\n\nmoderate_severe = dict(\n    source=\"moderate_severe\",\n    regex=[\n        r\"cirrhose\",\n        r\"necrose.{1,10}(hepati|foie)\",\n        r\"varice.{1,10}(estomac|oesopha|gastr)\",\n        r\"\\bvo\\b.{1,5}(stade|grade).(1|2|3|i{1,3})\",\n        r\"hypertension.{1,5}portale\",\n        r\"scleroses.{1,5}hepatoportale\",\n        r\"sydrome.{1,10}hepato.?ren\",\n        r\"insuffisance.{1,5}hepa\",\n        r\"encephalopathie.{1,5}hepa\",\n        r\"\\btips\\b\",\n    ],\n    regex_attr=\"NORM\",\n)\n\ntransplant = dict(\n    source=\"transplant\",\n    regex=[\n        r\"(?&lt;!pre.?)(greffe|transplant).{1,12}(hepatique|foie)\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=\"chc\",\n        window=(-5, 5),\n    ),\n)\n\ndefault_patterns = [\n    mild,\n    moderate_severe,\n    transplant,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/liver_disease/#edsnlp.pipelines.ner.disorders.liver_disease.liver_disease.LiverDiseaseMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"MILD\"</code> for mild liver diseases</li> <li><code>\"MODERATE_TO_SEVERE\"</code> else</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/liver_disease/#edsnlp.pipelines.ner.disorders.liver_disease.liver_disease.LiverDiseaseMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.liver_disease\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Il y a une fibrose h\u00e9patique\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [fibrose h\u00e9patique]\n</code></pre> <pre><code>text = \"Une h\u00e9patite B chronique\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [h\u00e9patite B chronique]\n</code></pre> <pre><code>text = \"Le patient consulte pour une cirrhose\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [cirrhose]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: MODERATE_TO_SEVERE\n</code></pre> <pre><code>text = \"Greffe h\u00e9patique.\"\ndoc = nlp(text)\nspans = doc.spans[\"liver_disease\"]\n\nspans\n# Out: [Greffe h\u00e9patique]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: MODERATE_TO_SEVERE\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/liver_disease/#edsnlp.pipelines.ner.disorders.liver_disease.liver_disease.LiverDiseaseMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.liver_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'mild', 'regex': ['cholangites?.{1,...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>liver_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'liver_disease': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/liver_disease/#edsnlp.pipelines.ner.disorders.liver_disease.liver_disease.LiverDiseaseMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.liver_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/liver_disease/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.liver_disease.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/","title":"<code>edsnlp.pipelines.ner.disorders.lymphoma</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/factory/","title":"<code>edsnlp.pipelines.ner.disorders.lymphoma.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/factory/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component","title":"<code>create_component = Language.factory('eds.lymphoma', assigns=['doc.ents', 'doc.spans'])(LymphomaMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.lymphoma</code> pipeline component extracts mentions of lymphoma.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"lymphom(?:.{1,10}hodgkin)\",\n        r\"lymphom\",\n        r\"lymphangio\",\n        r\"sezary\",\n        r\"burkitt\",\n        r\"kaposi\",\n        r\"hodgkin\",\n        r\"amylose\",\n        r\"plasm[ao]cytome\",\n        r\"lympho.{1,3}sarcome\",\n        r\"lympho.?prolif\",\n        r\"hemopathie.{1,10}lymphoide\",\n        r\"macroglobulinemie\",\n        r\"immunocytome\",\n        r\"maladie.des.chaine\",\n        r\"histiocytose.{1,5}(maligne|langerhans)\",\n        r\"waldenst(ro|or)m\",\n        r\"mycos.{1,10}fongoide\",\n        r\"myelome\",\n        r\"maladie.{1,5}immunoproliferative.{1,5}maligne\",\n        r\"leucemie.{1,10}plasmocyte\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLNH\\b\",\n        r\"\\bLH\\b\",\n        r\"\\bEATL\\b\",\n        r\"\\bLAGC\\b\",\n        r\"\\bLDGCB\\b\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=[\"/L\", \"/mL\"],\n        window=10,\n    ),\n)\n\n\ngammapathy = dict(\n    source=\"gammapathy\",\n    regex=[\n        r\"gammapathie monoclonale\",\n    ],\n    exclude=dict(\n        regex=[\n            \"benin\",\n            \"benign\",\n            \"signification.indeter\",\n            \"NMSI\",\n            \"MGUS\",\n        ],\n        window=(0, 5),\n    ),\n    regex_attr=\"NORM\",\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    # gammapathy,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/factory/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul> <p>Monoclonal gammapathy</p> <p>Monoclonal gammapathies are not extracted by this pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/factory/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.lymphoma\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Un lymphome de Hodgkin.\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [lymphome de Hodgkin]\n</code></pre> <pre><code>text = \"Atteint d'un Waldenst\u00f6rm\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [Waldenst\u00f6rm]\n</code></pre> <pre><code>text = \"Un LAGC\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [LAGC]\n</code></pre> <pre><code>text = \"anti LAGC: 10^4/mL\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/factory/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.lymphoma</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'main', 'regex': ['lymphom(?:.{1,10...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>lymphoma</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'lymphoma': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/factory/#edsnlp.pipelines.ner.disorders.lymphoma.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.lymphoma</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/lymphoma/","title":"<code>edsnlp.pipelines.ner.disorders.lymphoma.lymphoma</code>","text":"<p><code>eds.lymphoma</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.lymphoma.LymphomaMatcher","title":"<code>LymphomaMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.lymphoma</code> pipeline component extracts mentions of lymphoma.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"lymphom(?:.{1,10}hodgkin)\",\n        r\"lymphom\",\n        r\"lymphangio\",\n        r\"sezary\",\n        r\"burkitt\",\n        r\"kaposi\",\n        r\"hodgkin\",\n        r\"amylose\",\n        r\"plasm[ao]cytome\",\n        r\"lympho.{1,3}sarcome\",\n        r\"lympho.?prolif\",\n        r\"hemopathie.{1,10}lymphoide\",\n        r\"macroglobulinemie\",\n        r\"immunocytome\",\n        r\"maladie.des.chaine\",\n        r\"histiocytose.{1,5}(maligne|langerhans)\",\n        r\"waldenst(ro|or)m\",\n        r\"mycos.{1,10}fongoide\",\n        r\"myelome\",\n        r\"maladie.{1,5}immunoproliferative.{1,5}maligne\",\n        r\"leucemie.{1,10}plasmocyte\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bLNH\\b\",\n        r\"\\bLH\\b\",\n        r\"\\bEATL\\b\",\n        r\"\\bLAGC\\b\",\n        r\"\\bLDGCB\\b\",\n    ],\n    regex_attr=\"TEXT\",\n    exclude=dict(\n        regex=[\"/L\", \"/mL\"],\n        window=10,\n    ),\n)\n\n\ngammapathy = dict(\n    source=\"gammapathy\",\n    regex=[\n        r\"gammapathie monoclonale\",\n    ],\n    exclude=dict(\n        regex=[\n            \"benin\",\n            \"benign\",\n            \"signification.indeter\",\n            \"NMSI\",\n            \"MGUS\",\n        ],\n        window=(0, 5),\n    ),\n    regex_attr=\"NORM\",\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    # gammapathy,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.lymphoma.LymphomaMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul> <p>Monoclonal gammapathy</p> <p>Monoclonal gammapathies are not extracted by this pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.lymphoma.LymphomaMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.lymphoma\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Un lymphome de Hodgkin.\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [lymphome de Hodgkin]\n</code></pre> <pre><code>text = \"Atteint d'un Waldenst\u00f6rm\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [Waldenst\u00f6rm]\n</code></pre> <pre><code>text = \"Un LAGC\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: [LAGC]\n</code></pre> <pre><code>text = \"anti LAGC: 10^4/mL\"\ndoc = nlp(text)\nspans = doc.spans[\"lymphoma\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.lymphoma.LymphomaMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.lymphoma</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> DEFAULT: <code>[{'source': 'main', 'regex': ['lymphom(?:.{1,10...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>lymphoma</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'lymphoma': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/lymphoma/#edsnlp.pipelines.ner.disorders.lymphoma.lymphoma.LymphomaMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.lymphoma</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/lymphoma/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.lymphoma.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/","title":"<code>edsnlp.pipelines.ner.disorders.myocardial_infarction</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/factory/","title":"<code>edsnlp.pipelines.ner.disorders.myocardial_infarction.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/factory/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component","title":"<code>create_component = Language.factory('eds.myocardial_infarction', assigns=['doc.ents', 'doc.spans'])(MyocardialInfarctionMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.myocardial_infarction</code> pipeline component extracts mentions of myocardial infarction. It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Mentions of stents with a heart localization</li> </ul> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import HEART\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"coronaropathie\",\n        r\"angor.{1,5}instable\",\n        r\"cardiopathie(?!.{0,20}non).{0,20}(ischem|arteriosc)\",\n        r\"cardio.?myopathie(?!.{0,20}non).{0,20}(ischem|arteriosc)\",\n        r\"ischemi.{1,15}myocard\",\n        r\"syndrome.{1,5}corona.{1,10}aigu\",\n        r\"syndrome.{1,5}corona.{1,10}st\",\n        r\"pontage.{1,5}mammaire\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"\\bstent\",\n        r\"endoprothese\",\n        r\"pontage\",\n        r\"anevr[iy]sme\",\n        \"infarctus\",\n        r\"angioplasti\",\n    ],\n    assign=[\n        dict(\n            name=\"heart_localized\",\n            regex=\"(\" + r\"|\".join(HEART) + \")\",\n            window=(-10, 10),\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bidm\\b\",\n        r\"\\bsca\\b\",\n        r\"\\batl\\b\",\n    ],\n    regex_attr=\"NORM\",\n    assign=dict(\n        name=\"segment\",\n        regex=r\"st([+-])\",\n        window=2,\n    ),\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    with_localization,\n    acronym,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/factory/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>heart_localized</code>: localization of the stent or bypass</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/factory/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.myocardial_infarction\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Une cardiopathie isch\u00e9mique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [cardiopathie isch\u00e9mique]\n</code></pre> <pre><code>text = \"Une cardiopathie non-isch\u00e9mique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un stent sur la marginale\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [stent sur la marginale]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'heart_localized': [marginale]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un stent p\u00e9riph\u00e9rique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"infarctus du myocarde\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [infarctus du myocarde]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'heart_localized': [myocarde]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/factory/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.myocardial_infarction</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['coronaropathie',...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>myocardial_infarction</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'myocardial_infarction': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/factory/#edsnlp.pipelines.ner.disorders.myocardial_infarction.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.myocardial_infarction</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/myocardial_infarction/","title":"<code>edsnlp.pipelines.ner.disorders.myocardial_infarction.myocardial_infarction</code>","text":"<p><code>eds.myocardial_infarction</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/myocardial_infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.myocardial_infarction.MyocardialInfarctionMatcher","title":"<code>MyocardialInfarctionMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.myocardial_infarction</code> pipeline component extracts mentions of myocardial infarction. It will notably match:</p> <ul> <li>Mentions of various diseases (see below)</li> <li>Mentions of stents with a heart localization</li> </ul> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import HEART\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"coronaropathie\",\n        r\"angor.{1,5}instable\",\n        r\"cardiopathie(?!.{0,20}non).{0,20}(ischem|arteriosc)\",\n        r\"cardio.?myopathie(?!.{0,20}non).{0,20}(ischem|arteriosc)\",\n        r\"ischemi.{1,15}myocard\",\n        r\"syndrome.{1,5}corona.{1,10}aigu\",\n        r\"syndrome.{1,5}corona.{1,10}st\",\n        r\"pontage.{1,5}mammaire\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"\\bstent\",\n        r\"endoprothese\",\n        r\"pontage\",\n        r\"anevr[iy]sme\",\n        \"infarctus\",\n        r\"angioplasti\",\n    ],\n    assign=[\n        dict(\n            name=\"heart_localized\",\n            regex=\"(\" + r\"|\".join(HEART) + \")\",\n            window=(-10, 10),\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bidm\\b\",\n        r\"\\bsca\\b\",\n        r\"\\batl\\b\",\n    ],\n    regex_attr=\"NORM\",\n    assign=dict(\n        name=\"segment\",\n        regex=r\"st([+-])\",\n        window=2,\n    ),\n)\n\n\ndefault_patterns = [\n    main_pattern,\n    with_localization,\n    acronym,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/myocardial_infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.myocardial_infarction.MyocardialInfarctionMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>heart_localized</code>: localization of the stent or bypass</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/myocardial_infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.myocardial_infarction.MyocardialInfarctionMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.myocardial_infarction\")\n</code></pre> <p>Below are a few examples:</p> 12345 <pre><code>text = \"Une cardiopathie isch\u00e9mique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [cardiopathie isch\u00e9mique]\n</code></pre> <pre><code>text = \"Une cardiopathie non-isch\u00e9mique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un stent sur la marginale\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [stent sur la marginale]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'heart_localized': [marginale]}\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un stent p\u00e9riph\u00e9rique\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"infarctus du myocarde\"\ndoc = nlp(text)\nspans = doc.spans[\"myocardial_infarction\"]\n\nspans\n# Out: [infarctus du myocarde]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'heart_localized': [myocarde]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/myocardial_infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.myocardial_infarction.MyocardialInfarctionMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.myocardial_infarction</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['coronaropathie',...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>myocardial_infarction</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'myocardial_infarction': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/myocardial_infarction/#edsnlp.pipelines.ner.disorders.myocardial_infarction.myocardial_infarction.MyocardialInfarctionMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.myocardial_infarction</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/myocardial_infarction/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.myocardial_infarction.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/","title":"<code>edsnlp.pipelines.ner.disorders.peptic_ulcer_disease</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/factory/","title":"<code>edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/factory/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component","title":"<code>create_component = Language.factory('eds.peptic_ulcer_disease', assigns=['doc.ents', 'doc.spans'])(PepticUlcerDiseaseMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.peptic_ulcer_disease</code> pipeline component extracts mentions of peptic ulcer disease.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"ulcere.{1,10}gastr\",\n        r\"ulcere.{1,10}duoden\",\n        r\"ulcere.{1,10}antra\",\n        r\"ulcere.{1,10}pept\",\n        r\"ulcere.{1,10}estomac\",\n        r\"ulcere.{1,10}curling\",\n        r\"ulcere.{1,10}bulb\",\n        r\"(\u0153|oe)sophagites.{1,5}pepti.{1,10}ulcer\",\n        r\"gastrite.{1,20}ulcer\",\n        r\"antrite.{1,5}ulcer\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bUGD\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ngeneric = dict(\n    source=\"generic\",\n    regex=r\"ulcere\",\n    regex_attr=\"NORM\",\n    assign=dict(\n        name=\"is_peptic\",\n        regex=r\"\\b(gastr|digest)\",\n        window=(-20, 20),\n        limit_to_sentence=False,\n    ),\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    generic,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/factory/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that matches, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/factory/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.peptic_ulcer_disease\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Beaucoup d'ulc\u00e8res gastriques\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [ulc\u00e8res gastriques]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'UGD\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [UGD]\n</code></pre> <pre><code>text = \"La patient \u00e0 des ulc\u00e8res\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Au niveau gastrique: blabla blabla blabla blabla blabla quelques ulc\u00e8res\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [ulc\u00e8res]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'is_peptic': [gastrique]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/factory/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.peptic_ulcer_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['ulcere.{1,10}gas...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>peptic_ulcer_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'peptic_ulcer_disease': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/factory/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.peptic_ulcer_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/peptic_ulcer_disease/","title":"<code>edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.peptic_ulcer_disease</code>","text":"<p><code>eds.peptic_ulcer_disease</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/peptic_ulcer_disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.peptic_ulcer_disease.PepticUlcerDiseaseMatcher","title":"<code>PepticUlcerDiseaseMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.peptic_ulcer_disease</code> pipeline component extracts mentions of peptic ulcer disease.</p> Details of the used patterns <pre><code># fmt: off\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"ulcere.{1,10}gastr\",\n        r\"ulcere.{1,10}duoden\",\n        r\"ulcere.{1,10}antra\",\n        r\"ulcere.{1,10}pept\",\n        r\"ulcere.{1,10}estomac\",\n        r\"ulcere.{1,10}curling\",\n        r\"ulcere.{1,10}bulb\",\n        r\"(\u0153|oe)sophagites.{1,5}pepti.{1,10}ulcer\",\n        r\"gastrite.{1,20}ulcer\",\n        r\"antrite.{1,5}ulcer\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bUGD\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\ngeneric = dict(\n    source=\"generic\",\n    regex=r\"ulcere\",\n    regex_attr=\"NORM\",\n    assign=dict(\n        name=\"is_peptic\",\n        regex=r\"\\b(gastr|digest)\",\n        window=(-20, 20),\n        limit_to_sentence=False,\n    ),\n)\n\ndefault_patterns = [\n    main_pattern,\n    acronym,\n    generic,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/peptic_ulcer_disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.peptic_ulcer_disease.PepticUlcerDiseaseMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that matches, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/peptic_ulcer_disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.peptic_ulcer_disease.PepticUlcerDiseaseMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.peptic_ulcer_disease\")\n</code></pre> <p>Below are a few examples:</p> 1234 <pre><code>text = \"Beaucoup d'ulc\u00e8res gastriques\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [ulc\u00e8res gastriques]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'UGD\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [UGD]\n</code></pre> <pre><code>text = \"La patient \u00e0 des ulc\u00e8res\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Au niveau gastrique: blabla blabla blabla blabla blabla quelques ulc\u00e8res\"\ndoc = nlp(text)\nspans = doc.spans[\"peptic_ulcer_disease\"]\n\nspans\n# Out: [ulc\u00e8res]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'is_peptic': [gastrique]}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/peptic_ulcer_disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.peptic_ulcer_disease.PepticUlcerDiseaseMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.peptic_ulcer_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['ulcere.{1,10}gas...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>peptic_ulcer_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'peptic_ulcer_disease': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peptic_ulcer_disease/peptic_ulcer_disease/#edsnlp.pipelines.ner.disorders.peptic_ulcer_disease.peptic_ulcer_disease.PepticUlcerDiseaseMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.peptic_ulcer_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/","title":"<code>edsnlp.pipelines.ner.disorders.peripheral_vascular_disease</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/factory/","title":"<code>edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/factory/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component","title":"<code>create_component = Language.factory('eds.peripheral_vascular_disease', assigns=['doc.ents', 'doc.spans'])(PeripheralVascularDiseaseMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.peripheral_vascular_disease</code> pipeline component extracts mentions of peripheral vascular disease.</p> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import ASYMPTOMATIC, BRAIN, HEART, PERIPHERAL\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bAOMI\\b\",\n        r\"\\bACOM\\b\",\n        r\"\\bTAO\\b\",\n        r\"\\bSAPL\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n        r\"\\bSCS\\b\",\n        r\"\\bTVP\\b\",\n        r\"\\bCAPS\\b\",\n        r\"\\bMTEV\\b\",\n        r\"\\bPTT\\b\",\n        r\"\\bMAT\\b\",\n        r\"\\bSHU\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nother = dict(\n    source=\"other\",\n    regex=[\n        r\"\\bbuerger\",\n        r\"takayasu\",\n        r\"\\bhorton\",\n        r\"wegener\",\n        r\"churg.{1,10}strauss\",\n        r\"\\bsneddon\",\n        r\"budd.chiari\",\n        r\"infarctus.{1,5}(renal|splenique|polaire|pulmo)\",\n        r\"ulcere.{1,5}arter\",\n        r\"syndrome.?hemolytique.{1,8}uremique\",\n        r\"granulomatose.{1,10}polyangeite\",\n        r\"occlusion.{1,10}(artere|veine).{1,20}retine\",\n        r\"syndrome.{1,20}anti.?phospho\",\n        r\"embolie.{1,5}pulm\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"angiopathie\",\n        r\"arteriopathies.{1,5}obliterante\",\n        r\"gangren\",\n        r\"claudication\",\n        r\"dissection.{1,10}(aort|arter)\",\n        r\"tromboangeit\",\n        r\"tromboarterit\",\n        r\"(pontage|angioplastie).{1,10}(\\bfem|\\bpop|\\bren|\\bjamb)\",\n        r\"arterite\",\n        r\"(ischemie|infarctus).{1,10}mesenterique\",\n        r\"endarteriectomie\",\n        r\"vascularite\",\n        r\"occlusion.{1,10}terminaisons? carotid\",\n        r\"cryoglobulinemie\",\n        r\"colite.{1,5}ischemi\",\n        r\"embole.{1,10}cholesterol\",\n        r\"purpura.?thrombopenique.?idiopa\",\n        r\"micro.?angiopathie.?thrombotique\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART + ASYMPTOMATIC + [r\"inr\\srecommande\\ssous\\savk\"],\n            window=(-8, 8),\n            limit_to_sentence=False,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nthrombosis = dict(\n    source=\"thrombosis\",\n    regex=[\n        r\"thrombos\",\n        r\"thrombol[^y]\",\n        r\"thrombophi\",\n        r\"thrombi[^n]\",\n        r\"thrombus\",\n        r\"thrombectomi\",\n        r\"thrombo.?embo\",\n        r\"phlebit\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART + [\"superficiel\", \"\\biv\\b\", \"intra.?vein\"],\n            window=(-15, 15),\n            limit_to_sentence=False,\n        ),\n        dict(\n            regex=[\n                \"pre\",\n                \"anti\",\n                \"bilan\",\n            ],\n            window=-4,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\n\nischemia = dict(\n    source=\"ischemia\",\n    regex=[\n        r\"ischemi\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART,\n            window=(-7, 7),\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"peripheral\",\n            regex=\"(\" + r\"|\".join(PERIPHERAL) + \")\",\n            window=15,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nep = dict(\n    source=\"ep\",\n    regex=r\"\\bEP(?![\\w\\./-])\",\n    regex_attr=\"TEXT\",\n    exclude=[\n        dict(\n            regex=[\n                r\"fibreux\",\n                r\"retin\",\n                r\"\\bfove\",\n                r\"\\boct\\b\",\n                r\"\\bmacula\",\n                r\"prosta\",\n                r\"\\bip\\b\",\n                r\"protocole\",\n                r\"seance\",\n                r\"echange\",\n                r\"ritux\",\n                r\"ivig\",\n                r\"ig.?iv\",\n                r\"\\bctc\",\n                r\"corticoide\",\n                r\"serum\",\n                r\"\\bcure\",\n                r\"plasma\",\n                r\"mensuel\",\n                r\"semaine\",\n                r\"serologi\",\n                r\"espaces.porte\",\n                r\"projet\",\n                r\"bolus\",\n            ],\n            window=(-25, 25),\n            limit_to_sentence=False,\n            regex_attr=\"NORM\",\n        ),\n        dict(\n            regex=[r\"rdv\", r\"les\", r\"des\", r\"angine\"],\n            window=(-3, 0),\n            regex_attr=\"NORM\",\n        ),\n    ],\n)\n\nhypertension = dict(\n    source=\"main\",\n    regex=[\n        r\"\\bhta\\b\",\n        r\"hyper.?tension.?arte\",\n        r\"hyper.?tendu\",\n        r\"hyper.?tension.?essenti\",\n        r\"hypertensi\",\n    ],\n    exclude=dict(\n        regex=\"(pulmo|porta)\",\n        window=3,\n    ),\n)\n\ndefault_patterns = [\n    acronym,\n    other,\n    with_localization,\n    thrombosis,\n    ep,\n    ischemia,\n    hypertension,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/factory/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/factory/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.peripheral_vascular_disease\")\n</code></pre> <p>Below are a few examples:</p> 12345678910111213 <pre><code>text = \"Un AOMI\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [AOMI]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un infarctus r\u00e9nal\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [infarctus r\u00e9nal]\n</code></pre> <pre><code>text = \"Une angiopathie c\u00e9r\u00e9brale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une angiopathie\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [angiopathie]\n</code></pre> <pre><code>text = \"Une thrombose c\u00e9r\u00e9brale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une thrombose des veines superficielles\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une thrombose\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [thrombose]\n</code></pre> <pre><code>text = \"Effectuer un bilan pre-trombose\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une isch\u00e9mie des MI est remarqu\u00e9e.\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [isch\u00e9mie des MI]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'peripheral': [MI]}\n</code></pre> <pre><code>text = \"Plusieurs cas d'EP\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [EP]\n</code></pre> <pre><code>text = \"Effectuer des cures d'EP\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Le patient est hypertendu\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [hypertendu]\n</code></pre> <pre><code>text = \"Une hypertension portale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/factory/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.peripheral_vascular_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'acronym', 'regex': ['\\\\bAOMI\\\\b', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>peripheral_vascular_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'peripheral_vascular_disease': T...</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/factory/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.peripheral_vascular_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/peripheral_vascular_disease/","title":"<code>edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.peripheral_vascular_disease</code>","text":"<p><code>eds.peripheral_vascular_disease</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/peripheral_vascular_disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.peripheral_vascular_disease.PeripheralVascularDiseaseMatcher","title":"<code>PeripheralVascularDiseaseMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.peripheral_vascular_disease</code> pipeline component extracts mentions of peripheral vascular disease.</p> Details of the used patterns <pre><code># fmt: off\nfrom ..terms import ASYMPTOMATIC, BRAIN, HEART, PERIPHERAL\n\nacronym = dict(\n    source=\"acronym\",\n    regex=[\n        r\"\\bAOMI\\b\",\n        r\"\\bACOM\\b\",\n        r\"\\bTAO\\b\",\n        r\"\\bSAPL\\b\",\n        r\"\\bOACR\\b\",\n        r\"\\bOVCR\\b\",\n        r\"\\bSCS\\b\",\n        r\"\\bTVP\\b\",\n        r\"\\bCAPS\\b\",\n        r\"\\bMTEV\\b\",\n        r\"\\bPTT\\b\",\n        r\"\\bMAT\\b\",\n        r\"\\bSHU\\b\",\n    ],\n    regex_attr=\"TEXT\",\n)\n\nother = dict(\n    source=\"other\",\n    regex=[\n        r\"\\bbuerger\",\n        r\"takayasu\",\n        r\"\\bhorton\",\n        r\"wegener\",\n        r\"churg.{1,10}strauss\",\n        r\"\\bsneddon\",\n        r\"budd.chiari\",\n        r\"infarctus.{1,5}(renal|splenique|polaire|pulmo)\",\n        r\"ulcere.{1,5}arter\",\n        r\"syndrome.?hemolytique.{1,8}uremique\",\n        r\"granulomatose.{1,10}polyangeite\",\n        r\"occlusion.{1,10}(artere|veine).{1,20}retine\",\n        r\"syndrome.{1,20}anti.?phospho\",\n        r\"embolie.{1,5}pulm\",\n    ],\n    regex_attr=\"NORM\",\n)\n\nwith_localization = dict(\n    source=\"with_localization\",\n    regex=[\n        r\"angiopathie\",\n        r\"arteriopathies.{1,5}obliterante\",\n        r\"gangren\",\n        r\"claudication\",\n        r\"dissection.{1,10}(aort|arter)\",\n        r\"tromboangeit\",\n        r\"tromboarterit\",\n        r\"(pontage|angioplastie).{1,10}(\\bfem|\\bpop|\\bren|\\bjamb)\",\n        r\"arterite\",\n        r\"(ischemie|infarctus).{1,10}mesenterique\",\n        r\"endarteriectomie\",\n        r\"vascularite\",\n        r\"occlusion.{1,10}terminaisons? carotid\",\n        r\"cryoglobulinemie\",\n        r\"colite.{1,5}ischemi\",\n        r\"embole.{1,10}cholesterol\",\n        r\"purpura.?thrombopenique.?idiopa\",\n        r\"micro.?angiopathie.?thrombotique\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART + ASYMPTOMATIC + [r\"inr\\srecommande\\ssous\\savk\"],\n            window=(-8, 8),\n            limit_to_sentence=False,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nthrombosis = dict(\n    source=\"thrombosis\",\n    regex=[\n        r\"thrombos\",\n        r\"thrombol[^y]\",\n        r\"thrombophi\",\n        r\"thrombi[^n]\",\n        r\"thrombus\",\n        r\"thrombectomi\",\n        r\"thrombo.?embo\",\n        r\"phlebit\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART + [\"superficiel\", \"\\biv\\b\", \"intra.?vein\"],\n            window=(-15, 15),\n            limit_to_sentence=False,\n        ),\n        dict(\n            regex=[\n                \"pre\",\n                \"anti\",\n                \"bilan\",\n            ],\n            window=-4,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\n\nischemia = dict(\n    source=\"ischemia\",\n    regex=[\n        r\"ischemi\",\n    ],\n    exclude=[\n        dict(\n            regex=BRAIN + HEART,\n            window=(-7, 7),\n        ),\n    ],\n    assign=[\n        dict(\n            name=\"peripheral\",\n            regex=\"(\" + r\"|\".join(PERIPHERAL) + \")\",\n            window=15,\n        ),\n    ],\n    regex_attr=\"NORM\",\n)\n\nep = dict(\n    source=\"ep\",\n    regex=r\"\\bEP(?![\\w\\./-])\",\n    regex_attr=\"TEXT\",\n    exclude=[\n        dict(\n            regex=[\n                r\"fibreux\",\n                r\"retin\",\n                r\"\\bfove\",\n                r\"\\boct\\b\",\n                r\"\\bmacula\",\n                r\"prosta\",\n                r\"\\bip\\b\",\n                r\"protocole\",\n                r\"seance\",\n                r\"echange\",\n                r\"ritux\",\n                r\"ivig\",\n                r\"ig.?iv\",\n                r\"\\bctc\",\n                r\"corticoide\",\n                r\"serum\",\n                r\"\\bcure\",\n                r\"plasma\",\n                r\"mensuel\",\n                r\"semaine\",\n                r\"serologi\",\n                r\"espaces.porte\",\n                r\"projet\",\n                r\"bolus\",\n            ],\n            window=(-25, 25),\n            limit_to_sentence=False,\n            regex_attr=\"NORM\",\n        ),\n        dict(\n            regex=[r\"rdv\", r\"les\", r\"des\", r\"angine\"],\n            window=(-3, 0),\n            regex_attr=\"NORM\",\n        ),\n    ],\n)\n\nhypertension = dict(\n    source=\"main\",\n    regex=[\n        r\"\\bhta\\b\",\n        r\"hyper.?tension.?arte\",\n        r\"hyper.?tendu\",\n        r\"hyper.?tension.?essenti\",\n        r\"hypertensi\",\n    ],\n    exclude=dict(\n        regex=\"(pulmo|porta)\",\n        window=3,\n    ),\n)\n\ndefault_patterns = [\n    acronym,\n    other,\n    with_localization,\n    thrombosis,\n    ep,\n    ischemia,\n    hypertension,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/peripheral_vascular_disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.peripheral_vascular_disease.PeripheralVascularDiseaseMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to <code>\"PRESENT\"</code></li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/peripheral_vascular_disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.peripheral_vascular_disease.PeripheralVascularDiseaseMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.peripheral_vascular_disease\")\n</code></pre> <p>Below are a few examples:</p> 12345678910111213 <pre><code>text = \"Un AOMI\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [AOMI]\n</code></pre> <pre><code>text = \"Pr\u00e9sence d'un infarctus r\u00e9nal\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [infarctus r\u00e9nal]\n</code></pre> <pre><code>text = \"Une angiopathie c\u00e9r\u00e9brale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une angiopathie\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [angiopathie]\n</code></pre> <pre><code>text = \"Une thrombose c\u00e9r\u00e9brale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une thrombose des veines superficielles\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une thrombose\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [thrombose]\n</code></pre> <pre><code>text = \"Effectuer un bilan pre-trombose\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Une isch\u00e9mie des MI est remarqu\u00e9e.\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [isch\u00e9mie des MI]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'peripheral': [MI]}\n</code></pre> <pre><code>text = \"Plusieurs cas d'EP\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [EP]\n</code></pre> <pre><code>text = \"Effectuer des cures d'EP\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Le patient est hypertendu\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: [hypertendu]\n</code></pre> <pre><code>text = \"Une hypertension portale\"\ndoc = nlp(text)\nspans = doc.spans[\"peripheral_vascular_disease\"]\n\nspans\n# Out: []\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/peripheral_vascular_disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.peripheral_vascular_disease.PeripheralVascularDiseaseMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.peripheral_vascular_disease</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'acronym', 'regex': ['\\\\bAOMI\\\\b', ...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>peripheral_vascular_disease</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'peripheral_vascular_disease': T...</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/peripheral_vascular_disease/peripheral_vascular_disease/#edsnlp.pipelines.ner.disorders.peripheral_vascular_disease.peripheral_vascular_disease.PeripheralVascularDiseaseMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.peripheral_vascular_disease</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/","title":"<code>edsnlp.pipelines.ner.disorders.solid_tumor</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/factory/","title":"<code>edsnlp.pipelines.ner.disorders.solid_tumor.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/factory/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component","title":"<code>create_component = Language.factory('eds.solid_tumor', assigns=['doc.ents', 'doc.spans'])(SolidTumorMatcher)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.solid_tumor</code> pipeline component extracts mentions of solid tumors. It will notably match:</p> Details of the used patterns <pre><code># fmt: off\nBENINE = r\"benign|benin|(grade.?\\b[i1]\\b)\"\nSTAGE = r\"stade ([^\\s]*)\"\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"carcinom(?!.{0,10}in.?situ)\",\n        r\"seminome\",\n        r\"(?&lt;!lympho)(?&lt;!lympho-)sarcome\",\n        r\"blastome\",\n        r\"cancer([^o]|\\s|\\b)\",\n        r\"adamantinome\",\n        r\"chordome\",\n        r\"craniopharyngiome\",\n        r\"melanome\",\n        r\"neoplasie\",\n        r\"neoplasme\",\n        r\"linite\",\n        r\"melanome\",\n        r\"mesoteliome\",\n        r\"mesotheliome\",\n        r\"seminome\",\n        r\"myxome\",\n        r\"paragangliome\",\n        r\"craniopharyngiome\",\n        r\"k .{0,5}(prostate|sein)\",\n        r\"pancoast.?tobias\",\n        r\"syndrome.{1,10}lynch\",\n        r\"li.?fraumeni\",\n        r\"germinome\",\n        r\"adeno[\\s-]?k\",\n        r\"thymome\",\n        r\"\\bnut\\b\",\n        r\"\\bgist\\b\",\n        r\"\\bchc\\b\",\n        r\"\\badk\\b\",\n        r\"\\btves\\b\",\n        r\"\\btv.tves\\b\",\n        r\"lesion.{1,20}tumor\",\n        r\"tumeur\",\n        r\"carcinoid\",\n        r\"histiocytome\",\n        r\"ependymome\",\n        # r\"primitif\", Trop de FP\n    ],\n    exclude=dict(\n        regex=BENINE,\n        window=(0, 5),\n    ),\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"metastasis\",\n            regex=r\"(metasta|multinodul)\",\n            window=(-3, 7),\n            reduce_mode=\"keep_last\",\n        ),\n        dict(\n            name=\"stage\",\n            regex=STAGE,\n            window=7,\n            reduce_mode=\"keep_last\",\n        ),\n    ],\n)\n\nmetastasis_pattern = dict(\n    source=\"metastasis\",\n    regex=[\n        r\"cellule.{1,5}tumorale.{1,5}circulantes\",\n        r\"metasta\",\n        r\"multinodul\",\n        r\"carcinose\",\n        r\"ruptures.{1,5}corticale\",\n        r\"envahissement.{0,15}parties\\smolle\",\n        r\"(localisation|lesion)s?.{0,20}second\",\n        r\"(lymphangite|meningite).{1,5}carcinomateuse\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=r\"goitre\",\n        window=-3,\n    ),\n)\n\ndefault_patterns = [\n    main_pattern,\n    metastasis_pattern,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/factory/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"METASTASIS\"</code> for tumors at the metastatic stage</li> <li><code>\"LOCALIZED\"</code> else</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>stage</code>: stage of the tumor</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/factory/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.solid_tumor\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Pr\u00e9sence d'un carcinome intra-h\u00e9patique.\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [carcinome]\n</code></pre> <pre><code>text = \"Patient avec un K sein.\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [K sein]\n</code></pre> <pre><code>text = \"Il y a une tumeur b\u00e9nigne\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Tumeur m\u00e9tastas\u00e9e\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Tumeur m\u00e9tastas\u00e9e]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n\nspan._.assigned\n# Out: {'metastasis': m\u00e9tastas\u00e9e}\n</code></pre> <pre><code>text = \"Cancer du poumon au stade 4\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Cancer du poumon au stade 4]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n\nspan._.assigned\n# Out: {'stage': 4}\n</code></pre> <pre><code>text = \"Cancer du poumon au stade 2\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Cancer du poumon au stade 2]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': 2}\n</code></pre> <pre><code>text = \"Pr\u00e9sence de nombreuses l\u00e9sions secondaires\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [l\u00e9sions secondaires]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/factory/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.solid_tumor</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['carcinom(?!.{0,1...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>solid_tumor</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'solid_tumor': True}</code> </p> <code>use_tnm</code> <p>Whether to use TNM scores matching as well</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/factory/#edsnlp.pipelines.ner.disorders.solid_tumor.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.solid_tumor</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/patterns/","title":"<code>edsnlp.pipelines.ner.disorders.solid_tumor.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/solid_tumor/","title":"<code>edsnlp.pipelines.ner.disorders.solid_tumor.solid_tumor</code>","text":"<p><code>eds.solid_tumor</code> pipeline</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/solid_tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.solid_tumor.SolidTumorMatcher","title":"<code>SolidTumorMatcher</code>","text":"<p>           Bases: <code>DisorderMatcher</code></p> <p>The <code>eds.solid_tumor</code> pipeline component extracts mentions of solid tumors. It will notably match:</p> Details of the used patterns <pre><code># fmt: off\nBENINE = r\"benign|benin|(grade.?\\b[i1]\\b)\"\nSTAGE = r\"stade ([^\\s]*)\"\n\nmain_pattern = dict(\n    source=\"main\",\n    regex=[\n        r\"carcinom(?!.{0,10}in.?situ)\",\n        r\"seminome\",\n        r\"(?&lt;!lympho)(?&lt;!lympho-)sarcome\",\n        r\"blastome\",\n        r\"cancer([^o]|\\s|\\b)\",\n        r\"adamantinome\",\n        r\"chordome\",\n        r\"craniopharyngiome\",\n        r\"melanome\",\n        r\"neoplasie\",\n        r\"neoplasme\",\n        r\"linite\",\n        r\"melanome\",\n        r\"mesoteliome\",\n        r\"mesotheliome\",\n        r\"seminome\",\n        r\"myxome\",\n        r\"paragangliome\",\n        r\"craniopharyngiome\",\n        r\"k .{0,5}(prostate|sein)\",\n        r\"pancoast.?tobias\",\n        r\"syndrome.{1,10}lynch\",\n        r\"li.?fraumeni\",\n        r\"germinome\",\n        r\"adeno[\\s-]?k\",\n        r\"thymome\",\n        r\"\\bnut\\b\",\n        r\"\\bgist\\b\",\n        r\"\\bchc\\b\",\n        r\"\\badk\\b\",\n        r\"\\btves\\b\",\n        r\"\\btv.tves\\b\",\n        r\"lesion.{1,20}tumor\",\n        r\"tumeur\",\n        r\"carcinoid\",\n        r\"histiocytome\",\n        r\"ependymome\",\n        # r\"primitif\", Trop de FP\n    ],\n    exclude=dict(\n        regex=BENINE,\n        window=(0, 5),\n    ),\n    regex_attr=\"NORM\",\n    assign=[\n        dict(\n            name=\"metastasis\",\n            regex=r\"(metasta|multinodul)\",\n            window=(-3, 7),\n            reduce_mode=\"keep_last\",\n        ),\n        dict(\n            name=\"stage\",\n            regex=STAGE,\n            window=7,\n            reduce_mode=\"keep_last\",\n        ),\n    ],\n)\n\nmetastasis_pattern = dict(\n    source=\"metastasis\",\n    regex=[\n        r\"cellule.{1,5}tumorale.{1,5}circulantes\",\n        r\"metasta\",\n        r\"multinodul\",\n        r\"carcinose\",\n        r\"ruptures.{1,5}corticale\",\n        r\"envahissement.{0,15}parties\\smolle\",\n        r\"(localisation|lesion)s?.{0,20}second\",\n        r\"(lymphangite|meningite).{1,5}carcinomateuse\",\n    ],\n    regex_attr=\"NORM\",\n    exclude=dict(\n        regex=r\"goitre\",\n        window=-3,\n    ),\n)\n\ndefault_patterns = [\n    main_pattern,\n    metastasis_pattern,\n]\n# fmt: on\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/solid_tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.solid_tumor.SolidTumorMatcher--extensions","title":"Extensions","text":"<p>On each span <code>span</code> that match, the following attributes are available:</p> <ul> <li><code>span._.detailed_status</code>: set to either<ul> <li><code>\"METASTASIS\"</code> for tumors at the metastatic stage</li> <li><code>\"LOCALIZED\"</code> else</li> </ul> </li> <li><code>span._.assigned</code>: dictionary with the following keys, if relevant:<ul> <li><code>stage</code>: stage of the tumor</li> </ul> </li> </ul>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/solid_tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.solid_tumor.SolidTumorMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\n    \"eds.normalizer\",\n    config=dict(\n        accents=True,\n        lowercase=True,\n        quotes=True,\n        spaces=True,\n        pollution=dict(\n            information=True,\n            bars=True,\n            biology=True,\n            doctors=True,\n            web=True,\n            coding=True,\n            footer=True,\n        ),\n    ),\n)\nnlp.add_pipe(f\"eds.solid_tumor\")\n</code></pre> <p>Below are a few examples:</p> 1234567 <pre><code>text = \"Pr\u00e9sence d'un carcinome intra-h\u00e9patique.\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [carcinome]\n</code></pre> <pre><code>text = \"Patient avec un K sein.\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [K sein]\n</code></pre> <pre><code>text = \"Il y a une tumeur b\u00e9nigne\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: []\n</code></pre> <pre><code>text = \"Tumeur m\u00e9tastas\u00e9e\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Tumeur m\u00e9tastas\u00e9e]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n\nspan._.assigned\n# Out: {'metastasis': m\u00e9tastas\u00e9e}\n</code></pre> <pre><code>text = \"Cancer du poumon au stade 4\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Cancer du poumon au stade 4]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n\nspan._.assigned\n# Out: {'stage': 4}\n</code></pre> <pre><code>text = \"Cancer du poumon au stade 2\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [Cancer du poumon au stade 2]\n\nspan = spans[0]\n\nspan._.assigned\n# Out: {'stage': 2}\n</code></pre> <pre><code>text = \"Pr\u00e9sence de nombreuses l\u00e9sions secondaires\"\ndoc = nlp(text)\nspans = doc.spans[\"solid_tumor\"]\n\nspans\n# Out: [l\u00e9sions secondaires]\n\nspan = spans[0]\n\nspan._.detailed_status\n# Out: METASTASIS\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/solid_tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.solid_tumor.SolidTumorMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.solid_tumor</code> </p> <code>patterns</code> <p>The patterns to use for matching</p> <p> TYPE: <code>Union[Dict[str, Any], List[Dict[str, Any]]]</code> DEFAULT: <code>[{'source': 'main', 'regex': ['carcinom(?!.{0,1...</code> </p> <code>label</code> <p>The label to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>solid_tumor</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'solid_tumor': True}</code> </p> <code>use_tnm</code> <p>Whether to use TNM scores matching as well</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/solid_tumor/solid_tumor/#edsnlp.pipelines.ner.disorders.solid_tumor.solid_tumor.SolidTumorMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.solid_tumor</code> component was developed by AP-HP's Data Science team with a team of medical experts. A paper describing in details the development of those components is being drafted and will soon be available.</p>"},{"location":"reference/edsnlp/pipelines/ner/disorders/terms/","title":"<code>edsnlp.pipelines.ner.disorders.terms</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/drugs/","title":"<code>edsnlp.pipelines.ner.drugs</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/drugs/factory/","title":"<code>edsnlp.pipelines.ner.drugs.factory</code>","text":"<ol><li><p><p>Cossin S., Lebrun L., Lobre G., Loustau R., Jouhet V., Griffier R., Mougin F., Diallo G. and Thiessard F., 2019. Romedi: An Open Data Source About French Drugs on the Semantic Web. {Studies in Health Technology and Informatics}. 264, pp.79-82. 10.3233/SHTI190187</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/ner/drugs/factory/#edsnlp.pipelines.ner.drugs.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.drugs</code> pipeline component detects mentions of French drugs (brand names and active ingredients) and adds them to <code>doc.ents</code>. Each drug is mapped to an ATC code through the Romedi terminology (Cossin et al., 2019). The ATC classifies drugs into groups.</p>"},{"location":"reference/edsnlp/pipelines/ner/drugs/factory/#edsnlp.pipelines.ner.drugs.factory.create_component--examples","title":"Examples","text":"<p>In this example, we are looking for an oral antidiabetic medication (ATC code: A10B).</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.drugs\", config=dict(term_matcher=\"exact\"))\n\ntext = \"Traitement habituel: Kard\u00e9gic, cardensiel (bisoprolol), glucophage, lasilix\"\n\ndoc = nlp(text)\n\ndrugs_detected = [(x.text, x.kb_id_) for x in doc.ents]\n\ndrugs_detected[0]\n# Out: ('Kard\u00e9gic', 'B01AC06')\n\nlen(drugs_detected)\n# Out: 5\n\noral_antidiabetics_detected = list(\n    filter(lambda x: (x[1].startswith(\"A10B\")), drugs_detected)\n)\noral_antidiabetics_detected\n# Out: [('glucophage', 'A10BA02')]\n</code></pre> <p>Glucophage is the brand name of a medication that contains metformine, the first-line medication for the treatment of type 2 diabetes.</p>"},{"location":"reference/edsnlp/pipelines/ner/drugs/factory/#edsnlp.pipelines.ner.drugs.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.drugs'</code> </p> <code>attr</code> <p>The default attribute to use for matching.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens (requires an upstream pipeline to mark excluded tokens).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The matcher to use for matching phrases ? One of (exact, simstring)</p> <p> TYPE: <code>Literal['exact', 'simstring']</code> DEFAULT: <code>'exact'</code> </p> <code>term_matcher_config</code> <p>Parameters of the matcher term matcher</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'drug'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'drug': True}</code> </p> RETURNS DESCRIPTION <code>TerminologyMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/drugs/factory/#edsnlp.pipelines.ner.drugs.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.drugs</code> pipeline was developed by the IAM team and CHU de Bordeaux's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/ner/drugs/patterns/","title":"<code>edsnlp.pipelines.ner.drugs.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/","title":"<code>edsnlp.pipelines.ner.scores</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/base_score/","title":"<code>edsnlp.pipelines.ner.scores.base_score</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/base_score/#edsnlp.pipelines.ner.scores.base_score.SimpleScoreMatcher","title":"<code>SimpleScoreMatcher</code>","text":"<p>           Bases: <code>ContextualMatcher</code></p> <p>Matcher component to extract a numeric score</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/base_score/#edsnlp.pipelines.ner.scores.base_score.SimpleScoreMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>label</code> <p>The name of the extracted score</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>None</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>score_name</code> <p>Deprecated, use <code>label</code> instead. The name of the extracted score</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>Optional[SpanSetterArg]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/scores/base_score/#edsnlp.pipelines.ner.scores.base_score.SimpleScoreMatcher.process","title":"<code>process</code>","text":"<p>Extracts, if available, the value of the score. Normalizes the score via the provided <code>self.score_normalization</code> method.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/base_score/#edsnlp.pipelines.ner.scores.base_score.SimpleScoreMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>Document to process</p> <p> TYPE: <code>Doc</code> </p> YIELDS DESCRIPTION <code>Span</code> <p>Matches with, if found, an added <code>score_value</code> extension</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/","title":"<code>edsnlp.pipelines.ner.scores.charlson</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/factory/","title":"<code>edsnlp.pipelines.ner.scores.charlson.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/factory/#edsnlp.pipelines.ner.scores.charlson.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.charlson</code> component extracts the Charlson Comorbidity Index.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/factory/#edsnlp.pipelines.ner.scores.charlson.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.charlson\")\n\ntext = \"\"\"\nCharlson \u00e0 l'admission: 7.\nCharlson:\nOMS:\n\"\"\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (Charlson \u00e0 l'admission: 7,)\n</code></pre> <p>We can see that only one occurrence was extracted. The second mention of Charlson in the text doesn't contain any numerical value, so it isn't extracted.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/factory/#edsnlp.pipelines.ner.scores.charlson.factory.create_component--extensions","title":"Extensions","text":"<p>Each extraction exposes 2 extensions:</p> <pre><code>ent = doc.ents[0]\n\nent._.score_name\n# Out: 'charlson'\n\nent._.score_value\n# Out: 7\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/factory/#edsnlp.pipelines.ner.scores.charlson.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'charlson'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'charlson': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/patterns/","title":"<code>edsnlp.pipelines.ner.scores.charlson.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/charlson/patterns/#edsnlp.pipelines.ner.scores.charlson.patterns.score_normalization","title":"<code>score_normalization</code>","text":"<p>Charlson score normalization. If available, returns the integer value of the Charlson score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/","title":"<code>edsnlp.pipelines.ner.scores.elston_ellis</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/factory/","title":"<code>edsnlp.pipelines.ner.scores.elston_ellis.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/factory/#edsnlp.pipelines.ner.scores.elston_ellis.factory.create_component","title":"<code>create_component</code>","text":"<p>Matcher for the Elston-Ellis score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/factory/#edsnlp.pipelines.ner.scores.elston_ellis.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.elston_ellis\")\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/factory/#edsnlp.pipelines.ner.scores.elston_ellis.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'TEXT'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'elston_ellis'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'elston_ellis': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/patterns/","title":"<code>edsnlp.pipelines.ner.scores.elston_ellis.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/elston_ellis/patterns/#edsnlp.pipelines.ner.scores.elston_ellis.patterns.score_normalization","title":"<code>score_normalization</code>","text":"<p>Elston and Ellis score normalization. If available, returns the integer value of the Elston and Ellis score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/","title":"<code>edsnlp.pipelines.ner.scores.emergency</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/","title":"<code>edsnlp.pipelines.ner.scores.emergency.ccmu</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/factory/","title":"<code>edsnlp.pipelines.ner.scores.emergency.ccmu.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/factory/#edsnlp.pipelines.ner.scores.emergency.ccmu.factory.create_component","title":"<code>create_component</code>","text":"<p>Matcher for explicit mentions of the French CCMU emergency score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/factory/#edsnlp.pipelines.ner.scores.emergency.ccmu.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.emergency_ccmu\")\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/factory/#edsnlp.pipelines.ner.scores.emergency.ccmu.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value otherwise</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emergency_ccmu'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'emergency_ccmu': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/patterns/","title":"<code>edsnlp.pipelines.ner.scores.emergency.ccmu.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/ccmu/patterns/#edsnlp.pipelines.ner.scores.emergency.ccmu.patterns.score_normalization","title":"<code>score_normalization</code>","text":"<p>CCMU score normalization. If available, returns the integer value of the CCMU score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/","title":"<code>edsnlp.pipelines.ner.scores.emergency.gemsa</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/factory/","title":"<code>edsnlp.pipelines.ner.scores.emergency.gemsa.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/factory/#edsnlp.pipelines.ner.scores.emergency.gemsa.factory.create_component","title":"<code>create_component</code>","text":"<p>Matcher for explicit mentions of the French GEMSA emergency score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/factory/#edsnlp.pipelines.ner.scores.emergency.gemsa.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.emergency_gemsa\")\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/factory/#edsnlp.pipelines.ner.scores.emergency.gemsa.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value otherwise</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emergency_gemsa'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'emergency_gemsa': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/patterns/","title":"<code>edsnlp.pipelines.ner.scores.emergency.gemsa.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/gemsa/patterns/#edsnlp.pipelines.ner.scores.emergency.gemsa.patterns.score_normalization","title":"<code>score_normalization</code>","text":"<p>GEMSA score normalization. If available, returns the integer value of the GEMSA score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/","title":"<code>edsnlp.pipelines.ner.scores.emergency.priority</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/factory/","title":"<code>edsnlp.pipelines.ner.scores.emergency.priority.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/factory/#edsnlp.pipelines.ner.scores.emergency.priority.factory.create_component","title":"<code>create_component</code>","text":"<p>Matcher for explicit mentions of the French priority emergency score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/factory/#edsnlp.pipelines.ner.scores.emergency.priority.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.emergency_priority\")\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/factory/#edsnlp.pipelines.ner.scores.emergency.priority.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emergency_priority'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'emergency_priority': True}</code> </p> RETURNS DESCRIPTION <code>SimpleScoreMatcher</code>"},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/patterns/","title":"<code>edsnlp.pipelines.ner.scores.emergency.priority.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/emergency/priority/patterns/#edsnlp.pipelines.ner.scores.emergency.priority.patterns.score_normalization","title":"<code>score_normalization</code>","text":"<p>Priority score normalization. If available, returns the integer value of the priority score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/factory/","title":"<code>edsnlp.pipelines.ner.scores.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/factory/#edsnlp.pipelines.ner.scores.factory.create_component","title":"<code>create_component = Language.factory('eds.score', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>Matcher component to extract a numeric score</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/factory/#edsnlp.pipelines.ner.scores.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>label</code> <p>The name of the extracted score</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>value_extract</code> <p>Regex with capturing group to get the score value</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex and should return:</p> <ul> <li>None if no score could be extracted</li> <li>The desired score value else</li> </ul> <p> TYPE: <code>Union[str, Callable[[Union[str, None]], Any]]</code> DEFAULT: <code>None</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens when matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Regex flags to use when matching</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>score_name</code> <p>Deprecated, use <code>label</code> instead. The name of the extracted score</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>Optional[SpanSetterArg]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/","title":"<code>edsnlp.pipelines.ner.scores.sofa</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/factory/","title":"<code>edsnlp.pipelines.ner.scores.sofa.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/factory/#edsnlp.pipelines.ner.scores.sofa.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.sofa</code> component extracts Sequential Organ Failure Assessment (SOFA) scores, used to track a person's status during the stay in an intensive care unit to determine the extent of a person's organ function or rate failure.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/factory/#edsnlp.pipelines.ner.scores.sofa.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sofa\")\n\ntext = \"\"\"\nSOFA (\u00e0 24H) : 12.\nOMS:\n\"\"\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (SOFA (\u00e0 24H) : 12,)\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/factory/#edsnlp.pipelines.ner.scores.sofa.factory.create_component--extensions","title":"Extensions","text":"<p>Each extraction exposes 3 extensions:</p> <pre><code>ent = doc.ents[0]\n\nent._.score_name\n# Out: 'sofa'\n\nent._.score_value\n# Out: 12\n\nent._.score_method\n# Out: '24H'\n</code></pre> <p>Score method can here be \"24H\", \"Maximum\", \"A l'admission\" or \"Non pr\u00e9cis\u00e9e\"</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/factory/#edsnlp.pipelines.ner.scores.sofa.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the component</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regex</code> <p>A list of regexes to identify the SOFA score</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>regex</code> </p> <code>attr</code> <p>Whether to match on the text ('TEXT') or on the normalized text ('CUSTOM_NORM')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'NORM'</code> </p> <code>value_extract</code> <p>Regex to extract the score value</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>value_extract</code> </p> <code>score_normalization</code> <p>Function that takes the \"raw\" value extracted from the <code>value_extract</code> regex, and should return - None if no score could be extracted - The desired score value else</p> <p> TYPE: <code>Callable[[Union[str, None]], Any]</code> DEFAULT: <code>score_normalization_str</code> </p> <code>window</code> <p>Number of token to include after the score's mention to find the score's value</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>ignore_excluded</code> <p>Whether to ignore excluded spans</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to ignore space tokens</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>flags</code> <p>Flags to pass to the regex</p> <p> TYPE: <code>Union[RegexFlag, int]</code> DEFAULT: <code>0</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'sofa'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'sofa': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/patterns/","title":"<code>edsnlp.pipelines.ner.scores.sofa.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/patterns/#edsnlp.pipelines.ner.scores.sofa.patterns.score_normalization","title":"<code>score_normalization</code>","text":"<p>Sofa score normalization. If available, returns the integer value of the SOFA score.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/sofa/","title":"<code>edsnlp.pipelines.ner.scores.sofa.sofa</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/sofa/#edsnlp.pipelines.ner.scores.sofa.sofa.SofaMatcher","title":"<code>SofaMatcher</code>","text":"<p>           Bases: <code>SimpleScoreMatcher</code></p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/sofa/#edsnlp.pipelines.ner.scores.sofa.sofa.SofaMatcher.process","title":"<code>process</code>","text":"<p>Extracts, if available, the value of the score. Normalizes the score via the provided <code>self.score_normalization</code> method.</p>"},{"location":"reference/edsnlp/pipelines/ner/scores/sofa/sofa/#edsnlp.pipelines.ner.scores.sofa.sofa.SofaMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>Document to process</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>ents</code> <p>List of spaCy's spans, with, if found, an added <code>score_value</code> extension</p> <p> TYPE: <code>List[Span]</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/","title":"<code>edsnlp.pipelines.ner.tnm</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/tnm/factory/","title":"<code>edsnlp.pipelines.ner.tnm.factory</code>","text":"<ol><li><p><p>Kempf E., Priou S., Lam\\'e G., Daniel C., Bellamine A., Sommacale D., Belkacemi y., Bey R., Galula G., Taright N., Tannier X., Rance B., Flicoteaux R., Hemery F., Audureau E., Chatellier G. and Tournigand C., 2022. Impact of two waves of Sars-Cov2 outbreak on the number, clinical presentation, care trajectories and survival of patients newly referred for a colorectal cancer: A French multicentric cohort study from a large group of University hospitals. {International Journal of Cancer}. 150, pp.1609-1618. 10.1002/ijc.33928</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/ner/tnm/factory/#edsnlp.pipelines.ner.tnm.factory.create_component","title":"<code>create_component = Language.factory('eds.tnm', assigns=['doc.ents', 'doc.spans'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.tnm</code> component extracts TNM mentions from clinical documents.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/factory/#edsnlp.pipelines.ner.tnm.factory.create_component--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.tnm\")\n\ntext = \"TNM: pTx N1 M1\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (pTx N1 M1,)\n\nent = doc.ents[0]\nent._.tnm.dict()\n# {'modifier': 'p',\n#  'tumour': None,\n#  'tumour_specification': 'x',\n#  'node': '1',\n#  'node_specification': None,\n#  'metastasis': '1',\n#  'resection_completeness': None,\n#  'version': None,\n#  'version_year': None}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/tnm/factory/#edsnlp.pipelines.ner.tnm.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.tnm</code> </p> <code>pattern</code> <p>The regex pattern to use for matching ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>(?:\\b|^)(?&lt;=\\(?(?P&lt;version&gt;uicc|accj|tnm|UICC|A...</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>tnm</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'tnm': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/factory/#edsnlp.pipelines.ner.tnm.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The TNM score is based on the development of S. Priou, B. Rance and E. Kempf (Kempf et al., 2022).</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/model/","title":"<code>edsnlp.pipelines.ner.tnm.model</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/tnm/model/#edsnlp.pipelines.ner.tnm.model.TNM","title":"<code>TNM</code>","text":"<p>           Bases: <code>BaseModel</code></p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/model/#edsnlp.pipelines.ner.tnm.model.TNM.dict","title":"<code>dict</code>","text":"<p>Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/patterns/","title":"<code>edsnlp.pipelines.ner.tnm.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/","title":"<code>edsnlp.pipelines.ner.tnm.tnm</code>","text":"<p><code>eds.tnm</code> pipeline.</p> <ol><li><p><p>Kempf E., Priou S., Lam\\'e G., Daniel C., Bellamine A., Sommacale D., Belkacemi y., Bey R., Galula G., Taright N., Tannier X., Rance B., Flicoteaux R., Hemery F., Audureau E., Chatellier G. and Tournigand C., 2022. Impact of two waves of Sars-Cov2 outbreak on the number, clinical presentation, care trajectories and survival of patients newly referred for a colorectal cancer: A French multicentric cohort study from a large group of University hospitals. {International Journal of Cancer}. 150, pp.1609-1618. 10.1002/ijc.33928</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher","title":"<code>TNMMatcher</code>","text":"<p>           Bases: <code>BaseNERComponent</code></p> <p>The <code>eds.tnm</code> component extracts TNM mentions from clinical documents.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher--examples","title":"Examples","text":"<pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.tnm\")\n\ntext = \"TNM: pTx N1 M1\"\n\ndoc = nlp(text)\ndoc.ents\n# Out: (pTx N1 M1,)\n\nent = doc.ents[0]\nent._.tnm.dict()\n# {'modifier': 'p',\n#  'tumour': None,\n#  'tumour_specification': 'x',\n#  'node': '1',\n#  'node_specification': None,\n#  'metastasis': '1',\n#  'resection_completeness': None,\n#  'version': None,\n#  'version_year': None}\n</code></pre>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object</p> <p> TYPE: <code>Optional[Language]</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>eds.tnm</code> </p> <code>pattern</code> <p>The regex pattern to use for matching ADICAP codes</p> <p> TYPE: <code>Optional[Union[List[str], str]]</code> DEFAULT: <code>(?:\\b|^)(?&lt;=\\(?(?P&lt;version&gt;uicc|accj|tnm|UICC|A...</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>TEXT</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>tnm</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'tnm': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher--authors-and-citation","title":"Authors and citation","text":"<p>The TNM score is based on the development of S. Priou, B. Rance and E. Kempf (Kempf et al., 2022).</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.set_extensions","title":"<code>set_extensions</code>","text":"<p>Set spaCy extensions</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.process","title":"<code>process</code>","text":"<p>Find TNM mentions in doc.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.process--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>spans</code> <p>list of tnm spans</p> <p> TYPE: <code>List[Span]</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.parse","title":"<code>parse</code>","text":"<p>Parse dates using the groupdict returned by the matcher.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.parse--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>spans</code> <p>List of tuples containing the spans and groupdict returned by the matcher.</p> <p> TYPE: <code>List[Tuple[Span, Dict[str, str]]]</code> </p> RETURNS DESCRIPTION <code>List[Span]</code> <p>List of processed spans, with the date parsed.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.__call__","title":"<code>__call__</code>","text":"<p>Tags TNM mentions.</p>"},{"location":"reference/edsnlp/pipelines/ner/tnm/tnm/#edsnlp.pipelines.ner.tnm.tnm.TNMMatcher.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy Doc object</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>doc</code> <p>spaCy Doc object, annotated for TNM</p> <p> TYPE: <code>Doc</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/umls/","title":"<code>edsnlp.pipelines.ner.umls</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/umls/factory/","title":"<code>edsnlp.pipelines.ner.umls.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/umls/factory/#edsnlp.pipelines.ner.umls.factory.create_component","title":"<code>create_component</code>","text":"<p>The <code>eds.umls</code> pipeline component matches the UMLS (Unified Medical Language System from NIH) terminology.</p> <p>Very low recall</p> <p>When using the <code>exact</code> matching mode, this component has a very poor recall performance. We can use the <code>simstring</code> mode to retrieve approximate matches, albeit at the cost of a significantly higher computation time.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/factory/#edsnlp.pipelines.ner.umls.factory.create_component--examples","title":"Examples","text":"<p><code>eds.umls</code> is an additional module that needs to be setup by:</p> <ol> <li><code>pip install -U umls_downloader</code></li> <li>Signing up for a UMLS Terminology    Services Account. After filling a short form, you will receive your token API    within a few days.</li> <li>Set <code>UMLS_API_KEY</code> locally: <code>export UMLS_API_KEY=your_api_key</code></li> </ol> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.umls\")\n\ntext = \"Grosse toux: le malade a \u00e9t\u00e9 mordu par des Amphibiens \" \"sous le genou\"\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (toux, a, par, Amphibiens, genou)\n\nent = doc.ents[0]\n\nent.label_\n# Out: umls\n\nent._.umls\n# Out: C0010200\n</code></pre> <p>You can easily change the default languages and sources with the <code>pattern_config</code> argument:</p> <pre><code>import spacy\n\n# Enable the French and English languages, through the French MeSH and LOINC\npattern_config = dict(languages=[\"FRE\", \"ENG\"], sources=[\"MSHFRE\", \"LNC\"])\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.umls\", config=dict(pattern_config=pattern_config))\n</code></pre> <p>See more options of languages and sources here.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/factory/#edsnlp.pipelines.ner.umls.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy <code>Language</code> object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The name of the pipe</p> <p> TYPE: <code>str</code> DEFAULT: <code>'eds.umls'</code> </p> <code>attr</code> <p>Attribute to match on, eg <code>TEXT</code>, <code>NORM</code>, etc.</p> <p> TYPE: <code>Union[str, Dict[str, str]]</code> DEFAULT: <code>'NORM'</code> </p> <code>ignore_excluded</code> <p>Whether to skip excluded tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_space_tokens</code> <p>Whether to skip space tokens during matching.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>term_matcher</code> <p>The term matcher to use, either \"exact\" or \"simstring\"</p> <p> TYPE: <code>TerminologyTermMatcher</code> DEFAULT: <code>'exact'</code> </p> <code>term_matcher_config</code> <p>The configuration for the term matcher</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>pattern_config</code> <p>The pattern retriever configuration</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>dict(languages=['FRE'], sources=None)</code> </p> <code>label</code> <p>Label name to use for the <code>Span</code> object and the extension</p> <p> TYPE: <code>str</code> DEFAULT: <code>'umls'</code> </p> <code>span_setter</code> <p>How to set matches on the doc</p> <p> TYPE: <code>SpanSetterArg</code> DEFAULT: <code>{'ents': True, 'umls': True}</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/umls/factory/#edsnlp.pipelines.ner.umls.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.umls</code> pipeline was developed by AP-HP's Data Science team and INRIA SODA's team.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/","title":"<code>edsnlp.pipelines.ner.umls.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_patterns","title":"<code>get_patterns</code>","text":"<p>Load the UMLS terminology patterns.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_patterns--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>config</code> <p>Languages and sources to select from the whole terminology. For both keys, None will select all values.</p> <p> TYPE: <code>dict[list]</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_patterns--return","title":"Return","text":"<p>patterns : dict[list]     The mapping between CUI codes and their synonyms.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_patterns--notes","title":"Notes","text":"<p>When run for the first time, this method will download the entire UMLS file and store it at ~/.data/bio/umls/2022AA/. Therefore the second run will be significantly faster than the first one.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_path","title":"<code>get_path</code>","text":"<p>Get the path, module and filename of the UMLS file.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_path--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>config</code> <p>Languages and sources to select from the whole terminology. For both keys, None will select all values.</p> <p> TYPE: <code>dict[list]</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_path--return","title":"Return","text":"<p>path, module, filename : pathlib.Path, pystow.module, str</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_path--notes","title":"Notes","text":"<p><code>get_path</code> will convert the config dict into a pretty filename.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.get_path--examples","title":"Examples","text":"<p>config = {\"languages\": [\"FRE\", \"ENG\"], \"sources\": None} print(get_path(config)) .data/bio/umls/2022AA/languagesFRE-ENG_sourcesNone.pkl\"</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.download_and_agg_umls","title":"<code>download_and_agg_umls</code>","text":"<p>Download the UMLS if not exist and create a mapping between CUI code and synonyms.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.download_and_agg_umls--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>config</code> <p>Languages and sources to select from the whole terminology. For both keys, None will select all values.</p> <p> TYPE: <code>dict[list]</code> </p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.download_and_agg_umls--return","title":"Return","text":"<p>patterns : dict[list]     The mapping between CUI codes and their synonyms.</p>"},{"location":"reference/edsnlp/pipelines/ner/umls/patterns/#edsnlp.pipelines.ner.umls.patterns.download_and_agg_umls--notes","title":"Notes","text":"<p>Performs filtering on the returned mapping only, not the downloaded resource.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/","title":"<code>edsnlp.pipelines.qualifiers</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/base/","title":"<code>edsnlp.pipelines.qualifiers.base</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/base/#edsnlp.pipelines.qualifiers.base.RuleBasedQualifier","title":"<code>RuleBasedQualifier</code>","text":"<p>           Bases: <code>BaseComponent</code></p> <p>Implements the NegEx algorithm.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/base/#edsnlp.pipelines.qualifiers.base.RuleBasedQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> </p> <code>on_ents_only</code> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> </p> <code>**terms</code> <p>Terms to look for.</p> <p> TYPE: <code>Dict[str, Optional[List[str]]]</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/base/#edsnlp.pipelines.qualifiers.base.RuleBasedQualifier.get_matches","title":"<code>get_matches</code>","text":"<p>Extract matches.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/base/#edsnlp.pipelines.qualifiers.base.RuleBasedQualifier.get_matches--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doc</code> <p>spaCy <code>Doc</code> object.</p> <p> TYPE: <code>Doc</code> </p> RETURNS DESCRIPTION <code>List[Span]</code> <p>List of detected spans</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/base/#edsnlp.pipelines.qualifiers.base.get_qualifier_extensions","title":"<code>get_qualifier_extensions</code>","text":"<p>Check for all qualifiers present in the pipe and return its corresponding extension</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/factories/","title":"<code>edsnlp.pipelines.qualifiers.factories</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/family/","title":"<code>edsnlp.pipelines.qualifiers.family</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/family/factory/","title":"<code>edsnlp.pipelines.qualifiers.family.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/family/factory/#edsnlp.pipelines.qualifiers.family.factory.create_component","title":"<code>create_component = Language.factory('eds.family', assigns=['span._.family'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.family</code> component uses a simple rule-based algorithm to detect spans that describe a family member (or family history) of the patient rather than the patient themself.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/factory/#edsnlp.pipelines.qualifiers.family.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks the family context of the extracted entities. It is complete, and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", osteoporose=\"ost\u00e9oporose\")),\n)\nnlp.add_pipe(\"eds.family\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Il a des ant\u00e9c\u00e9dents familiaux d'ost\u00e9oporose\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, ost\u00e9oporose)\n\ndoc.ents[0]._.family\n# Out: False\n\ndoc.ents[1]._.family\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/factory/#edsnlp.pipelines.qualifiers.family.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.family</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>family</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token relates to a family member.</li> <li>The <code>family_</code> property is a human-readable string, computed from the <code>family</code>    attribute. It implements a simple getter function that outputs <code>PATIENT</code> or    <code>FAMILY</code>, depending on the value of <code>family</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/factory/#edsnlp.pipelines.qualifiers.family.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.family</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>family</code> <p>List of terms indicating family reference.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of syntagms termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_sections</code> <p>Whether to use annotated sections (namely <code>ant\u00e9c\u00e9dents familiaux</code>).</p> <p> TYPE: <code>bool, by default `False`</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/factory/#edsnlp.pipelines.qualifiers.family.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.family</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/family/","title":"<code>edsnlp.pipelines.qualifiers.family.family</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/family/family/#edsnlp.pipelines.qualifiers.family.family.FamilyContextQualifier","title":"<code>FamilyContextQualifier</code>","text":"<p>           Bases: <code>RuleBasedQualifier</code></p> <p>The <code>eds.family</code> component uses a simple rule-based algorithm to detect spans that describe a family member (or family history) of the patient rather than the patient themself.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/family/#edsnlp.pipelines.qualifiers.family.family.FamilyContextQualifier--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks the family context of the extracted entities. It is complete, and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", osteoporose=\"ost\u00e9oporose\")),\n)\nnlp.add_pipe(\"eds.family\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Il a des ant\u00e9c\u00e9dents familiaux d'ost\u00e9oporose\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, ost\u00e9oporose)\n\ndoc.ents[0]._.family\n# Out: False\n\ndoc.ents[1]._.family\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/family/#edsnlp.pipelines.qualifiers.family.family.FamilyContextQualifier--extensions","title":"Extensions","text":"<p>The <code>eds.family</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>family</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token relates to a family member.</li> <li>The <code>family_</code> property is a human-readable string, computed from the <code>family</code>    attribute. It implements a simple getter function that outputs <code>PATIENT</code> or    <code>FAMILY</code>, depending on the value of <code>family</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/family/#edsnlp.pipelines.qualifiers.family.family.FamilyContextQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.family</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>family</code> <p>List of terms indicating family reference.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of syntagms termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_sections</code> <p>Whether to use annotated sections (namely <code>ant\u00e9c\u00e9dents familiaux</code>).</p> <p> TYPE: <code>bool, by default `False`</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/family/#edsnlp.pipelines.qualifiers.family.family.FamilyContextQualifier--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.family</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/family/patterns/","title":"<code>edsnlp.pipelines.qualifiers.family.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/history/","title":"<code>edsnlp.pipelines.qualifiers.history</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/history/factory/","title":"<code>edsnlp.pipelines.qualifiers.history.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/history/factory/#edsnlp.pipelines.qualifiers.history.factory.create_component","title":"<code>create_component = Language.factory('eds.history', assigns=['span._.history'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.history</code> pipeline uses a simple rule-based algorithm to detect spans that describe medical history rather than the diagnostic of a given visit.</p> <p>The mere definition of a medical history is not straightforward. Hence, this component only tags entities that are explicitly described as part of the medical history, e.g., preceded by a synonym of \"medical history\".</p> <p>This component may also use the output of:</p> <ul> <li>the <code>eds.sections</code> component. In that case, the entire <code>ant\u00e9c\u00e9dent</code> section is tagged as a medical history.</li> </ul> <p>Sections</p> <p>Be careful, the <code>eds.sections</code> component may oversize the <code>ant\u00e9c\u00e9dents</code> section. Indeed, it detects section titles and tags the entire text between a title and the next as a section. Hence, should a section title goes undetected after the <code>ant\u00e9c\u00e9dents</code> title, some parts of the document will erroneously be tagged as a medical history.</p> <p>To curb that possibility, using the output of the <code>eds.sections</code> component is deactivated by default.</p> <ul> <li>the <code>eds.dates</code> component. In that case, it will take the   dates into account to tag extracted entities as a medical history or not.</li> </ul> <p>Dates</p> <p>To take the most of the <code>eds.dates</code> component, you may add the <code>note_datetime</code> context (cf. Adding context). It allows the component to compute the duration of absolute dates (e.g., le 28 ao\u00fbt 2022/August 28, 2022). The <code>birth_datetime</code> context allows the component to exclude the birthdate from the extracted dates.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/factory/#edsnlp.pipelines.qualifiers.history.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are history or not. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\nnlp.add_pipe(\"eds.dates\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", malaise=\"malaises\")),\n)\nnlp.add_pipe(\n    \"eds.history\",\n    config=dict(\n        use_sections=True,\n        use_dates=True,\n    ),\n)\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Il a des ant\u00e9c\u00e9dents de malaises.\"\n    \"ANT\u00c9C\u00c9DENTS : \"\n    \"- le patient a d\u00e9j\u00e0 eu des malaises. \"\n    \"- le patient a eu une douleur \u00e0 la jambe il y a 10 jours\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, malaises, malaises, douleur)\n\ndoc.ents[0]._.history\n# Out: False\n\ndoc.ents[1]._.history\n# Out: True\n\ndoc.ents[2]._.history  # (1)\n# Out: True\n\ndoc.ents[3]._.history  # (2)\n# Out: False\n</code></pre> <ol> <li>The entity is in the section <code>ant\u00e9c\u00e9dent</code>.</li> <li>The entity is in the section <code>ant\u00e9c\u00e9dent</code>, however the extracted <code>relative_date</code> refers to an event that took place within 14 days.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/factory/#edsnlp.pipelines.qualifiers.history.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.history</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>history</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is a medical history.</li> <li>The <code>history_</code> property is a human-readable string, computed from the <code>history</code>    attribute. It implements a simple getter function that outputs <code>CURRENT</code> or    <code>ATCD</code>, depending on the value of <code>history</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/factory/#edsnlp.pipelines.qualifiers.history.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.history</code> </p> <code>history</code> <p>List of terms indicating medical history reference.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of syntagms termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>use_sections</code> <p>Whether to use section pipeline to detect medical history section.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_dates</code> <p>Whether to use dates pipeline to detect if the event occurs  a long time before the document date.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>history_limit</code> <p>The number of days after which the event is considered as history.</p> <p> TYPE: <code>Union[int, timedelta]</code> DEFAULT: <code>14</code> </p> <code>exclude_birthdate</code> <p>Whether to exclude the birthdate from history dates.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>closest_dates_only</code> <p>Whether to include the closest dates only.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/factory/#edsnlp.pipelines.qualifiers.history.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.history</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/history/","title":"<code>edsnlp.pipelines.qualifiers.history.history</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/history/history/#edsnlp.pipelines.qualifiers.history.history.HistoryQualifier","title":"<code>HistoryQualifier</code>","text":"<p>           Bases: <code>RuleBasedQualifier</code></p> <p>The <code>eds.history</code> pipeline uses a simple rule-based algorithm to detect spans that describe medical history rather than the diagnostic of a given visit.</p> <p>The mere definition of a medical history is not straightforward. Hence, this component only tags entities that are explicitly described as part of the medical history, e.g., preceded by a synonym of \"medical history\".</p> <p>This component may also use the output of:</p> <ul> <li>the <code>eds.sections</code> component. In that case, the entire <code>ant\u00e9c\u00e9dent</code> section is tagged as a medical history.</li> </ul> <p>Sections</p> <p>Be careful, the <code>eds.sections</code> component may oversize the <code>ant\u00e9c\u00e9dents</code> section. Indeed, it detects section titles and tags the entire text between a title and the next as a section. Hence, should a section title goes undetected after the <code>ant\u00e9c\u00e9dents</code> title, some parts of the document will erroneously be tagged as a medical history.</p> <p>To curb that possibility, using the output of the <code>eds.sections</code> component is deactivated by default.</p> <ul> <li>the <code>eds.dates</code> component. In that case, it will take the   dates into account to tag extracted entities as a medical history or not.</li> </ul> <p>Dates</p> <p>To take the most of the <code>eds.dates</code> component, you may add the <code>note_datetime</code> context (cf. Adding context). It allows the component to compute the duration of absolute dates (e.g., le 28 ao\u00fbt 2022/August 28, 2022). The <code>birth_datetime</code> context allows the component to exclude the birthdate from the extracted dates.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/history/#edsnlp.pipelines.qualifiers.history.history.HistoryQualifier--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are history or not. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\nnlp.add_pipe(\"eds.normalizer\")\nnlp.add_pipe(\"eds.sections\")\nnlp.add_pipe(\"eds.dates\")\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", malaise=\"malaises\")),\n)\nnlp.add_pipe(\n    \"eds.history\",\n    config=dict(\n        use_sections=True,\n        use_dates=True,\n    ),\n)\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Il a des ant\u00e9c\u00e9dents de malaises.\"\n    \"ANT\u00c9C\u00c9DENTS : \"\n    \"- le patient a d\u00e9j\u00e0 eu des malaises. \"\n    \"- le patient a eu une douleur \u00e0 la jambe il y a 10 jours\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, malaises, malaises, douleur)\n\ndoc.ents[0]._.history\n# Out: False\n\ndoc.ents[1]._.history\n# Out: True\n\ndoc.ents[2]._.history  # (1)\n# Out: True\n\ndoc.ents[3]._.history  # (2)\n# Out: False\n</code></pre> <ol> <li>The entity is in the section <code>ant\u00e9c\u00e9dent</code>.</li> <li>The entity is in the section <code>ant\u00e9c\u00e9dent</code>, however the extracted <code>relative_date</code> refers to an event that took place within 14 days.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/history/#edsnlp.pipelines.qualifiers.history.history.HistoryQualifier--extensions","title":"Extensions","text":"<p>The <code>eds.history</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>history</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is a medical history.</li> <li>The <code>history_</code> property is a human-readable string, computed from the <code>history</code>    attribute. It implements a simple getter function that outputs <code>CURRENT</code> or    <code>ATCD</code>, depending on the value of <code>history</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/history/#edsnlp.pipelines.qualifiers.history.history.HistoryQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.history</code> </p> <code>history</code> <p>List of terms indicating medical history reference.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of syntagms termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>use_sections</code> <p>Whether to use section pipeline to detect medical history section.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_dates</code> <p>Whether to use dates pipeline to detect if the event occurs  a long time before the document date.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>history_limit</code> <p>The number of days after which the event is considered as history.</p> <p> TYPE: <code>Union[int, timedelta]</code> DEFAULT: <code>14</code> </p> <code>exclude_birthdate</code> <p>Whether to exclude the birthdate from history dates.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>closest_dates_only</code> <p>Whether to include the closest dates only.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/history/#edsnlp.pipelines.qualifiers.history.history.HistoryQualifier--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.history</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/history/patterns/","title":"<code>edsnlp.pipelines.qualifiers.history.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/","title":"<code>edsnlp.pipelines.qualifiers.hypothesis</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/","title":"<code>edsnlp.pipelines.qualifiers.hypothesis.factory</code>","text":"<ol><li><p><p>Dalloux C., Claveau V. and Grabar N., 2017. D\u00e9tection de la n\u00e9gation : corpus fran\u00e7ais et apprentissage supervis\u00e9.</p></p></li><li><p><p>Grabar N., Claveau V. and Dalloux C., 2018. CAS: French Corpus with Clinical Cases.</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component","title":"<code>create_component = Language.factory('eds.hypothesis', assigns=['span._.hypothesis'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.hypothesis</code> pipeline uses a simple rule-based algorithm to detect spans that are speculations rather than certain statements.</p> <p>The component looks for five kinds of expressions in the text :</p> <ul> <li>preceding hypothesis, ie cues that precede a hypothetical expression</li> <li>following hypothesis, ie cues that follow a hypothetical expression</li> <li>pseudo hypothesis : contain a hypothesis cue, but are not hypothesis   (eg \"pas de doute\"/\"no doubt\")</li> <li>hypothetical verbs : verbs indicating hypothesis (eg \"douter\")</li> <li>classic verbs conjugated to the conditional, thus indicating hypothesis</li> </ul>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are part of a speculation. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", fracture=\"fracture\")),\n)\nnlp.add_pipe(\"eds.hypothesis\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Possible fracture du radius.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, fracture)\n\ndoc.ents[0]._.hypothesis\n# Out: False\n\ndoc.ents[1]._.hypothesis\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.hypothesis</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>hypothesis</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is a speculation.</li> <li>The <code>hypothesis_</code> property is a human-readable string, computed from the    <code>hypothesis</code> attribute. It implements a simple getter function that outputs    <code>HYP</code> or <code>CERT</code>, depending on the value of <code>hypothesis</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--performance","title":"Performance","text":"<p>The component's performance is measured on three datasets :</p> <ul> <li>The ESSAI (Dalloux et al., 2017) and CAS (Grabar et al., 2018) datasets were developed   at the CNRS. The two are concatenated.</li> <li>The NegParHyp corpus was specifically developed at APHP's CDW to test the   component on actual clinical notes, using pseudonymised notes from the APHP's CDW.</li> </ul> Dataset Hypothesis F1 CAS/ESSAI 49% NegParHyp 52% <p>NegParHyp corpus</p> <p>The NegParHyp corpus was built by matching a subset of the MeSH terminology with around 300 documents from AP-HP's clinical data warehouse. Matched entities were then labelled for negation, speculation and family context.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.hypothesis</code> </p> <code>attr</code> <p>spaCy's attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>pseudo</code> <p>List of pseudo hypothesis cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of preceding hypothesis cues</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of following hypothesis cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs_hyp</code> <p>List of hypothetical verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs_eds</code> <p>List of mainstream verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr'</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/factory/#edsnlp.pipelines.qualifiers.hypothesis.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.hypothesis</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/","title":"<code>edsnlp.pipelines.qualifiers.hypothesis.hypothesis</code>","text":"<ol><li><p><p>Dalloux C., Claveau V. and Grabar N., 2017. D\u00e9tection de la n\u00e9gation : corpus fran\u00e7ais et apprentissage supervis\u00e9.</p></p></li><li><p><p>Grabar N., Claveau V. and Dalloux C., 2018. CAS: French Corpus with Clinical Cases.</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier","title":"<code>HypothesisQualifier</code>","text":"<p>           Bases: <code>RuleBasedQualifier</code></p> <p>The <code>eds.hypothesis</code> pipeline uses a simple rule-based algorithm to detect spans that are speculations rather than certain statements.</p> <p>The component looks for five kinds of expressions in the text :</p> <ul> <li>preceding hypothesis, ie cues that precede a hypothetical expression</li> <li>following hypothesis, ie cues that follow a hypothetical expression</li> <li>pseudo hypothesis : contain a hypothesis cue, but are not hypothesis   (eg \"pas de doute\"/\"no doubt\")</li> <li>hypothetical verbs : verbs indicating hypothesis (eg \"douter\")</li> <li>classic verbs conjugated to the conditional, thus indicating hypothesis</li> </ul>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are part of a speculation. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(douleur=\"douleur\", fracture=\"fracture\")),\n)\nnlp.add_pipe(\"eds.hypothesis\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Possible fracture du radius.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (douleur, fracture)\n\ndoc.ents[0]._.hypothesis\n# Out: False\n\ndoc.ents[1]._.hypothesis\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier--extensions","title":"Extensions","text":"<p>The <code>eds.hypothesis</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>hypothesis</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is a speculation.</li> <li>The <code>hypothesis_</code> property is a human-readable string, computed from the    <code>hypothesis</code> attribute. It implements a simple getter function that outputs    <code>HYP</code> or <code>CERT</code>, depending on the value of <code>hypothesis</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier--performance","title":"Performance","text":"<p>The component's performance is measured on three datasets :</p> <ul> <li>The ESSAI (Dalloux et al., 2017) and CAS (Grabar et al., 2018) datasets were developed   at the CNRS. The two are concatenated.</li> <li>The NegParHyp corpus was specifically developed at APHP's CDW to test the   component on actual clinical notes, using pseudonymised notes from the APHP's CDW.</li> </ul> Dataset Hypothesis F1 CAS/ESSAI 49% NegParHyp 52% <p>NegParHyp corpus</p> <p>The NegParHyp corpus was built by matching a subset of the MeSH terminology with around 300 documents from AP-HP's clinical data warehouse. Matched entities were then labelled for negation, speculation and family context.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.hypothesis</code> </p> <code>attr</code> <p>spaCy's attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>pseudo</code> <p>List of pseudo hypothesis cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of preceding hypothesis cues</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of following hypothesis cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs_hyp</code> <p>List of hypothetical verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs_eds</code> <p>List of mainstream verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr'</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.hypothesis</code> pipeline was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier.load_verbs","title":"<code>load_verbs</code>","text":"<p>Conjugate \"classic\" verbs to conditional, and add hypothesis verbs conjugated to all tenses.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/hypothesis/#edsnlp.pipelines.qualifiers.hypothesis.hypothesis.HypothesisQualifier.load_verbs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verbs_hyp</code> <p> TYPE: <code>List[str]</code> </p> <code>verbs_eds</code> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>list of hypothesis verbs conjugated at all tenses and classic</code> <code>verbs conjugated to conditional.</code>"},{"location":"reference/edsnlp/pipelines/qualifiers/hypothesis/patterns/","title":"<code>edsnlp.pipelines.qualifiers.hypothesis.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/negation/","title":"<code>edsnlp.pipelines.qualifiers.negation</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/","title":"<code>edsnlp.pipelines.qualifiers.negation.factory</code>","text":"<ol><li><p><p>Chapman W.W., Bridewell W., Hanbury P., Cooper G.F. and Buchanan B.G., 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics. 34, pp.301--310. 10.1006/jbin.2001.1029</p></p></li><li><p><p>Dalloux C., Claveau V. and Grabar N., 2017. D\u00e9tection de la n\u00e9gation : corpus fran\u00e7ais et apprentissage supervis\u00e9.</p></p></li><li><p><p>Grabar N., Claveau V. and Dalloux C., 2018. CAS: French Corpus with Clinical Cases.</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/#edsnlp.pipelines.qualifiers.negation.factory.create_component","title":"<code>create_component = Language.factory('eds.negation', assigns=['span._.negation'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.negation</code> component uses a simple rule-based algorithm to detect negated spans. It was designed at AP-HP's EDS, following the insights of the NegEx algorithm by Chapman et al., 2001.</p> <p>The component looks for five kinds of expressions in the text :</p> <ul> <li>preceding negations, i.e., cues that precede a negated expression</li> <li>following negations, i.e., cues that follow a negated expression</li> <li>pseudo negations : contain a negation cue, but are not negations   (eg \"pas de doute\"/\"no doubt\")</li> <li>negation verbs, i.e., verbs that indicate a negation</li> <li>terminations, i.e., words that delimit propositions.   The negation spans from the preceding cue to the termination.</li> </ul>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/#edsnlp.pipelines.qualifiers.negation.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks the polarity of the extracted entities. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(patient=\"patient\", fracture=\"fracture\")),\n)\nnlp.add_pipe(\"eds.negation\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Le scanner ne d\u00e9tecte aucune fracture.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (patient, fracture)\n\ndoc.ents[0]._.negation  # (1)\n# Out: False\n\ndoc.ents[1]._.negation\n# Out: True\n</code></pre> <ol> <li>The result of the component is kept in the <code>negation</code> custom extension.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/#edsnlp.pipelines.qualifiers.negation.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.negation</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>negation</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is negated.</li> <li>The <code>negation_</code> property is a human-readable string, computed from the <code>negation</code>    attribute. It implements a simple getter function that outputs <code>AFF</code> or <code>NEG</code>,    depending on the value of <code>negation</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/#edsnlp.pipelines.qualifiers.negation.factory.create_component--performance","title":"Performance","text":"<p>The component's performance is measured on three datasets :</p> <ul> <li>The ESSAI (Dalloux et al., 2017) and CAS (Grabar et al., 2018) datasets were developed   at the CNRS. The two are concatenated.</li> <li>The NegParHyp corpus was specifically developed at AP-HP to test the component   on actual clinical notes, using pseudonymised notes from the AP-HP.</li> </ul> Dataset Negation F1 CAS/ESSAI 71% NegParHyp 88% <p>NegParHyp corpus</p> <p>The NegParHyp corpus was built by matching a subset of the MeSH terminology with around 300 documents from AP-HP's clinical data warehouse. Matched entities were then labelled for negation, speculation and family context.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/#edsnlp.pipelines.qualifiers.negation.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.negation</code> </p> <code>attr</code> <p>spaCy's attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>pseudo</code> <p>List of pseudo negation cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of preceding negation cues</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of following negation cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs</code> <p>List of negation verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/factory/#edsnlp.pipelines.qualifiers.negation.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.negation</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/","title":"<code>edsnlp.pipelines.qualifiers.negation.negation</code>","text":"<ol><li><p><p>Chapman W.W., Bridewell W., Hanbury P., Cooper G.F. and Buchanan B.G., 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics. 34, pp.301--310. 10.1006/jbin.2001.1029</p></p></li><li><p><p>Dalloux C., Claveau V. and Grabar N., 2017. D\u00e9tection de la n\u00e9gation : corpus fran\u00e7ais et apprentissage supervis\u00e9.</p></p></li><li><p><p>Grabar N., Claveau V. and Dalloux C., 2018. CAS: French Corpus with Clinical Cases.</p></p></li></ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier","title":"<code>NegationQualifier</code>","text":"<p>           Bases: <code>RuleBasedQualifier</code></p> <p>The <code>eds.negation</code> component uses a simple rule-based algorithm to detect negated spans. It was designed at AP-HP's EDS, following the insights of the NegEx algorithm by Chapman et al., 2001.</p> <p>The component looks for five kinds of expressions in the text :</p> <ul> <li>preceding negations, i.e., cues that precede a negated expression</li> <li>following negations, i.e., cues that follow a negated expression</li> <li>pseudo negations : contain a negation cue, but are not negations   (eg \"pas de doute\"/\"no doubt\")</li> <li>negation verbs, i.e., verbs that indicate a negation</li> <li>terminations, i.e., words that delimit propositions.   The negation spans from the preceding cue to the termination.</li> </ul>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks the polarity of the extracted entities. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(patient=\"patient\", fracture=\"fracture\")),\n)\nnlp.add_pipe(\"eds.negation\")\n\ntext = (\n    \"Le patient est admis le 23 ao\u00fbt 2021 pour une douleur au bras. \"\n    \"Le scanner ne d\u00e9tecte aucune fracture.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (patient, fracture)\n\ndoc.ents[0]._.negation  # (1)\n# Out: False\n\ndoc.ents[1]._.negation\n# Out: True\n</code></pre> <ol> <li>The result of the component is kept in the <code>negation</code> custom extension.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier--extensions","title":"Extensions","text":"<p>The <code>eds.negation</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>negation</code> attribute is a boolean, set to <code>True</code> if the component predicts    that the span/token is negated.</li> <li>The <code>negation_</code> property is a human-readable string, computed from the <code>negation</code>    attribute. It implements a simple getter function that outputs <code>AFF</code> or <code>NEG</code>,    depending on the value of <code>negation</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier--performance","title":"Performance","text":"<p>The component's performance is measured on three datasets :</p> <ul> <li>The ESSAI (Dalloux et al., 2017) and CAS (Grabar et al., 2018) datasets were developed   at the CNRS. The two are concatenated.</li> <li>The NegParHyp corpus was specifically developed at AP-HP to test the component   on actual clinical notes, using pseudonymised notes from the AP-HP.</li> </ul> Dataset Negation F1 CAS/ESSAI 71% NegParHyp 88% <p>NegParHyp corpus</p> <p>The NegParHyp corpus was built by matching a subset of the MeSH terminology with around 300 documents from AP-HP's clinical data warehouse. Matched entities were then labelled for negation, speculation and family context.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The pipeline object.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.negation</code> </p> <code>attr</code> <p>spaCy's attribute to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>pseudo</code> <p>List of pseudo negation cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of preceding negation cues</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of following negation cues.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>verbs</code> <p>List of negation verbs.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>termination</code> <p>List of termination terms.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Deprecated, use <code>span_getter</code> instead.</p> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.negation</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier.load_verbs","title":"<code>load_verbs</code>","text":"<p>Conjugate negating verbs to specific tenses.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/negation/#edsnlp.pipelines.qualifiers.negation.negation.NegationQualifier.load_verbs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verbs</code> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>list_neg_verbs_preceding</code> <p> TYPE: <code>List of conjugated negating verbs preceding entities.</code> </p> <code>list_neg_verbs_following</code> <p> TYPE: <code>List of conjugated negating verbs following entities.</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/negation/patterns/","title":"<code>edsnlp.pipelines.qualifiers.negation.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/","title":"<code>edsnlp.pipelines.qualifiers.reported_speech</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/factory/","title":"<code>edsnlp.pipelines.qualifiers.reported_speech.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/factory/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component","title":"<code>create_component = Language.factory('eds.reported_speech', assigns=['span._.reported_speech'])(create_component)</code>  <code>module-attribute</code>","text":"<p>The <code>eds.reported_speech</code> component uses a simple rule-based algorithm to detect spans that relate to reported speech (eg when the doctor quotes the patient). It was designed at AP-HP's EDS.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/factory/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are part of a reported speech. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(patient=\"patient\", alcool=\"alcoolis\u00e9\")),\n)\nnlp.add_pipe(\"eds.reported_speech\")\n\ntext = (\n    \"Le patient est admis aux urgences ce soir pour une douleur au bras. \"\n    \"Il nie \u00eatre alcoolis\u00e9.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (patient, alcoolis\u00e9)\n\ndoc.ents[0]._.reported_speech\n# Out: False\n\ndoc.ents[1]._.reported_speech\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/factory/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--extensions","title":"Extensions","text":"<p>The <code>eds.reported_speech</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>reported_speech</code> attribute is a boolean, set to <code>True</code> if the component    predicts that the span/token is reported.</li> <li>The <code>reported_speech_</code> property is a human-readable string, computed from the    <code>reported_speech</code> attribute. It implements a simple getter function that outputs    <code>DIRECT</code> or <code>REPORTED</code>, depending on the value of <code>reported_speech</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/factory/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.reported_speech</code> </p> <code>quotation</code> <p>String gathering all quotation cues.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>verbs</code> <p>List of reported speech verbs.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of terms following a reported speech.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of terms preceding a reported speech.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/factory/#edsnlp.pipelines.qualifiers.reported_speech.factory.create_component--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.reported_speech</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/patterns/","title":"<code>edsnlp.pipelines.qualifiers.reported_speech.patterns</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/","title":"<code>edsnlp.pipelines.qualifiers.reported_speech.reported_speech</code>","text":""},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier","title":"<code>ReportedSpeechQualifier</code>","text":"<p>           Bases: <code>RuleBasedQualifier</code></p> <p>The <code>eds.reported_speech</code> component uses a simple rule-based algorithm to detect spans that relate to reported speech (eg when the doctor quotes the patient). It was designed at AP-HP's EDS.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier--examples","title":"Examples","text":"<p>The following snippet matches a simple terminology, and checks whether the extracted entities are part of a reported speech. It is complete and can be run as is.</p> <pre><code>import spacy\n\nnlp = spacy.blank(\"eds\")\nnlp.add_pipe(\"eds.sentences\")\n# Dummy matcher\nnlp.add_pipe(\n    \"eds.matcher\",\n    config=dict(terms=dict(patient=\"patient\", alcool=\"alcoolis\u00e9\")),\n)\nnlp.add_pipe(\"eds.reported_speech\")\n\ntext = (\n    \"Le patient est admis aux urgences ce soir pour une douleur au bras. \"\n    \"Il nie \u00eatre alcoolis\u00e9.\"\n)\n\ndoc = nlp(text)\n\ndoc.ents\n# Out: (patient, alcoolis\u00e9)\n\ndoc.ents[0]._.reported_speech\n# Out: False\n\ndoc.ents[1]._.reported_speech\n# Out: True\n</code></pre>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier--extensions","title":"Extensions","text":"<p>The <code>eds.reported_speech</code> component declares two extensions, on both <code>Span</code> and <code>Token</code> objects :</p> <ol> <li>The <code>reported_speech</code> attribute is a boolean, set to <code>True</code> if the component    predicts that the span/token is reported.</li> <li>The <code>reported_speech_</code> property is a human-readable string, computed from the    <code>reported_speech</code> attribute. It implements a simple getter function that outputs    <code>DIRECT</code> or <code>REPORTED</code>, depending on the value of <code>reported_speech</code>.</li> </ol>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>spaCy nlp pipeline to use for matching.</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>The component name.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>eds.reported_speech</code> </p> <code>quotation</code> <p>String gathering all quotation cues.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>verbs</code> <p>List of reported speech verbs.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>following</code> <p>List of terms following a reported speech.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>preceding</code> <p>List of terms preceding a reported speech.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>attr</code> <p>spaCy's attribute to use: a string with the value \"TEXT\" or \"NORM\", or a dict with the key 'term_attr' we can also add a key for each regex.</p> <p> TYPE: <code>str</code> DEFAULT: <code>NORM</code> </p> <code>span_getter</code> <p>Which entities should be classified. By default, <code>doc.ents</code></p> <p> TYPE: <code>SpanGetterArg</code> DEFAULT: <code>None</code> </p> <code>on_ents_only</code> <p>Whether to look for matches around detected entities only. Useful for faster inference in downstream tasks.</p> <ul> <li>If True, will look in all ents located in <code>doc.ents</code> only</li> <li>If an iterable of string is passed, will additionally look in <code>doc.spans[key]</code> for each key in the iterable</li> </ul> <p> TYPE: <code>Union[bool, str, List[str], Set[str]]</code> DEFAULT: <code>True</code> </p> <code>within_ents</code> <p>Whether to consider cues within entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to keep track of cues for each entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier--authors-and-citation","title":"Authors and citation","text":"<p>The <code>eds.reported_speech</code> component was developed by AP-HP's Data Science team.</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier.load_verbs","title":"<code>load_verbs</code>","text":"<p>Conjugate reporting verbs to specific tenses (trhid person)</p>"},{"location":"reference/edsnlp/pipelines/qualifiers/reported_speech/reported_speech/#edsnlp.pipelines.qualifiers.reported_speech.reported_speech.ReportedSpeechQualifier.load_verbs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verbs</code> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>list_rep_verbs</code> <p> TYPE: <code>List of reporting verbs conjugated to specific tenses.</code> </p>"},{"location":"reference/edsnlp/pipelines/terminations/","title":"<code>edsnlp.pipelines.terminations</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/","title":"<code>edsnlp.pipelines.trainable</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/layers/","title":"<code>edsnlp.pipelines.trainable.layers</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/","title":"<code>edsnlp.pipelines.trainable.layers.crf</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF","title":"<code>LinearChainCRF</code>","text":"<p>           Bases: <code>Module</code></p> <p>A linear chain CRF in Pytorch</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>forbidden_transitions</code> <p>Shape: n_tags * n_tags Impossible transitions (1 means impossible) from position n to position n+1</p> <p> </p> <code>start_forbidden_transitions</code> <p>Shape: n_tags Impossible transitions at the start of a sequence</p> <p> DEFAULT: <code>None</code> </p> <code>end_forbidden_transitions</code> <p>Shape is (n_tags,) Impossible transitions at the end of a sequence</p> <p> DEFAULT: <code>None</code> </p> <code>learnable_transitions</code> <p>Should we learn transition scores to complete the constraints ?</p> <p> DEFAULT: <code>True</code> </p> <code>with_start_end_transitions</code> <p>Should we apply start-end transitions. If learnable_transitions is True, learn start/end transition scores</p> <p> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF.decode","title":"<code>decode</code>","text":"<p>Decodes a sequence of tag scores using the Viterbi algorithm</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF.decode--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>emissions</code> <p>Shape: ... * n_tokens * n_tags</p> <p> </p> <code>mask</code> <p>Shape: ... * n_tokens</p> <p> </p> RETURNS DESCRIPTION <code>LongTensor</code> <p>Backtrack indices (= argmax), ie best tag sequence</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF.marginal","title":"<code>marginal</code>","text":"<p>Compute the marginal log-probabilities of the tags given the emissions and the transition probabilities and constraints of the CRF</p> <p>We could use the <code>propagate</code> method but this implementation is faster.</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF.marginal--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>emissions</code> <p>Shape: ... * n_tokens * n_tags</p> <p> </p> <code>mask</code> <p>Shape: ... * n_tokens</p> <p> </p> RETURNS DESCRIPTION <code>FloatTensor</code> <p>Shape: ... * n_tokens * n_tags</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF.forward","title":"<code>forward</code>","text":"<p>Compute the posterior reduced log-probabilities of the tags given the emissions and the transition probabilities and constraints of the CRF, ie the loss.</p> <p>We could use the <code>propagate</code> method but this implementation is faster.</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.LinearChainCRF.forward--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>emissions</code> <p>Shape: ... * n_tokens * n_tags</p> <p> </p> <code>mask</code> <p>Shape: ... * n_tokens</p> <p> </p> <code>target</code> <p>Shape: ... * n_tokens * n_tags The target tags represented with 1-hot encoding We use 1-hot instead of long format to handle cases when multiple tags at a given position are allowed during training.</p> <p> </p> RETURNS DESCRIPTION <code>FloatTensor</code> <p>Shape: ... The loss</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.MultiLabelBIOULDecoder","title":"<code>MultiLabelBIOULDecoder</code>","text":"<p>           Bases: <code>LinearChainCRF</code></p> <p>Create a linear chain CRF with hard constraints to enforce the BIOUL tagging scheme</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.MultiLabelBIOULDecoder--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>num_labels</code> <code>with_start_end_transitions</code> <p> DEFAULT: <code>True</code> </p> <code>learnable_transitions</code> <p> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.MultiLabelBIOULDecoder.spans_to_tags","title":"<code>spans_to_tags</code>  <code>staticmethod</code>","text":"<p>Convert a tensor of spans of shape n_spans * (doc_idx, label, begin, end) to a matrix of BIOUL tags of shape n_samples * n_labels * n_tokens</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.MultiLabelBIOULDecoder.spans_to_tags--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>spans</code> <p> TYPE: <code>Tensor</code> </p> <code>n_samples</code> <p> TYPE: <code>int</code> </p> <code>n_labels</code> <p> TYPE: <code>int</code> </p> <code>n_tokens</code> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Tensor</code>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.MultiLabelBIOULDecoder.tags_to_spans","title":"<code>tags_to_spans</code>  <code>staticmethod</code>","text":"<p>Convert a sequence of multiple label BIOUL tags to a sequence of spans</p>"},{"location":"reference/edsnlp/pipelines/trainable/layers/crf/#edsnlp.pipelines.trainable.layers.crf.MultiLabelBIOULDecoder.tags_to_spans--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>tags</code> <p>Shape: n_samples * n_labels * n_tokens</p> <p> </p> RETURNS DESCRIPTION <code>LongTensor</code> <p>Shape: n_spans *  4 (doc_idx, label_idx, begin, end)</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/","title":"<code>edsnlp.pipelines.trainable.nested_ner</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/factory/","title":"<code>edsnlp.pipelines.trainable.nested_ner.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/factory/#edsnlp.pipelines.trainable.nested_ner.factory.create_component","title":"<code>create_component</code>","text":"<p>Initialize a general named entity recognizer (with or without nested or overlapping entities).</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/factory/#edsnlp.pipelines.trainable.nested_ner.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>The current nlp object</p> <p> TYPE: <code>Language</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> </p> <code>model</code> <p>The model to extract the spans</p> <p> TYPE: <code>Model</code> </p> <code>ent_labels</code> <p>list of labels to filter entities for in <code>doc.ents</code></p> <p> DEFAULT: <code>None</code> </p> <code>spans_labels</code> <p>Mapping from span group names to list of labels to look for entities and assign the predicted entities</p> <p> DEFAULT: <code>None</code> </p> <code>scorer</code> <p>Method to call to score predictions</p> <p> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/","title":"<code>edsnlp.pipelines.trainable.nested_ner.nested_ner</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer","title":"<code>TrainableNer</code>","text":"<p>           Bases: <code>TrainablePipe</code></p> <p>Initialize a general named entity recognizer (with or without nested or overlapping entities).</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>vocab</code> <p>Spacy vocabulary</p> <p> TYPE: <code>Vocab</code> </p> <code>model</code> <p>The model to extract the spans</p> <p> TYPE: <code>Model</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'nested_ner'</code> </p> <code>ent_labels</code> <p>list of labels to filter entities for in <code>doc.ents</code></p> <p> TYPE: <code>Iterable[str]</code> DEFAULT: <code>()</code> </p> <code>spans_labels</code> <p>Mapping from span group names to list of labels to look for entities and assign the predicted entities</p> <p> TYPE: <code>Mapping[str, Iterable[str]]</code> DEFAULT: <code>None</code> </p> <code>scorer</code> <p>Method to call to score predictions</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.labels","title":"<code>labels: Tuple[str]</code>  <code>property</code>","text":"<p>Return the labels currently added to the component.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.spans_labels","title":"<code>spans_labels: Dict[str, Tuple[str]]</code>  <code>property</code>","text":"<p>Return the span group to labels filters mapping</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.ent_labels","title":"<code>ent_labels</code>  <code>property</code>","text":"<p>Return the doc.ents labels filters</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.add_label","title":"<code>add_label</code>","text":"<p>Add a new label to the pipe.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.predict","title":"<code>predict</code>","text":"<p>Apply the pipeline's model to a batch of docs, without modifying them.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.predict--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p> TYPE: <code>List[Doc]</code> </p> RETURNS DESCRIPTION <code>Int2d</code> <p>The predicted list of (doc_idx, label_idx, begin, end) tuples as a tensor that contain the spans' prediction for all the batch</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.set_annotations","title":"<code>set_annotations</code>","text":"<p>Modify a batch of <code>Doc</code> objects, using predicted spans.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.set_annotations--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p>The documents to update</p> <p> TYPE: <code>List[Doc]</code> </p> <code>predictions</code> <p>Spans predictions, as returned by the model's predict method</p> <p> TYPE: <code>Dict[str, Ints2d]</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.update","title":"<code>update</code>","text":"<p>Learn from a batch of documents and gold-standard information, updating the pipe's model. Delegates to begin_update and get_loss.</p> <p>Unlike standard TrainablePipe components, the discrete ops (best selection of tags) is performed by the model directly (<code>begin_update</code> returns the loss and the predictions)</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.update--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>examples</code> <p> TYPE: <code>Iterable[Example]</code> </p> <code>drop</code> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <p>set_annotations: bool     Whether to update the document with predicted spans sgd: Optional[Optimizer]     Optimizer losses: Optional[Dict[str, float]]     Dict of loss, updated in place</p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Updated losses dict</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.get_loss","title":"<code>get_loss</code>","text":"<p>Find the loss and gradient of loss for the batch of documents and their predicted scores.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.initialize","title":"<code>initialize</code>","text":"<p>Initialize the pipe for training, using a representative set of data examples.</p> <ol> <li>If no ent_labels are provided, we scrap them from the ents    of the set of examples.</li> <li>If no span labels are provided, we scrap them from the spans of the set    of examples, and filter these labels with the ents_labels.</li> </ol>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.initialize--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>get_examples</code> <p>Method to sample some examples</p> <p> TYPE: <code>Callable[[], Iterable[Example]]</code> </p> <code>nlp</code> <p>Unused spacy model</p> <p> TYPE: <code>Language</code> DEFAULT: <code>None</code> </p> <code>labels</code> <p>Unused list of labels</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.examples_to_truth","title":"<code>examples_to_truth</code>","text":"<p>Converts the spans of the examples into a list of (doc_idx, label_idx, begin, end) tuple as a tensor, that will be fed to the model with the <code>begin_update</code> method.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.TrainableNer.examples_to_truth--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>examples</code> <p> TYPE: <code>List[Example]</code> </p> RETURNS DESCRIPTION <code>Ints2d</code>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.nested_ner_scorer","title":"<code>nested_ner_scorer</code>","text":"<p>Scores the extracted entities that may be overlapping or nested by looking in <code>doc.ents</code>, and <code>doc.spans</code>.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/nested_ner/#edsnlp.pipelines.trainable.nested_ner.nested_ner.nested_ner_scorer--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>examples</code> <p> TYPE: <code>Iterable[Example]</code> </p> <code>cfg</code> <ul> <li>labels: Iterable[str] labels to take into account</li> <li>spans_labels: Iterable[str] span group names to look into for entities</li> </ul> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/","title":"<code>edsnlp.pipelines.trainable.nested_ner.stack_crf_ner</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.StackedCRFNERModule","title":"<code>StackedCRFNERModule</code>","text":"<p>           Bases: <code>PytorchWrapperModule</code></p> <p>Nested NER CRF module</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.StackedCRFNERModule--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>input_size</code> <p>Size of the input embeddings</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>n_labels</code> <p>Number of labels predicted by the module</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>mode</code> <p>Loss mode of the CRF</p> <p> TYPE: <code>CRFMode</code> DEFAULT: <code>joint</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.StackedCRFNERModule.initialize","title":"<code>initialize</code>","text":"<p>Once the number of labels n_labels are known, this method initializes the torch linear layer.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.StackedCRFNERModule.forward","title":"<code>forward</code>","text":"<p>Apply the nested ner module to the document embeddings to: - compute the loss - predict the spans non exclusively. If spans are predicted, they are assigned to the <code>additional_outputs</code> dictionary.</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.StackedCRFNERModule.forward--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>embeds</code> <p>Token embeddings to predict the tags from</p> <p> TYPE: <code>FloatTensor</code> </p> <code>mask</code> <p>Mask of the sequences</p> <p> TYPE: <code>BoolTensor</code> </p> <code>spans</code> <p>2d tensor of n_spans * (doc_idx, label_idx, begin, end)</p> <p> TYPE: <code>Optional[LongTensor]</code> DEFAULT: <code>None</code> </p> <code>additional_outputs</code> <p>Additional outputs that should not / cannot be back-propped through (Thinc treats Pytorch models solely as derivable functions, but the CRF that we employ performs the best tag decoding function with Pytorch) This dict will contain the predicted 2d tensor of spans</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>None</code> </p> <code>is_train</code> <p>Are we training the model (defaults to True)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>is_predict</code> <p>Are we predicting the model (defaults to False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Optional[FloatTensor]</code> <p>Optional 0d loss (shape = [1]) to train the model</p>"},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.create_model","title":"<code>create_model</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/nested_ner/stack_crf_ner/#edsnlp.pipelines.trainable.nested_ner.stack_crf_ner.create_model--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>tok2vec</code> <p>The tok2vec embedding model used to generate the word embeddings</p> <p> TYPE: <code>Model[List[Doc], List[Floats2d]]</code> </p> <code>mode</code> <p>How the CRF loss is computed</p> <ul> <li><code>joint</code>: Loss accounts for CRF transitions</li> <li><code>independent</code>: Loss does not account for CRF transitions (softmax loss)</li> <li><code>marginal</code>: Tag scores are smoothly updated with CRF transitions, and softmax loss is applied</li> </ul> <p> TYPE: <code>CRFMode</code> </p> <code>n_labels</code> <p>Number of labels. This will be automatically set later during initialization</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Model</code>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/","title":"<code>edsnlp.pipelines.trainable.pytorch_wrapper</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule","title":"<code>PytorchWrapperModule</code>","text":"<p>           Bases: <code>Module</code></p> <p>Pytorch wrapping module for Spacy. Models that expect to be wrapped with wrap_pytorch_model should inherit from this module.</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>input_size</code> <p>Size of the input embeddings</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>n_labels</code> <p>Number of labels predicted by the module</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.load_state_dict","title":"<code>load_state_dict</code>","text":"<p>Loads the model inplace from a dumped <code>state_dict</code> object</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.load_state_dict--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>state_dict</code> <p> TYPE: <code>OrderedDict[str, Tensor]</code> </p> <code>strict</code> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.state_dict","title":"<code>state_dict</code>","text":"<p>Loads the model inplace from a dumped <code>state_dict</code> object</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.state_dict--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>destination</code> <p> DEFAULT: <code>None</code> </p> <code>prefix</code> <p> DEFAULT: <code>''</code> </p> <code>keep_vars</code> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>dict</code>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.set_n_labels","title":"<code>set_n_labels</code>","text":"<p>Sets the number of labels. To instantiate the linear layer, we need to call the <code>initialize</code> method.</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.set_n_labels--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>n_labels</code> <p>Number of different labels predicted by this module</p> <p> </p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.initialize","title":"<code>initialize</code>","text":"<p>Once the number of labels n_labels are known, this method initializes the torch linear layer.</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.forward","title":"<code>forward</code>","text":"<p>Apply the nested pytorch module to: - compute the loss - predict the outputs non exclusively. If outputs are predicted, they are assigned to the <code>additional_outputs</code> list.</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.PytorchWrapperModule.forward--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>embeds</code> <p>Input embeddings</p> <p> TYPE: <code>FloatTensor</code> </p> <code>mask</code> <p>Input embeddings mask</p> <p> TYPE: <code>BoolTensor</code> </p> <code>additional_outputs</code> <p>Additional outputs that should not / cannot be back-propped through (Thinc treats Pytorch models solely as derivable functions, but the CRF that we employ performs the best tag decoding function with Pytorch) This list will contain the predicted outputs</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>None</code> </p> <code>is_train</code> <p>Are we training the model (defaults to True)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>is_predict</code> <p>Are we predicting the model (defaults to False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Optional[FloatTensor]</code> <p>Optional 0d loss (shape = [1]) to train the model</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.pytorch_forward","title":"<code>pytorch_forward</code>","text":"<p>Run the stacked CRF pytorch model to train / run a nested NER model</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.pytorch_forward--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>model</code> <p> TYPE: <code>Model</code> </p> <code>X</code> <p> TYPE: <code>Tuple[Iterable[Doc], PredT, bool]</code> </p> <code>is_train</code> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Tuple[Tuple[Floats1d, PredictionT], Callable[Floats1d, Any]]</code>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.instance_init","title":"<code>instance_init</code>","text":"<p>Initializes the model by setting the input size of the model layers and the number of predicted labels</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.instance_init--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>model</code> <p>Nested NER thinc model</p> <p> TYPE: <code>Model</code> </p> <code>X</code> <p>list of documents on which we apply the encoder layer</p> <p> TYPE: <code>List[Doc]</code> DEFAULT: <code>None</code> </p> <code>Y</code> <p>Unused gold spans</p> <p> TYPE: <code>Ints2d</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Model</code>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.wrap_pytorch_model","title":"<code>wrap_pytorch_model</code>","text":"<p>Chain and wraps a spaCy/Thinc encoder model (like a tok2vec) and a pytorch model. The loss should be computed directly in the Pytorch module and Categorical predictions are supported</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.wrap_pytorch_model--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>encoder</code> <p>The Thinc document token embedding layer</p> <p> TYPE: <code>Model[List[Doc], List[Floats2d]]</code> </p> <code>pt_model</code> <p>The Pytorch model</p> <p> TYPE: <code>PytorchWrapperModule</code> </p> <code>attrs</code> <p>The attributes of the Pytorch model that should be copied to the Thinc model</p> <p> TYPE: <code>Sequence[str]</code> DEFAULT: <code>('set_n_labels')</code> </p> RETURNS DESCRIPTION <code>    Tuple[Iterable[Doc], Optional[PredT], Optional[bool]],</code>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.wrap_pytorch_model--inputs-docs-gold-rest-is_predict","title":"inputs (docs, gold, *rest, is_predict)","text":"<p>Tuple[Floats1d, PredT],</p>"},{"location":"reference/edsnlp/pipelines/trainable/pytorch_wrapper/#edsnlp.pipelines.trainable.pytorch_wrapper.wrap_pytorch_model--outputs-loss-additional_outputs","title":"outputs (loss, *additional_outputs)","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/","title":"<code>edsnlp.pipelines.trainable.span_qualifier</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/factory/","title":"<code>edsnlp.pipelines.trainable.span_qualifier.factory</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/factory/#edsnlp.pipelines.trainable.span_qualifier.factory.create_component","title":"<code>create_component</code>","text":"<p>Create a generic span classification component</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/factory/#edsnlp.pipelines.trainable.span_qualifier.factory.create_component--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>Spacy vocabulary</p> <p> </p> <code>model</code> <p>The model to extract the spans</p> <p> TYPE: <code>Model</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'span_qualifier'</code> </p> <code>on_ents</code> <p>Whether to look into <code>doc.ents</code> for spans to classify. If a list of strings is provided, only the span of the given labels will be considered. If None and <code>on_span_groups</code> is False, labels mentioned in <code>label_constraints</code> will be used, and all ents will be used if <code>label_constraints</code> is None.</p> <p> TYPE: <code>Optional[Union[bool, Sequence[str]]]</code> DEFAULT: <code>None</code> </p> <code>on_span_groups</code> <p>Whether to look into <code>doc.spans</code> for spans to classify:</p> <ul> <li>If True, all span groups will be considered</li> <li>If False, no span group will be considered</li> <li>If a list of str is provided, only these span groups will be kept</li> <li>If a mapping is provided, the keys are the span group names and the values   are either a list of allowed labels in the group or True to keep them all</li> </ul> <p> TYPE: <code>Union[bool, Sequence[str], Mapping[str, Union[bool, Sequence[str]]]]</code> DEFAULT: <code>False</code> </p> <code>qualifiers</code> <p>The qualifiers to predict or train on. If None, keys from the <code>label_constraints</code> will be used</p> <p> TYPE: <code>Optional[Sequence[str]]</code> DEFAULT: <code>None</code> </p> <code>label_constraints</code> <p>Constraints to select qualifiers for each span depending on their labels. Keys of the dict are the qualifiers and values are the labels for which the qualifier is allowed. If None, all qualifiers will be used for all spans</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> <code>candidate_getter</code> <p>Optional method to call to extract the candidate spans and the qualifiers to predict or train on. If None, a candidate getter will be created from the other parameters: <code>on_ents</code>, <code>on_span_groups</code>, <code>qualifiers</code> and <code>label_constraints</code>.</p> <p> TYPE: <code>Optional[Callable[[Doc], Tuple[Spans, Optional[Spans], SpanGroups, List[List[str]]]]]</code> DEFAULT: <code>None</code> </p> <code>scorer</code> <p>Optional method to call to score predictions</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/","title":"<code>edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/#edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier.SpanMultiClassifier","title":"<code>SpanMultiClassifier</code>","text":"<p>           Bases: <code>PytorchWrapperModule</code></p> <p>Pytorch module for constrained multi-label &amp; multi-class span classification</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/#edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier.SpanMultiClassifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>input_size</code> <p>Size of the input embeddings</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>n_labels</code> <p>Number of labels predicted by the module</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>pooler_mode</code> <p>How embeddings are aggregated</p> <p> TYPE: <code>PoolerMode</code> DEFAULT: <code>'max'</code> </p> <code>projection_mode</code> <p>How embeddings converted into logits</p> <p> TYPE: <code>ProjectionMode</code> DEFAULT: <code>'dot'</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/#edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier.SpanMultiClassifier.initialize","title":"<code>initialize</code>","text":"<p>Once the number of labels n_labels are known, this method initializes the torch linear layer.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/#edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier.SpanMultiClassifier.set_label_groups","title":"<code>set_label_groups</code>","text":"<p>Set the label groups matrices.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/#edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier.SpanMultiClassifier.forward","title":"<code>forward</code>","text":"<p>Apply the span classifier module to the document embeddings and given spans to: - compute the loss - and/or predict the labels of spans If labels are predicted, they are assigned to the <code>additional_outputs</code> dictionary.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_multi_classifier/#edsnlp.pipelines.trainable.span_qualifier.span_multi_classifier.SpanMultiClassifier.forward--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>embeds</code> <p>Token embeddings to predict the tags from</p> <p> TYPE: <code>FloatTensor</code> </p> <code>mask</code> <p>Mask of the sequences</p> <p> TYPE: <code>BoolTensor</code> </p> <code>spans</code> <p>2d tensor of n_spans * (doc_idx, ner_label_idx, begin, end)</p> <p> TYPE: <code>Optional[LongTensor]</code> </p> <code>targets</code> <p>list of 2d tensor of n_spans * n_combinations (1 hot)</p> <p> TYPE: <code>Optional[LongTensor]</code> </p> <code>additional_outputs</code> <p>Additional outputs that should not / cannot be back-propped through This dict will contain the predicted 2d tensor of labels</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>None</code> </p> <code>is_train</code> <p>Are we training the model (defaults to True)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>is_predict</code> <p>Are we predicting the model (defaults to False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Optional[FloatTensor]</code> <p>Optional 0d loss (shape = [1]) to train the model</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/","title":"<code>edsnlp.pipelines.trainable.span_qualifier.span_qualifier</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier","title":"<code>TrainableSpanQualifier</code>","text":"<p>           Bases: <code>TrainablePipe</code></p> <p>Create a generic span classification component</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>vocab</code> <p>Spacy vocabulary</p> <p> TYPE: <code>Vocab</code> </p> <code>model</code> <p>The model to extract the spans</p> <p> TYPE: <code>Model</code> </p> <code>name</code> <p>Name of the component</p> <p> TYPE: <code>str</code> DEFAULT: <code>'span_qualifier'</code> </p> <code>candidate_getter</code> <p>Method to call to extract the candidate spans and the qualifiers to predict or train on.</p> <p> TYPE: <code>Callable[[Doc], Tuple[Spans, Optional[Spans], SpanGroups, List[List[str]]]]</code> </p> <code>scorer</code> <p>Method to call to score predictions</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.qualifiers","title":"<code>qualifiers: Tuple[str]</code>  <code>property</code>","text":"<p>Return the qualifiers predicted by the component</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.add_label","title":"<code>add_label</code>","text":"<p>Add a new label to the pipe.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.predict","title":"<code>predict</code>","text":"<p>Apply the pipeline's model to a batch of docs, without modifying them.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.predict--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p> TYPE: <code>List[Doc]</code> </p> RETURNS DESCRIPTION <code># noqa: E501</code> <code>Tuple[Dict[str, Ints2d], Spans, List[Spans], List[SpanGroups], List[List[str]]]</code> <p>The predicted list of 1-hot label sequence as a tensor that represent the labels of spans for all the batch, the list of all spans, and the span groups and ents in case the \"label_\" qualifier is updated</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.set_annotations","title":"<code>set_annotations</code>","text":"<p>Modify the spans of a batch of <code>spacy.tokens.Span</code> objects, using the predicted labels.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.set_annotations--noqa-e501","title":"noqa: E501","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.set_annotations--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>docs</code> <p>The docs to update, not used in this function</p> <p> TYPE: <code>List[Doc]</code> </p> <code>predictions</code> <p>Tuple returned by the <code>predict</code> method, containing: - the label predictions. This is a 2d boolean tensor of shape   (<code>batch_size</code>, <code>len(self.bindings)</code>) - the spans to update - the ents to reassign if the \"label_\" qualifier is updated - the span groups dicts to reassign if the \"label_\" qualifier is updated - the qualifiers for each span</p> <p> TYPE: <code>Tuple[Dict[str, Ints2d], Spans, List[Optional[Spans]], List[SpanGroups], List[List[str]]]</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.update","title":"<code>update</code>","text":"<p>Learn from a batch of documents and gold-standard information, updating the pipe's model. Delegates to begin_update and get_loss.</p> <p>Unlike standard TrainablePipe components, the discrete ops (best selection of labels) is performed by the model directly (<code>begin_update</code> returns the loss and the predictions)</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.update--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>examples</code> <p> TYPE: <code>Iterable[Example]</code> </p> <code>drop</code> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <p>set_annotations: bool     Whether to update the document with predicted spans sgd: Optional[Optimizer]     Optimizer losses: Optional[Dict[str, float]]     Dict of loss, updated in place</p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Updated losses dict</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.get_loss","title":"<code>get_loss</code>","text":"<p>Find the loss and gradient of loss for the batch of documents and their predicted scores.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.initialize","title":"<code>initialize</code>","text":"<p>Initialize the pipe for training, using a representative set of data examples.</p> <p>Gather the qualifier values by iterating on the spans and their qualifiers matching the rules defined in the <code>candidate_getter</code>, and retrieving the values of the qualifiers.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.initialize--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>get_examples</code> <p>Method to sample some examples</p> <p> TYPE: <code>Callable[[], Iterable[Example]]</code> </p> <code>nlp</code> <p>Unused spacy model</p> <p> TYPE: <code>Language</code> DEFAULT: <code>None</code> </p> <code>labels</code> <p>Unused list of labels</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.examples_to_truth","title":"<code>examples_to_truth</code>","text":"<p>Converts the spans of the examples into a list of (doc_idx, label_idx, begin, end) tuple as a tensor, and the labels of the spans into a list of 1-hot label sequence</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/span_qualifier/#edsnlp.pipelines.trainable.span_qualifier.span_qualifier.TrainableSpanQualifier.examples_to_truth--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>examples</code> <p> TYPE: <code>List[Example]</code> </p> RETURNS DESCRIPTION <code>Tuple[Spans, List[Spans], List[SpanGroups], List[List[str]], Ints2d, List[Ints2d]]</code> <p>The list of spans, the spans tensor, the qualifiers tensor, and the list of entities and span groups to reassign them if the label_ attribute is part of the updated qualifiers</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/","title":"<code>edsnlp.pipelines.trainable.span_qualifier.utils</code>","text":""},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/#edsnlp.pipelines.trainable.span_qualifier.utils.make_candidate_getter","title":"<code>make_candidate_getter</code>","text":"<p>Make a span qualifier candidate getter function.</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/#edsnlp.pipelines.trainable.span_qualifier.utils.make_candidate_getter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>on_ents</code> <p>Whether to look into <code>doc.ents</code> for spans to classify. If a list of strings is provided, only the span of the given labels will be considered. If None and <code>on_span_groups</code> is False, labels mentioned in <code>label_constraints</code> will be used.</p> <p> TYPE: <code>Optional[Union[bool, Sequence[str]]]</code> DEFAULT: <code>None</code> </p> <code>on_span_groups</code> <p>Whether to look into <code>doc.spans</code> for spans to classify:</p> <ul> <li>If True, all span groups will be considered</li> <li>If False, no span group will be considered</li> <li>If a list of str is provided, only these span groups will be kept</li> <li>If a mapping is provided, the keys are the span group names and the values   are either a list of allowed labels in the group or True to keep them all</li> </ul> <p> TYPE: <code>Union[bool, Sequence[str], Mapping[str, Union[bool, Sequence[str]]]]</code> DEFAULT: <code>False</code> </p> <code>qualifiers</code> <p>The qualifiers to predict or train on. If None, keys from the <code>label_constraints</code> will be used</p> <p> TYPE: <code>Optional[Sequence[str]]</code> DEFAULT: <code>None</code> </p> <code>label_constraints</code> <p>Constraints to select qualifiers for each span depending on their labels. Keys of the dict are the qualifiers and values are the labels for which the qualifier is allowed. If None, all qualifiers will be used for all spans</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Callable[[Doc], Tuple[Spans, Optional[Spans], SpanGroups, List[List[str]]]]</code>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/#edsnlp.pipelines.trainable.span_qualifier.utils.make_binding_getter","title":"<code>make_binding_getter</code>","text":"<p>Make a qualifier getter</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/#edsnlp.pipelines.trainable.span_qualifier.utils.make_binding_getter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>qualifier</code> <p>Either one of the following: - a path to a nested attributes of the span, such as \"qualifier_\" or \"_.negated\" - a tuple of (key, value) equality, such as <code>(\"_.date.mode\", \"PASSED\")</code></p> <p> TYPE: <code>Union[str, Binding]</code> </p> RETURNS DESCRIPTION <code>Callable[[Span], bool]</code> <p>The qualifier getter</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/#edsnlp.pipelines.trainable.span_qualifier.utils.make_binding_setter","title":"<code>make_binding_setter</code>","text":"<p>Make a qualifier setter</p>"},{"location":"reference/edsnlp/pipelines/trainable/span_qualifier/utils/#edsnlp.pipelines.trainable.span_qualifier.utils.make_binding_setter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>binding</code> <p>A pair of - a path to a nested attributes of the span, such as <code>qualifier_</code> or <code>_.negated</code> - a value assignment</p> <p> TYPE: <code>Binding</code> </p> RETURNS DESCRIPTION <code>Callable[[Span]]</code> <p>The qualifier setter</p>"},{"location":"reference/edsnlp/processing/","title":"<code>edsnlp.processing</code>","text":""},{"location":"reference/edsnlp/processing/distributed/","title":"<code>edsnlp.processing.distributed</code>","text":""},{"location":"reference/edsnlp/processing/distributed/#edsnlp.processing.distributed.pyspark_type_finder","title":"<code>pyspark_type_finder</code>","text":"<p>Returns (when possible) the PySpark type of any python object</p>"},{"location":"reference/edsnlp/processing/distributed/#edsnlp.processing.distributed.pipe","title":"<code>pipe</code>","text":"<p>Function to apply a spaCy pipe to a pyspark or koalas DataFrame note</p>"},{"location":"reference/edsnlp/processing/distributed/#edsnlp.processing.distributed.pipe--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>A Pyspark or Koalas DataFrame with a <code>note_id</code> and <code>note_text</code> column</p> <p> TYPE: <code>DataFrame</code> </p> <code>nlp</code> <p>A spaCy pipe</p> <p> TYPE: <code>Language</code> </p> <code>context</code> <p>A list of column to add to the generated SpaCy document as an extension. For instance, if <code>context=[\"note_datetime\"], the corresponding value found in the</code>note_datetime<code>column will be stored in</code>doc._.note_datetime<code>, which can be useful e.g. for the</code>dates` pipeline.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>[]</code> </p> <code>additional_spans</code> <p>A name (or list of names) of SpanGroup on which to apply the pipe too: SpanGroup are available as <code>doc.spans[spangroup_name]</code> and can be generated by some pipes. For instance, the <code>eds.dates</code> pipeline component populates <code>doc.spans['dates']</code></p> <p> TYPE: <code>Union[List[str], str], by default \"discarded\"</code> DEFAULT: <code>'discarded'</code> </p> <code>extensions</code> <p>Spans extensions to add to the extracted results: For instance, if <code>extensions=[\"score_name\"]</code>, the extracted result will include, for each entity, <code>ent._.score_name</code>.</p> <p> TYPE: <code>List[Tuple[str, T.DataType]], by default []</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>A pyspark DataFrame with one line per extraction</p>"},{"location":"reference/edsnlp/processing/distributed/#edsnlp.processing.distributed.custom_pipe","title":"<code>custom_pipe</code>","text":"<p>Function to apply a spaCy pipe to a pyspark or koalas DataFrame note, a generic callback function that converts a spaCy <code>Doc</code> object into a list of dictionaries.</p>"},{"location":"reference/edsnlp/processing/distributed/#edsnlp.processing.distributed.custom_pipe--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>A Pyspark or Koalas DataFrame with a <code>note_text</code> column</p> <p> TYPE: <code>DataFrame</code> </p> <code>nlp</code> <p>A spaCy pipe</p> <p> TYPE: <code>Language</code> </p> <code>results_extractor</code> <p>Arbitrary function that takes extract serialisable results from the computed spaCy <code>Doc</code> object. The output of the function must be a list of dictionaries containing the extracted spans or entities.</p> <p>There is no requirement for all entities to provide every dictionary key.</p> <p> TYPE: <code>Callable[[Doc], List[Dict[str, Any]]]</code> </p> <code>dtypes</code> <p>Dictionary containing all expected keys from the <code>results_extractor</code> function, along with their types.</p> <p> TYPE: <code>Dict[str, DataType]</code> </p> <code>context</code> <p>A list of column to add to the generated SpaCy document as an extension. For instance, if <code>context=[\"note_datetime\"], the corresponding value found in the</code>note_datetime<code>column will be stored in</code>doc._.note_datetime<code>, which can be useful e.g. for the</code>dates` pipeline.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>[]</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>A pyspark DataFrame with one line per extraction</p>"},{"location":"reference/edsnlp/processing/helpers/","title":"<code>edsnlp.processing.helpers</code>","text":""},{"location":"reference/edsnlp/processing/helpers/#edsnlp.processing.helpers.slugify","title":"<code>slugify</code>","text":"<p>Slugify a chained attribute name</p>"},{"location":"reference/edsnlp/processing/helpers/#edsnlp.processing.helpers.slugify--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>chained_attr</code> <p>The string to slugify (replace dots by _)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The slugified string</p>"},{"location":"reference/edsnlp/processing/parallel/","title":"<code>edsnlp.processing.parallel</code>","text":""},{"location":"reference/edsnlp/processing/parallel/#edsnlp.processing.parallel.pipe","title":"<code>pipe</code>","text":"<p>Function to apply a spaCy pipe to a pandas DataFrame note by using multiprocessing</p>"},{"location":"reference/edsnlp/processing/parallel/#edsnlp.processing.parallel.pipe--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>A pandas DataFrame with a <code>note_id</code> and <code>note_text</code> column</p> <p> TYPE: <code>DataFrame</code> </p> <code>nlp</code> <p>A spaCy pipe</p> <p> TYPE: <code>Language</code> </p> <code>context</code> <p>A list of column to add to the generated SpaCy document as an extension. For instance, if <code>context=[\"note_datetime\"], the corresponding value found in the</code>note_datetime<code>column will be stored in</code>doc._.note_datetime<code>, which can be useful e.g. for the</code>dates` pipeline.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>[]</code> </p> <code>results_extractor</code> <p>Arbitrary function that takes extract serialisable results from the computed spaCy <code>Doc</code> object. The output of the function must be a list of dictionaries containing the extracted spans or entities.</p> <p> TYPE: <code>Optional[Callable[[Doc], List[Dict[str, Any]]]]</code> DEFAULT: <code>None</code> </p> <code>additional_spans</code> <p>A name (or list of names) of SpanGroup on which to apply the pipe too: SpanGroup are available as <code>doc.spans[spangroup_name]</code> and can be generated by some pipes. For instance, the <code>date</code> pipe populates doc.spans['dates']</p> <p> TYPE: <code>Union[List[str], str], by default [] (empty list)</code> DEFAULT: <code>[]</code> </p> <code>extensions</code> <p>Spans extensions to add to the extracted results: For instance, if <code>extensions=[\"score_name\"]</code>, the extracted result will include, for each entity, <code>ent._.score_name</code>.</p> <p> TYPE: <code>List[Tuple[str, T.DataType]], by default []</code> DEFAULT: <code>[]</code> </p> <code>chunksize</code> <p>Batch size used to split tasks</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>n_jobs</code> <p>Max number of parallel jobs. The default value uses the maximum number of available cores.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-2</code> </p> <code>progress_bar</code> <p>Whether to display a progress bar or not</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>**pipe_kwargs</code> <p>Arguments exposed in <code>processing.pipe_generator</code> are also available here</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>A pandas DataFrame with one line per extraction</p>"},{"location":"reference/edsnlp/processing/simple/","title":"<code>edsnlp.processing.simple</code>","text":""},{"location":"reference/edsnlp/processing/simple/#edsnlp.processing.simple.pipe","title":"<code>pipe</code>","text":"<p>Function to apply a spaCy pipe to a pandas DataFrame note For a large DataFrame, prefer the parallel version.</p>"},{"location":"reference/edsnlp/processing/simple/#edsnlp.processing.simple.pipe--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>A pandas DataFrame with a <code>note_id</code> and <code>note_text</code> column</p> <p> TYPE: <code>DataFrame</code> </p> <code>nlp</code> <p>A spaCy pipe</p> <p> TYPE: <code>Language</code> </p> <code>context</code> <p>A list of column to add to the generated SpaCy document as an extension. For instance, if <code>context=[\"note_datetime\"], the corresponding value found in the</code>note_datetime<code>column will be stored in</code>doc._.note_datetime<code>, which can be useful e.g. for the</code>dates` pipeline.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>[]</code> </p> <code>additional_spans</code> <p>A name (or list of names) of SpanGroup on which to apply the pipe too: SpanGroup are available as <code>doc.spans[spangroup_name]</code> and can be generated by some pipes. For instance, the <code>date</code> pipe populates doc.spans['dates']</p> <p> TYPE: <code>Union[List[str], str], by default \"discarded\"</code> DEFAULT: <code>[]</code> </p> <code>extensions</code> <p>Spans extensions to add to the extracted results: For instance, if <code>extensions=[\"score_name\"]</code>, the extracted result will include, for each entity, <code>ent._.score_name</code>.</p> <p> TYPE: <code>List[Tuple[str, T.DataType]], by default []</code> DEFAULT: <code>[]</code> </p> <code>batch_size</code> <p>Batch size used by spaCy's pipe</p> <p> TYPE: <code>int, by default 1000</code> DEFAULT: <code>1000</code> </p> <code>progress_bar</code> <p>Whether to display a progress bar or not</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>A pandas DataFrame with one line per extraction</p>"},{"location":"reference/edsnlp/processing/utils/","title":"<code>edsnlp.processing.utils</code>","text":""},{"location":"reference/edsnlp/processing/wrapper/","title":"<code>edsnlp.processing.wrapper</code>","text":""},{"location":"reference/edsnlp/processing/wrapper/#edsnlp.processing.wrapper.pipe","title":"<code>pipe</code>","text":"<p>Function to apply a spaCy pipe to a pandas or pyspark DataFrame</p>"},{"location":"reference/edsnlp/processing/wrapper/#edsnlp.processing.wrapper.pipe--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>note</code> <p>A pandas/pyspark/koalas DataFrame with a <code>note_id</code> and <code>note_text</code> column</p> <p> TYPE: <code>DataFrame</code> </p> <code>nlp</code> <p>A spaCy pipe</p> <p> TYPE: <code>Language</code> </p> <code>context</code> <p>A list of column to add to the generated SpaCy document as an extension. For instance, if <code>context=[\"note_datetime\"], the corresponding value found in the</code>note_datetime<code>column will be stored in</code>doc._.note_datetime<code>, which can be useful e.g. for the</code>dates` pipeline.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>[]</code> </p> <code>n_jobs</code> <p>Only used when providing a Pandas DataFrame</p> <ul> <li><code>n_jobs=1</code> corresponds to <code>simple_pipe</code></li> <li><code>n_jobs&gt;1</code> corresponds to <code>parallel_pipe</code> with <code>n_jobs</code> parallel workers</li> <li><code>n_jobs=-1</code> corresponds to <code>parallel_pipe</code> with maximum number of workers</li> <li><code>n_jobs=-2</code> corresponds to <code>parallel_pipe</code> with maximum number of workers -1</li> </ul> <p> TYPE: <code>int, by default -2</code> DEFAULT: <code>-2</code> </p> <code>additional_spans</code> <p>A name (or list of names) of SpanGroup on which to apply the pipe too: SpanGroup are available as <code>doc.spans[spangroup_name]</code> and can be generated by some pipes. For instance, the <code>date</code> pipe populates doc.spans['dates']</p> <p> TYPE: <code>Union[List[str], str], by default \"discarded\"</code> DEFAULT: <code>[]</code> </p> <code>extensions</code> <p>Spans extensions to add to the extracted results: For instance, if <code>extensions=[\"score_name\"]</code>, the extracted result will include, for each entity, <code>ent._.score_name</code>.</p> <p> TYPE: <code>List[Tuple[str, T.DataType]], by default []</code> DEFAULT: <code>[]</code> </p> <code>kwargs</code> <p>Additional parameters depending on the <code>how</code> argument.</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>A DataFrame with one line per extraction</p>"},{"location":"reference/edsnlp/utils/","title":"<code>edsnlp.utils</code>","text":""},{"location":"reference/edsnlp/utils/collections/","title":"<code>edsnlp.utils.collections</code>","text":""},{"location":"reference/edsnlp/utils/colors/","title":"<code>edsnlp.utils.colors</code>","text":""},{"location":"reference/edsnlp/utils/colors/#edsnlp.utils.colors.create_colors","title":"<code>create_colors</code>","text":"<p>Assign a colour for each label, using category20 palette. The method loops over the colour palette in case there are too many labels.</p>"},{"location":"reference/edsnlp/utils/colors/#edsnlp.utils.colors.create_colors--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>labels</code> <p>List of labels to colorise in displacy.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>A displacy-compatible colour assignment.</p>"},{"location":"reference/edsnlp/utils/deprecation/","title":"<code>edsnlp.utils.deprecation</code>","text":""},{"location":"reference/edsnlp/utils/deprecation/#edsnlp.utils.deprecation.deprecated_factory","title":"<code>deprecated_factory</code>","text":"<p>Execute the Language.factory method on a modified factory function. The modification adds a deprecation warning.</p>"},{"location":"reference/edsnlp/utils/deprecation/#edsnlp.utils.deprecation.deprecated_factory--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>name</code> <p>The deprecated name for the pipeline</p> <p> TYPE: <code>str</code> </p> <code>new_name</code> <p>The new name for the pipeline, which should be used, by default None</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>default_config</code> <p>The configuration that should be passed to Language.factory, by default None</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> <code>func</code> <p>The function to decorate, by default None</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Callable</code>"},{"location":"reference/edsnlp/utils/examples/","title":"<code>edsnlp.utils.examples</code>","text":""},{"location":"reference/edsnlp/utils/examples/#edsnlp.utils.examples.find_matches","title":"<code>find_matches</code>","text":"<p>Finds entities within the example.</p>"},{"location":"reference/edsnlp/utils/examples/#edsnlp.utils.examples.find_matches--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>example</code> <p>Example to process.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Match]</code> <p>List of matches for entities.</p>"},{"location":"reference/edsnlp/utils/examples/#edsnlp.utils.examples.parse_match","title":"<code>parse_match</code>","text":"<p>Parse a regex match representing an entity.</p>"},{"location":"reference/edsnlp/utils/examples/#edsnlp.utils.examples.parse_match--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>match</code> <p>Match for an entity.</p> <p> TYPE: <code>Match</code> </p> RETURNS DESCRIPTION <code>Match</code> <p>Usable representation for the entity match.</p>"},{"location":"reference/edsnlp/utils/examples/#edsnlp.utils.examples.parse_example","title":"<code>parse_example</code>","text":"<p>Parses an example : finds examples and removes the tags.</p>"},{"location":"reference/edsnlp/utils/examples/#edsnlp.utils.examples.parse_example--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>example</code> <p>Example to process.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Tuple[str, List[Entity]]</code> <p>Cleaned text and extracted entities.</p>"},{"location":"reference/edsnlp/utils/extensions/","title":"<code>edsnlp.utils.extensions</code>","text":""},{"location":"reference/edsnlp/utils/extensions/#edsnlp.utils.extensions.rgetattr","title":"<code>rgetattr</code>","text":"<p>Get attribute recursively</p>"},{"location":"reference/edsnlp/utils/extensions/#edsnlp.utils.extensions.rgetattr--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>obj</code> <p>An object</p> <p> TYPE: <code>Any</code> </p> <code>attr</code> <p>The name of the attribute to get. Can contain dots.</p> <p> TYPE: <code>str</code> </p>"},{"location":"reference/edsnlp/utils/filter/","title":"<code>edsnlp.utils.filter</code>","text":""},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.default_sort_key","title":"<code>default_sort_key</code>","text":"<p>Returns the sort key for filtering spans.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.default_sort_key--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>span</code> <p>Span to sort.</p> <p> TYPE: <code>Span</code> </p> RETURNS DESCRIPTION <code>key</code> <p>Sort key.</p> <p> TYPE: <code>Tuple(int, int)</code> </p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.start_sort_key","title":"<code>start_sort_key</code>","text":"<p>Returns the sort key for filtering spans by start order.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.start_sort_key--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>span</code> <p>Span to sort.</p> <p> TYPE: <code>Span</code> </p> RETURNS DESCRIPTION <code>key</code> <p>Sort key.</p> <p> TYPE: <code>Tuple(int, int)</code> </p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.filter_spans","title":"<code>filter_spans</code>","text":"<p>Re-definition of spacy's filtering function, that returns discarded spans as well as filtered ones.</p> <p>Can also accept a <code>label_to_remove</code> argument, useful for filtering out pseudo cues. If set, <code>results</code> can contain overlapping spans: only spans overlapping with excluded labels are removed. The main expected use case is for pseudo-cues.</p> <p>It can handle an iterable of tuples instead of an iterable of <code>Span</code>s. The primary use-case is the use with the <code>RegexMatcher</code>'s capacity to return the span's <code>groupdict</code>.</p> <p>The spaCy documentation states:</p> <p>Filter a sequence of spans and remove duplicates or overlaps. Useful for creating named entities (where one token can only be part of one entity) or when merging spans with <code>Retokenizer.merge</code>. When spans overlap, the (first) longest span is preferred over shorter spans.</p> <p>Filtering out spans</p> <p>If the <code>label_to_remove</code> argument is supplied, it might be tempting to filter overlapping spans that are not part of a label to remove.</p> <p>The reason we keep all other possibly overlapping labels is that in qualifier pipelines, the same cue can precede and follow a marked entity. Hence we need to keep every example.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.filter_spans--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>spans</code> <p>Spans to filter.</p> <p> TYPE: <code>Iterable[Union[Span, Tuple[Span, Any]]]</code> </p> <code>return_discarded</code> <p>Whether to return discarded spans.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>label_to_remove</code> <p>Label to remove. If set, results can contain overlapping spans.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>sort_key</code> <p>Key to sorting spans before applying overlap conflict resolution. A span with a higher key will have precedence over another span. By default, the largest, leftmost spans are selected first.</p> <p> TYPE: <code>Callable[Span, Any]</code> DEFAULT: <code>default_sort_key</code> </p> RETURNS DESCRIPTION <code>results</code> <p>Filtered spans</p> <p> TYPE: <code>List[Union[Span, Tuple[Span, Any]]]</code> </p> <code>discarded</code> <p>Discarded spans</p> <p> TYPE: <code>(List[Union[Span, Tuple[Span, Any]]], optional)</code> </p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.consume_spans","title":"<code>consume_spans</code>","text":"<p>Consume a list of span, according to a filter.</p> <p>Warning</p> <p>This method makes the hard hypothesis that:</p> <ol> <li>Spans are sorted.</li> <li>Spans are consumed in sequence and only once.</li> </ol> <p>The second item is problematic for the way we treat long entities, hence the <code>second_chance</code> parameter, which lets entities be seen more than once.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.consume_spans--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>spans</code> <p>List of spans to filter</p> <p> TYPE: <code>List of spans</code> </p> <code>filter</code> <p>Filtering function. Should return True when the item is to be included.</p> <p> TYPE: <code>Callable</code> </p> <code>second_chance</code> <p>Optional list of spans to include again (useful for long entities), by default None</p> <p> TYPE: <code>List of spans</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>matches</code> <p>List of spans consumed by the filter.</p> <p> TYPE: <code>List of spans</code> </p> <code>remainder</code> <p>List of remaining spans in the original <code>spans</code> parameter.</p> <p> TYPE: <code>List of spans</code> </p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.get_spans","title":"<code>get_spans</code>","text":"<p>Extracts spans with a given label. Prefer using hash label for performance reasons.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.get_spans--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>spans</code> <p>List of spans to filter.</p> <p> TYPE: <code>List[Span]</code> </p> <code>label</code> <p>Label to filter on.</p> <p> TYPE: <code>Union[int, str]</code> </p> RETURNS DESCRIPTION <code>List[Span]</code> <p>Filtered spans.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.span_f1","title":"<code>span_f1</code>","text":"<p>Computes the F1 overlap between two spans.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.span_f1--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>a</code> <p>First span</p> <p> TYPE: <code>Span</code> </p> <code>b</code> <p>Second span</p> <p> TYPE: <code>Span</code> </p> RETURNS DESCRIPTION <code>float</code> <p>F1 overlap</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.align_spans","title":"<code>align_spans</code>","text":"<p>Aligns two lists of spans, by matching source spans that overlap target spans. This function is optimized to avoid quadratic complexity.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.align_spans--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>source</code> <p>List of spans to align.</p> <p> TYPE: <code>List[Span]</code> </p> <code>target</code> <p>List of spans to align.</p> <p> TYPE: <code>List[Span]</code> </p> <code>sort_by_overlap</code> <p>Whether to sort the aligned spans by maximum dice/f1 overlap with the target span.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[List[Span]]</code> <p>Subset of <code>source</code> spans for each target span</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.get_span_group","title":"<code>get_span_group</code>","text":"<p>Get the spans of a span group that are contained inside a doclike object.</p>"},{"location":"reference/edsnlp/utils/filter/#edsnlp.utils.filter.get_span_group--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>doclike</code> <p>Doclike object to act as a mask.</p> <p> TYPE: <code>Union[Doc, Span]</code> </p> <code>group</code> <p>Group name from which to get the spans.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Span]</code> <p>List of spans.</p>"},{"location":"reference/edsnlp/utils/inclusion/","title":"<code>edsnlp.utils.inclusion</code>","text":""},{"location":"reference/edsnlp/utils/inclusion/#edsnlp.utils.inclusion.check_inclusion","title":"<code>check_inclusion</code>","text":"<p>Checks whether the span overlaps the boundaries.</p>"},{"location":"reference/edsnlp/utils/inclusion/#edsnlp.utils.inclusion.check_inclusion--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>span</code> <p>Span to check.</p> <p> TYPE: <code>Span</code> </p> <code>start</code> <p>Start of the boundary</p> <p> TYPE: <code>int</code> </p> <code>end</code> <p>End of the boundary</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the span overlaps the boundaries.</p>"},{"location":"reference/edsnlp/utils/inclusion/#edsnlp.utils.inclusion.check_sent_inclusion","title":"<code>check_sent_inclusion</code>","text":"<p>Checks whether the span overlaps the boundaries.</p>"},{"location":"reference/edsnlp/utils/inclusion/#edsnlp.utils.inclusion.check_sent_inclusion--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>span</code> <p>Span to check.</p> <p> TYPE: <code>Span</code> </p> <code>start</code> <p>Start of the boundary</p> <p> TYPE: <code>int</code> </p> <code>end</code> <p>End of the boundary</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the span overlaps the boundaries.</p>"},{"location":"reference/edsnlp/utils/lists/","title":"<code>edsnlp.utils.lists</code>","text":""},{"location":"reference/edsnlp/utils/lists/#edsnlp.utils.lists.flatten","title":"<code>flatten</code>","text":"<p>Flatten (if necessary) a list of sublists</p>"},{"location":"reference/edsnlp/utils/lists/#edsnlp.utils.lists.flatten--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>my_list</code> <p>A list of items, each items in turn can be a list</p> <p> TYPE: <code>List</code> </p> RETURNS DESCRIPTION <code>List</code> <p>A flatten list</p>"},{"location":"reference/edsnlp/utils/merge_configs/","title":"<code>edsnlp.utils.merge_configs</code>","text":""},{"location":"reference/edsnlp/utils/merge_configs/#edsnlp.utils.merge_configs.merge_configs","title":"<code>merge_configs</code>","text":"<p>Deep merge two configs.</p>"},{"location":"reference/edsnlp/utils/numbers/","title":"<code>edsnlp.utils.numbers</code>","text":""},{"location":"reference/edsnlp/utils/regex/","title":"<code>edsnlp.utils.regex</code>","text":""},{"location":"reference/edsnlp/utils/regex/#edsnlp.utils.regex.make_pattern","title":"<code>make_pattern</code>","text":"<p>Create OR pattern from a list of patterns.</p>"},{"location":"reference/edsnlp/utils/regex/#edsnlp.utils.regex.make_pattern--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>patterns</code> <p>List of patterns to merge.</p> <p> TYPE: <code>List[str]</code> </p> <code>with_breaks</code> <p>Whether to add breaks (<code>\\b</code>) on each side, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>name</code> <p>Name of the group, using regex <code>?P&lt;&gt;</code> directive.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Merged pattern.</p>"},{"location":"reference/edsnlp/utils/regex/#edsnlp.utils.regex.compile_regex","title":"<code>compile_regex</code>","text":"<p>This function tries to compile <code>reg</code>  using the <code>re</code> module, and fallbacks to the <code>regex</code> module that is more permissive.</p>"},{"location":"reference/edsnlp/utils/regex/#edsnlp.utils.regex.compile_regex--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>reg</code> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[Pattern, Pattern]</code>"},{"location":"reference/edsnlp/utils/resources/","title":"<code>edsnlp.utils.resources</code>","text":""},{"location":"reference/edsnlp/utils/resources/#edsnlp.utils.resources.get_verbs","title":"<code>get_verbs</code>","text":"<p>Extract verbs from the resources, as a pandas dataframe.</p>"},{"location":"reference/edsnlp/utils/resources/#edsnlp.utils.resources.get_verbs--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>verbs</code> <p>List of verbs to keep. Returns all verbs by default.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>check_contains</code> <p>Whether to check that no verb is missing if a list of verbs was provided. By default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>DataFrame containing conjugated verbs.</p>"},{"location":"reference/edsnlp/utils/resources/#edsnlp.utils.resources.get_adicap_dict","title":"<code>get_adicap_dict</code>  <code>cached</code>","text":"RETURNS DESCRIPTION <code>Dict</code>"},{"location":"reference/edsnlp/utils/span_getters/","title":"<code>edsnlp.utils.span_getters</code>","text":""},{"location":"reference/edsnlp/utils/span_getters/#edsnlp.utils.span_getters.make_span_getter","title":"<code>make_span_getter</code>","text":"<p>Make a span qualifier candidate getter function.</p>"},{"location":"reference/edsnlp/utils/span_getters/#edsnlp.utils.span_getters.make_span_getter--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>on_ents</code> <p>Whether to look into <code>doc.ents</code> for spans to classify. If a list of strings is provided, only the span of the given labels will be considered. If None and <code>on_spans_groups</code> is False, labels mentioned in <code>label_constraints</code> will be used.</p> <p> TYPE: <code>Optional[Union[bool, Sequence[str]]]</code> DEFAULT: <code>None</code> </p> <code>on_spans_groups</code> <p>Whether to look into <code>doc.spans</code> for spans to classify:</p> <ul> <li>If True, all span groups will be considered</li> <li>If False, no span group will be considered</li> <li>If a list of str is provided, only these span groups will be kept</li> <li>If a mapping is provided, the keys are the span group names and the values   are either a list of allowed labels in the group or True to keep them all</li> </ul> <p> TYPE: <code>Union[bool, Sequence[str], Mapping[str, Union[bool, Sequence[str]]]]</code> DEFAULT: <code>False</code> </p>"},{"location":"reference/edsnlp/utils/training/","title":"<code>edsnlp.utils.training</code>","text":""},{"location":"reference/edsnlp/utils/training/#edsnlp.utils.training.make_spacy_corpus_config","title":"<code>make_spacy_corpus_config</code>","text":"<p>Helper to create a spacy's corpus config from training and dev data by loading the documents accordingly and exporting the documents using spacy's DocBin.</p>"},{"location":"reference/edsnlp/utils/training/#edsnlp.utils.training.make_spacy_corpus_config--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>train_data</code> <p>The training data. Can be:     - a list of spacy.Doc     - a path to a given dataset</p> <p> TYPE: <code>Union[str, List[Doc]]</code> </p> <code>dev_data</code> <p>The development data. Can be:     - a list of spacy.Doc     - a path to a given dataset     - the number of documents to take from the training data     - the fraction of documents to take from the training data</p> <p> TYPE: <code>Union[str, List[Doc], int, float]</code> </p> <code>data_format</code> <p>Optional data format to determine how we should load the documents from the disk</p> <p> TYPE: <code>Union[Optional[DataFormat], str]</code> DEFAULT: <code>None</code> </p> <code>nlp</code> <p>Optional spacy model to load documents from non-spacy formats (like brat)</p> <p> TYPE: <code>Optional[Language]</code> DEFAULT: <code>None</code> </p> <code>seed</code> <p>The seed if we need to shuffle the data when splitting the dataset</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>reader</code> <p>Which spacy reader to use when loading the data</p> <p> TYPE: <code>str</code> DEFAULT: <code>'spacy.Corpus.v1'</code> </p> RETURNS DESCRIPTION <code>Config</code>"},{"location":"reference/edsnlp/utils/training/#edsnlp.utils.training.train","title":"<code>train</code>","text":"<p>Training help to learn weight of trainable components in a pipeline. This function has been adapted from https://github.com/explosion/spaCy/blob/397197e/spacy/cli/train.py#L18</p>"},{"location":"reference/edsnlp/utils/training/#edsnlp.utils.training.train--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>nlp</code> <p>Spacy model to train</p> <p> TYPE: <code>Language</code> </p> <code>output_path</code> <p>Path to save the model</p> <p> TYPE: <code>Union[Path, str]</code> </p> <code>config</code> <p>Optional config overrides</p> <p> TYPE: <code>Union[Config, dict]</code> </p> <code>use_gpu</code> <p>Which gpu to use for training (-1 means CPU)</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p>"},{"location":"reference/edsnlp/viz/","title":"<code>edsnlp.viz</code>","text":""},{"location":"reference/edsnlp/viz/quick_examples/","title":"<code>edsnlp.viz.quick_examples</code>","text":""},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample","title":"<code>QuickExample</code>","text":""},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.__call__","title":"<code>__call__</code>","text":"<p>Displays the text and a table of entities</p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.__call__--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>as_dataframe</code> <p>If true, returns the table as a DataFrame instead of displaying it, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Optional[DataFrame]</code> <p>The DataFrame describing the document</p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.get_ents_interval","title":"<code>get_ents_interval</code>","text":"<p>From the list of all entities, removes overlapping spans</p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.is_ent","title":"<code>is_ent</code>","text":"<p>Check if the provided Token is part of an entity</p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.is_ent--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>tok</code> <p>A spaCy Token</p> <p> TYPE: <code>Token</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if <code>tok</code> is part of an entity</p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.get_text","title":"<code>get_text</code>","text":"<p>Adds bold tags to <code>self.text</code></p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.display","title":"<code>display</code>","text":"<p>Displays the text and a table of entities</p>"},{"location":"reference/edsnlp/viz/quick_examples/#edsnlp.viz.quick_examples.QuickExample.display--parameters","title":"Parameters","text":"PARAMETER DESCRIPTION <code>as_dataframe</code> <p>If true, returns the table as a DataFrame instead of displaying it, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Optional[DataFrame]</code> <p>The DataFrame describing the document</p>"},{"location":"contributing/","title":"Contributing to EDS-NLP","text":"<p>We welcome contributions ! There are many ways to help. For example, you can:</p> <ol> <li>Help us track bugs by filing issues</li> <li>Suggest and help prioritise new functionalities</li> <li>Develop a new pipeline ! Fork the project and propose a new functionality through a pull request</li> <li>Help us make the library as straightforward as possible, by simply asking questions on whatever does not seem clear to you.</li> </ol>"},{"location":"contributing/#development-installation","title":"Development installation","text":"<p>To be able to run the test suite, run the example notebooks and develop your own pipeline, you should clone the repo and install it locally.</p> <pre><code># Clone the repository and change directory\n$ git clone https://github.com/aphp/edsnlp.git\n---&gt; 100%\n$ cd edsnlp\n\n# Optional: create a virtual environment\n$ python -m venv venv\n$ source venv/bin/activate\n\n# Install the package with common, dev, setup dependencies in editable mode\n$ pip install -e '.[dev,setup]'\n# And build resources\n$ python scripts/conjugate_verbs.py\n</code></pre> <p>To make sure the pipeline will not fail because of formatting errors, we added pre-commit hooks using the <code>pre-commit</code> Python library. To use it, simply install it:</p> <pre><code>$ pre-commit install\n</code></pre> <p>The pre-commit hooks defined in the configuration will automatically run when you commit your changes, letting you know if something went wrong.</p> <p>The hooks only run on staged changes. To force-run it on all files, run:</p> <pre><code>$ pre-commit run --all-files\n---&gt; 100%\ncolor:green All good !\n</code></pre>"},{"location":"contributing/#proposing-a-merge-request","title":"Proposing a merge request","text":"<p>At the very least, your changes should :</p> <ul> <li>Be well-documented ;</li> <li>Pass every tests, and preferably implement its own ;</li> <li>Follow the style guide.</li> </ul>"},{"location":"contributing/#testing-your-code","title":"Testing your code","text":"<p>We use the Pytest test suite.</p> <p>The following command will run the test suite. Writing your own tests is encouraged !</p> <pre><code>python -m pytest\n</code></pre> <p>Testing Cython code</p> <p>Make sure the package is installed in editable mode. Otherwise <code>Pytest</code> won't be able to find the Cython modules.</p> <p>Should your contribution propose a bug fix, we require the bug be thoroughly tested.</p>"},{"location":"contributing/#architecture-of-a-pipeline","title":"Architecture of a pipeline","text":"<p>Pipelines should follow the same pattern :</p> <pre><code>edsnlp/pipelines/&lt;pipeline&gt;\n   |-- &lt;pipeline&gt;.py                # Defines the component logic\n   |-- patterns.py                  # Defines matched patterns\n   |-- factory.py                   # Declares the pipeline to spaCy\n</code></pre>"},{"location":"contributing/#style-guide","title":"Style Guide","text":"<p>We use Black to reformat the code. While other formatter only enforce PEP8 compliance, Black also makes the code uniform. In short :</p> <p>Black reformats entire files in place. It is not configurable.</p> <p>Moreover, the CI/CD pipeline enforces a number of checks on the \"quality\" of the code. To wit, non black-formatted code will make the test pipeline fail. We use <code>pre-commit</code> to keep our codebase clean.</p> <p>Refer to the development install tutorial for tips on how to format your files automatically. Most modern editors propose extensions that will format files on save.</p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>Make sure to document your improvements, both within the code with comprehensive docstrings, as well as in the documentation itself if need be.</p> <p>We use <code>MkDocs</code> for EDS-NLP's documentation. You can checkout the changes you make with:</p> <pre><code># Install the requirements\n$ pip install -e '.[dev]'\n---&gt; 100%\ncolor:green Installation successful\n\n# Run the documentation\n$ mkdocs serve\n</code></pre> <p>Go to <code>localhost:8000</code> to see your changes. MkDocs watches for changes in the documentation folder and automatically reloads the page.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>New <code>to_duration</code> method to convert an absolute date into a date relative to the note_datetime (or None)</li> </ul>"},{"location":"changelog/#changes","title":"Changes","text":"<ul> <li>Input and output of components are now specified by <code>span_getter</code> and <code>span_setter</code> arguments.</li> <li> Score / disorders / behaviors entities now have a fixed label (passed as an argument), instead of being dynamically set from the component name. The following scores may have a different name than the current one in your pipelines:</li> <li><code>eds.emergency.gemsa</code> \u2192 <code>emergency_gemsa</code></li> <li><code>eds.emergency.ccmu</code> \u2192 <code>emergency_ccmu</code></li> <li><code>eds.emergency.priority</code> \u2192 <code>emergency_priority</code></li> <li><code>eds.charlson</code> \u2192 <code>charlson</code></li> <li><code>eds.elston_ellis</code> \u2192 <code>elston_ellis</code></li> <li><code>eds.SOFA</code> \u2192 <code>sofa</code></li> <li><code>eds.adicap</code> \u2192 <code>adicap</code></li> <li><code>eds.measuremets</code> \u2192 <code>size</code>, <code>weight</code>, ... instead of <code>eds.size</code>, <code>eds.weight</code>, ...</li> <li><code>eds.dates</code> now separate dates from durations. Each entity has its own label:</li> <li><code>spans[\"dates\"]</code> \u2192 entities labelled as <code>date</code> with a <code>span._.date</code> parsed object</li> <li><code>spans[\"durations\"]</code> \u2192 entities labelled as <code>duration</code> with a <code>span._.duration</code> parsed object</li> <li>the \"relative\" / \"absolute\" / \"duration\" mode of the time entity is now stored in   the <code>mode</code> attribute of the <code>span._.date/duration</code></li> <li>the \"from\" / \"until\" period bound, if any, is now stored in the <code>span._.date.bound</code> attribute</li> <li><code>to_datetime</code> now only return absolute dates, converts relative dates into absolute if <code>doc._.note_datetime</code> is given, and None otherwise</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li><code>export_to_brat</code> issue with spans of entities on multiple lines.</li> </ul>"},{"location":"changelog/#v081-2023-05-31","title":"v0.8.1 (2023-05-31)","text":"<p>Fix release to allow installation from source</p>"},{"location":"changelog/#v080-2023-05-24","title":"v0.8.0 (2023-05-24)","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>New trainable component for multi-label, multi-class span qualification (any attribute/extension)</li> <li>Add range measurements (like <code>la tumeur fait entre 1 et 2 cm</code>) to <code>eds.measurements</code> matcher</li> <li>Add <code>eds.CKD</code> component</li> <li>Add <code>eds.COPD</code> component</li> <li>Add <code>eds.alcohol</code> component</li> <li>Add <code>eds.cerebrovascular_accident</code> component</li> <li>Add <code>eds.congestive_heart_failure</code> component</li> <li>Add <code>eds.connective_tissue_disease</code> component</li> <li>Add <code>eds.dementia</code> component</li> <li>Add <code>eds.diabetes</code> component</li> <li>Add <code>eds.hemiplegia</code> component</li> <li>Add <code>eds.leukemia</code> component</li> <li>Add <code>eds.liver_disease</code> component</li> <li>Add <code>eds.lymphoma</code> component</li> <li>Add <code>eds.myocardial_infarction</code> component</li> <li>Add <code>eds.peptic_ulcer_disease</code> component</li> <li>Add <code>eds.peripheral_vascular_disease</code> component</li> <li>Add <code>eds.solid_tumor</code> component</li> <li>Add <code>eds.tobacco</code> component</li> <li>Add <code>eds.spaces</code> (or <code>eds.normalizer</code> with <code>spaces=True</code>) to detect space tokens, and add <code>ignore_space_tokens</code> to <code>EDSPhraseMatcher</code> and <code>SimstringMatcher</code> to skip them</li> <li>Add <code>ignore_space_tokens</code> option in most components</li> <li><code>eds.tables</code>: new pipeline to identify formatted tables</li> <li>New <code>merge_mode</code> parameter in <code>eds.measurements</code> to normalize existing entities or detect   measures only inside existing entities</li> <li>Tokenization exceptions (<code>Mr.</code>, <code>Dr.</code>, <code>Mrs.</code>) and non end-of-sentence periods are now tokenized with the next letter in the <code>eds</code> tokenizer</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Disable <code>EDSMatcher</code> preprocessing auto progress tracking by default</li> <li>Moved dependencies to a single pyproject.toml: support for <code>pip install -e '.[dev,docs,setup]'</code></li> <li>ADICAP matcher now allow dot separators (e.g. <code>B.H.HP.A7A0</code>)</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Abbreviation and number tokenization issues in the <code>eds</code> tokenizer</li> <li><code>eds.adicap</code> : reparsed the dictionnary used to decode the ADICAP codes (some of them were wrongly decoded)</li> <li>Fix build for python 3.9 on Mac M1/M2 machines.</li> </ul>"},{"location":"changelog/#v074-2022-12-12","title":"v0.7.4 (2022-12-12)","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li><code>eds.history</code> : Add the option to consider only the closest dates in the sentence (dates inside the boundaries and if there is not, it takes the closest date in the entire sentence).</li> <li><code>eds.negation</code> : It takes into account following past participates and preceding infinitives.</li> <li><code>eds.hypothesis</code>: It takes into account following past participates hypothesis verbs.</li> <li><code>eds.negation</code> &amp; <code>eds.hypothesis</code> : Introduce new patterns and remove unnecessary patterns.</li> <li><code>eds.dates</code> : Add a pattern for preceding relative dates (ex: l'embolie qui est survenue \u00e0 10 jours).</li> <li>Improve patterns in the <code>eds.pollution</code> component to account for multiline footers</li> <li>Add <code>QuickExample</code> object to quickly try a pipeline.</li> <li>Add UMLS terminology matcher <code>eds.umls</code></li> <li>New <code>RegexMatcher</code> method to create spans from groupdicts</li> <li>New <code>eds.dates</code> option to disable time detection</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Improve date detection by removing false positives</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li><code>eds.hypothesis</code> : Remove too generic patterns.</li> <li><code>EDSTokenizer</code> : It now tokenizes <code>\"rechereche d'\"</code> as <code>[\"recherche\", \"d'\"]</code>, instead of <code>[\"recherche\", \"d\", \"'\"]</code>.</li> <li>Fix small typos in the documentation and in the docstring.</li> <li>Harmonize processing utils (distributed custom_pipe) to have the same API for Pandas and Pyspark</li> <li>Fix BratConnector file loading issues with complex file hierarchies</li> </ul>"},{"location":"changelog/#v072-2022-10-26","title":"v0.7.2 (2022-10-26)","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Improve the <code>eds.history</code> component by taking into account the date extracted from <code>eds.dates</code> component.</li> <li>New pop up when you click on the copy icon in the termynal widget (docs).</li> <li>Add NER <code>eds.elston-ellis</code> pipeline to identify Elston Ellis scores</li> <li>Add flags=re.MULTILINE to <code>eds.pollution</code> and change pattern of footer</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Remove the warning in the <code>eds.sections</code> when <code>eds.normalizer</code> is in the pipe.</li> <li>Fix filter_spans for strictly nested entities</li> <li>Fill eds.remove-lowercase \"assign\" metadata to run the pipeline during EDSPhraseMatcher preprocessing</li> <li>Allow back spaCy components whose name contains a dot (forbidden since spaCy v3.4.2) for backward compatibility.</li> </ul>"},{"location":"changelog/#v071-2022-10-13","title":"v0.7.1 (2022-10-13)","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Add new patterns (footer, web entities, biology tables, coding sections) to pipeline normalisation (pollution)</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Improved TNM detection algorithm</li> <li>Account for more modifiers in ADICAP codes detection</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Add nephew, niece and daughter to family qualifier patterns</li> <li>EDSTokenizer (<code>spacy.blank('eds')</code>) now recognizes non-breaking whitespaces as spaces and does not split float numbers</li> <li><code>eds.dates</code> pipeline now allows new lines as space separators in dates</li> </ul>"},{"location":"changelog/#v070-2022-09-06","title":"v0.7.0 (2022-09-06)","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>New nested NER trainable <code>nested_ner</code> pipeline component</li> <li>Support for nested entities and attributes in BratDataConnector</li> <li>Pytorch wrappers and experimental training utils</li> <li>Add attribute <code>section</code> to entities</li> <li>Add new cases for separator pattern when components of the TNM score are separated by a forward slash</li> <li>Add NER <code>eds.adicap</code> pipeline to identify ADICAP codes</li> <li>Add patterns to <code>pollution</code> pipeline and simplifies activating or deactivating specific patterns</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Simplified the configuration scheme of the <code>pollution</code> pipeline</li> <li>Update of the <code>ContextualMatcher</code> (and all pipelines depending on it), rendering it more flexible to use</li> <li>Rename R component of score TNM as \"resection_completeness\"</li> </ul>"},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Prevent section titles from capturing surrounding tokens, causing overlaps (#113)</li> <li>Enhance existing patterns for section detection and add patterns for previously ignored sections (introduction, evolution, modalites de sortie, vaccination) .</li> <li>Fix explain mode, which was always triggered, in <code>eds.history</code> factory.</li> <li>Fix test in <code>eds.sections</code>. Previously, no check was done</li> <li>Remove SOFA scores spurious span suffixes</li> </ul>"},{"location":"changelog/#v062-2022-08-02","title":"v0.6.2 (2022-08-02)","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>New <code>SimstringMatcher</code> matcher to perform fuzzy term matching, and <code>algorithm</code> parameter in terminology components and <code>eds.matcher</code> component</li> <li>Makefile to install,test the application and see the documentation</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Add consultation date pattern \"CS\", and False Positive patterns for dates (namely phone numbers and pagination).</li> <li>Update the pipeline score <code>eds.TNM</code>. Now it is possible to return a dictionary where the results are either <code>str</code> or <code>int</code> values</li> </ul>"},{"location":"changelog/#fixed_6","title":"Fixed","text":"<ul> <li>Add new patterns to the negation qualifier</li> <li>Numpy header issues with binary distributed packages</li> <li>Simstring dependency on Windows</li> </ul>"},{"location":"changelog/#v061-2022-07-11","title":"v0.6.1 (2022-07-11)","text":""},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li>Now possible to provide regex flags when using the RegexMatcher</li> <li>New <code>ContextualMatcher</code> pipe, aiming at replacing the <code>AdvancedRegex</code> pipe.</li> <li>New <code>as_ents</code> parameter for <code>eds.dates</code>, to save detected dates as entities</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Faster <code>eds.sentences</code> pipeline component with Cython</li> <li>Bump version of Pydantic in <code>requirements.txt</code> to 1.8.2 to handle an incompatibility with the ContextualMatcher</li> <li>Optimise space requirements by using <code>.csv.gz</code> compression for verbs</li> </ul>"},{"location":"changelog/#fixed_7","title":"Fixed","text":"<ul> <li><code>eds.sentences</code> behaviour with dot-delimited dates (eg <code>02.07.2022</code>, which counted as three sentences)</li> </ul>"},{"location":"changelog/#v060-2022-06-17","title":"v0.6.0 (2022-06-17)","text":""},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li>Complete revamp of the measurements detection pipeline, with better parsing and more exhaustive matching</li> <li>Add new functionality to the method <code>Span._.date.to_datetime()</code> to return a result infered from context for those cases with missing information.</li> <li>Force a batch size of 2000 when distributing a pipeline with Spark</li> <li>New patterns to pipeline <code>eds.dates</code> to identify cases where only the month is mentioned</li> <li>New <code>eds.terminology</code> component for generic terminology matching, using the <code>kb_id_</code> attribute to store fine-grained entity label</li> <li>New <code>eds.cim10</code> terminology matching pipeline</li> <li>New <code>eds.drugs</code> terminology pipeline that maps brand names and active ingredients to a unique ATC code</li> </ul>"},{"location":"changelog/#v053-2022-05-04","title":"v0.5.3 (2022-05-04)","text":""},{"location":"changelog/#added_9","title":"Added","text":"<ul> <li>Support for strings in the example utility</li> <li>TNM detection and normalisation with the <code>eds.TNM</code> pipeline</li> <li>Support for arbitrary callback for Pandas multiprocessing, with the <code>callback</code> argument</li> </ul>"},{"location":"changelog/#v052-2022-04-29","title":"v0.5.2 (2022-04-29)","text":""},{"location":"changelog/#added_10","title":"Added","text":"<ul> <li>Support for chained attributes in the <code>processing</code> pipelines</li> <li>Colour utility with the category20 colour palette</li> </ul>"},{"location":"changelog/#fixed_8","title":"Fixed","text":"<ul> <li>Correct a REGEX on the date detector (both <code>nov</code> and <code>nov.</code> are now detected, as all other months)</li> </ul>"},{"location":"changelog/#v051-2022-04-11","title":"v0.5.1 (2022-04-11)","text":""},{"location":"changelog/#fixed_9","title":"Fixed","text":"<ul> <li>Updated Numpy requirements to be compatible with the <code>EDSPhraseMatcher</code></li> </ul>"},{"location":"changelog/#v050-2022-04-08","title":"v0.5.0 (2022-04-08)","text":""},{"location":"changelog/#added_11","title":"Added","text":"<ul> <li>New <code>eds</code> language to better fit French clinical documents and improve speed</li> <li>Testing for markdown codeblocks to make sure the documentation is actually executable</li> </ul>"},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>Complete revamp of the date detection pipeline, with better parsing and more exhaustive matching</li> <li>Reimplementation of the EDSPhraseMatcher in Cython, leading to a x15 speed increase</li> </ul>"},{"location":"changelog/#v044","title":"v0.4.4","text":"<ul> <li>Add <code>measures</code> pipeline</li> <li>Cap Jinja2 version to fix mkdocs</li> <li>Adding the possibility to add context in the processing module</li> <li>Improve the speed of char replacement pipelines (accents and quotes)</li> <li>Improve the speed of the regex matcher</li> </ul>"},{"location":"changelog/#v043","title":"v0.4.3","text":"<ul> <li>Fix regex matching on spans.</li> <li>Add fast_parse in date pipeline.</li> <li>Add relative_date information parsing</li> </ul>"},{"location":"changelog/#v042","title":"v0.4.2","text":"<ul> <li>Fix issue with <code>dateparser</code> library (see scrapinghub/dateparser#1045)</li> <li>Fix <code>attr</code> issue in the <code>advanced-regex</code> pipelin</li> <li>Add documentation for <code>eds.covid</code></li> <li>Update the demo with an explanation for the regex</li> </ul>"},{"location":"changelog/#v041","title":"v0.4.1","text":"<ul> <li>Added support to Koalas DataFrames in the <code>edsnlp.processing</code> pipe.</li> <li>Added <code>eds.covid</code> NER pipeline for detecting COVID19 mentions.</li> </ul>"},{"location":"changelog/#v040","title":"v0.4.0","text":"<ul> <li>Profound re-write of the normalisation :</li> <li>The custom attribute <code>CUSTOM_NORM</code> is completely abandoned in favour of a more spacyfic alternative</li> <li>The <code>normalizer</code> pipeline modifies the <code>NORM</code> attribute in place</li> <li>Other pipelines can modify the <code>Token._.excluded</code> custom attribute</li> <li>EDS regex and term matchers can ignore excluded tokens during matching, effectively adding a second dimension to normalisation (choice of the attribute and possibility to skip pollution tokens regardless of the attribute)</li> <li>Matching can be performed on custom attributes more easily</li> <li>Qualifiers are regrouped together within the <code>edsnlp.qualifiers</code> submodule, the inheritance from the <code>GenericMatcher</code> is dropped.</li> <li><code>edsnlp.utils.filter.filter_spans</code> now accepts a <code>label_to_remove</code> parameter. If set, only corresponding spans are removed, along with overlapping spans. Primary use-case: removing pseudo cues for qualifiers.</li> <li>Generalise the naming convention for extensions, which keep the same name as the pipeline that created them (eg <code>Span._.negation</code> for the <code>eds.negation</code> pipeline). The previous convention is kept for now, but calling it issues a warning.</li> <li>The <code>dates</code> pipeline underwent some light formatting to increase robustness and fix a few issues</li> <li>A new <code>consultation_dates</code> pipeline was added, which looks for dates preceded by expressions specific to consultation dates</li> <li>In rule-based processing, the <code>terms.py</code> submodule is replaced by <code>patterns.py</code> to reflect the possible presence of regular expressions</li> <li>Refactoring of the architecture :</li> <li>pipelines are now regrouped by type (<code>core</code>, <code>ner</code>, <code>misc</code>, <code>qualifiers</code>)</li> <li><code>matchers</code> submodule contains <code>RegexMatcher</code> and <code>PhraseMatcher</code> classes, which interact with the normalisation</li> <li><code>multiprocessing</code> submodule contains <code>spark</code> and <code>local</code> multiprocessing tools</li> <li><code>connectors</code> contains <code>Brat</code>, <code>OMOP</code> and <code>LabelTool</code> connectors</li> <li><code>utils</code> contains various utilities</li> <li>Add entry points to make pipeline usable directly, removing the need to import <code>edsnlp.components</code>.</li> <li>Add a <code>eds</code> namespace for components: for instance, <code>negation</code> becomes <code>eds.negation</code>. Using the former pipeline name still works, but issues a deprecation warning.</li> <li>Add 3 score pipelines related to emergency</li> <li>Add a helper function to use a spaCy pipeline as a Spark UDF.</li> <li>Fix alignment issues in RegexMatcher</li> <li>Change the alignment procedure, dropping clumsy <code>numpy</code> dependency in favour of <code>bisect</code></li> <li>Change the name of <code>eds.antecedents</code> to <code>eds.history</code>.   Calling <code>eds.antecedents</code> still works, but issues a deprecation warning and support will be removed in a future version.</li> <li>Add a <code>eds.covid</code> component, that identifies mentions of COVID</li> <li>Change the demo, to include NER components</li> </ul>"},{"location":"changelog/#v032","title":"v0.3.2","text":"<ul> <li>Major revamp of the normalisation.</li> <li>The <code>normalizer</code> pipeline now adds atomic components (<code>lowercase</code>, <code>accents</code>, <code>quotes</code>, <code>pollution</code> &amp; <code>endlines</code>) to the processing pipeline, and compiles the results into a new <code>Doc._.normalized</code> extension. The latter is itself a spaCy <code>Doc</code> object, wherein tokens are normalised and pollution tokens are removed altogether. Components that match on the <code>CUSTOM_NORM</code> attribute process the <code>normalized</code> document, and matches are brought back to the original document using a token-wise mapping.</li> <li>Update the <code>RegexMatcher</code> to use the <code>CUSTOM_NORM</code> attribute</li> <li>Add an <code>EDSPhraseMatcher</code>, wrapping spaCy's <code>PhraseMatcher</code> to enable matching on <code>CUSTOM_NORM</code>.</li> <li>Update the <code>matcher</code> and <code>advanced</code> pipelines to enable matching on the <code>CUSTOM_NORM</code> attribute.</li> <li>Add an OMOP connector, to help go back and forth between OMOP-formatted pandas dataframes and spaCy documents.</li> <li>Add a <code>reason</code> pipeline, that extracts the reason for visit.</li> <li>Add an <code>endlines</code> pipeline, that classifies newline characters between spaces and actual ends of line.</li> <li>Add possibility to annotate within entities for qualifiers (<code>negation</code>, <code>hypothesis</code>, etc), ie if the cue is within the entity. Disabled by default.</li> </ul>"},{"location":"changelog/#v031","title":"v0.3.1","text":"<ul> <li>Update <code>dates</code> to remove miscellaneous bugs.</li> <li>Add <code>isort</code> pre-commit hook.</li> <li>Improve performance for <code>negation</code>, <code>hypothesis</code>, <code>antecedents</code>, <code>family</code> and <code>rspeech</code> by using spaCy's <code>filter_spans</code> and our <code>consume_spans</code> methods.</li> <li>Add proposition segmentation to <code>hypothesis</code> and <code>family</code>, enhancing results.</li> </ul>"},{"location":"changelog/#v030","title":"v0.3.0","text":"<ul> <li>Renamed <code>generic</code> to <code>matcher</code>. This is a non-breaking change for the average user, adding the pipeline is still :</li> </ul> <pre><code>nlp.add_pipe(\"matcher\", config=dict(terms=dict(maladie=\"maladie\")))\n</code></pre> <ul> <li>Removed <code>quickumls</code> pipeline. It was untested, unmaintained. Will be added back in a future release.</li> <li>Add <code>score</code> pipeline, and <code>charlson</code>.</li> <li>Add <code>advanced-regex</code> pipeline</li> <li>Corrected bugs in the <code>negation</code> pipeline</li> </ul>"},{"location":"changelog/#v020","title":"v0.2.0","text":"<ul> <li>Add <code>negation</code> pipeline</li> <li>Add <code>family</code> pipeline</li> <li>Add <code>hypothesis</code> pipeline</li> <li>Add <code>antecedents</code> pipeline</li> <li>Add <code>rspeech</code> pipeline</li> <li>Refactor the library :</li> <li>Remove the <code>rules</code> folder</li> <li>Add a <code>pipelines</code> folder, containing one subdirectory per component</li> <li>Every component subdirectory contains a module defining the component, and a module defining a factory, plus any other utilities (eg <code>terms.py</code>)</li> </ul>"},{"location":"changelog/#v010","title":"v0.1.0","text":"<p>First working version. Available pipelines :</p> <ul> <li><code>section</code></li> <li><code>sentences</code></li> <li><code>normalization</code></li> <li><code>pollution</code></li> </ul>"}]}